2020-11-26 14:26:21,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-11-26 14:26:21,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-11-26 14:26:22,299 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-11-26 14:26:22,416 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-11-26 14:26:22,416 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-11-26 14:26:22,419 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-11-26 14:26:22,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-11-26 14:26:22,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-11-26 14:26:22,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-11-26 14:26:22,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-11-26 14:26:22,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-11-26 14:26:22,562 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-11-26 14:26:22,569 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-11-26 14:26:22,588 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-11-26 14:26:22,592 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-11-26 14:26:22,594 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-11-26 14:26:22,594 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-11-26 14:26:22,594 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-11-26 14:26:22,605 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40457
2020-11-26 14:26:22,605 INFO org.mortbay.log: jetty-6.1.26
2020-11-26 14:26:22,809 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40457
2020-11-26 14:26:22,905 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-11-26 14:26:22,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-11-26 14:26:22,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-11-26 14:26:23,002 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-11-26 14:26:23,014 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-11-26 14:26:23,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-11-26 14:26:23,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-11-26 14:26:23,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-11-26 14:26:23,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-11-26 14:26:23,123 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-11-26 14:26:23,130 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-11-26 14:26:23,541 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 61@slave1
2020-11-26 14:26:23,542 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,542 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 14:26:23,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-33536009-172.18.0.2-1606371975169 is not formatted for BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 14:26:23,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-33536009-172.18.0.2-1606371975169 directory /tmp/hadoop/dfs/data/current/BP-33536009-172.18.0.2-1606371975169/current
2020-11-26 14:26:23,605 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-11-26 14:26:23,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1701568202;bpid=BP-33536009-172.18.0.2-1606371975169;lv=-56;nsInfo=lv=-63;cid=CID-a667e8b6-c7c4-443b-90cf-9eeda9af83fd;nsid=1701568202;c=0;bpid=BP-33536009-172.18.0.2-1606371975169;dnuuid=null
2020-11-26 14:26:23,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 6b7e0787-cf64-4e20-81f3-92e456d74456
2020-11-26 14:26:23,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-55ad6825-29d0-4a6c-b110-e4ba27d04973
2020-11-26 14:26:23,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-11-26 14:26:23,692 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-11-26 14:26:23,692 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,693 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 14:26:23,701 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-33536009-172.18.0.2-1606371975169 on /tmp/hadoop/dfs/data/current: 7ms
2020-11-26 14:26:23,701 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-33536009-172.18.0.2-1606371975169: 10ms
2020-11-26 14:26:23,702 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 14:26:23,702 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-11-26 14:26:23,702 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-11-26 14:26:23,838 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data
2020-11-26 14:26:23,840 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): finished scanning block pool BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,864 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1606381857864 with interval 21600000
2020-11-26 14:26:23,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-11-26 14:26:23,896 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): no suitable block pools found to scan.  Waiting 1814399927 ms.
2020-11-26 14:26:23,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-11-26 14:26:23,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-11-26 14:26:23,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid 6b7e0787-cf64-4e20-81f3-92e456d74456) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-11-26 14:26:23,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid 6b7e0787-cf64-4e20-81f3-92e456d74456) service to master/172.18.0.2:54310
2020-11-26 14:26:24,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1a36b339f66,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-11-26 14:26:24,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:29:10,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741826_1002 src: /172.18.0.2:33070 dest: /172.18.0.3:50010
2020-11-26 14:29:10,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33070, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741826_1002, duration: 155033591
2020-11-26 14:29:10,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741828_1004 src: /172.18.0.2:33074 dest: /172.18.0.3:50010
2020-11-26 14:29:11,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33074, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741828_1004, duration: 62265328
2020-11-26 14:29:11,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741829_1005 src: /172.18.0.2:33076 dest: /172.18.0.3:50010
2020-11-26 14:29:11,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33076, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741829_1005, duration: 54942250
2020-11-26 14:29:11,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741831_1007 src: /172.18.0.2:33080 dest: /172.18.0.3:50010
2020-11-26 14:29:11,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33080, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741831_1007, duration: 42482987
2020-11-26 14:29:11,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741832_1008 src: /172.18.0.2:33082 dest: /172.18.0.3:50010
2020-11-26 14:29:11,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33082, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741832_1008, duration: 45765520
2020-11-26 14:29:11,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741837_1013 src: /172.18.0.2:33092 dest: /172.18.0.3:50010
2020-11-26 14:29:11,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33092, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741837_1013, duration: 52794706
2020-11-26 14:29:11,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741838_1014 src: /172.18.0.2:33094 dest: /172.18.0.3:50010
2020-11-26 14:29:11,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33094, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741838_1014, duration: 56436286
2020-11-26 14:29:11,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741839_1015 src: /172.18.0.2:33096 dest: /172.18.0.3:50010
2020-11-26 14:29:11,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33096, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741839_1015, duration: 61858260
2020-11-26 14:29:11,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741840_1016 src: /172.18.0.2:33098 dest: /172.18.0.3:50010
2020-11-26 14:29:12,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33098, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741840_1016, duration: 82835998
2020-11-26 14:29:12,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741841_1017 src: /172.18.0.2:33100 dest: /172.18.0.3:50010
2020-11-26 14:29:12,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33100, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741841_1017, duration: 50650245
2020-11-26 14:29:12,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741844_1020 src: /172.18.0.2:33106 dest: /172.18.0.3:50010
2020-11-26 14:29:12,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33106, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741844_1020, duration: 63203323
2020-11-26 14:29:12,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741845_1021 src: /172.18.0.2:33108 dest: /172.18.0.3:50010
2020-11-26 14:29:12,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33108, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741845_1021, duration: 56705882
2020-11-26 14:29:12,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741846_1022 src: /172.18.0.2:33110 dest: /172.18.0.3:50010
2020-11-26 14:29:12,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33110, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741846_1022, duration: 66855801
2020-11-26 14:29:12,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741847_1023 src: /172.18.0.2:33112 dest: /172.18.0.3:50010
2020-11-26 14:29:12,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33112, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741847_1023, duration: 79579946
2020-11-26 14:29:12,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741848_1024 src: /172.18.0.2:33114 dest: /172.18.0.3:50010
2020-11-26 14:29:12,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33114, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741848_1024, duration: 40421243
2020-11-26 14:29:12,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741850_1026 src: /172.18.0.2:33118 dest: /172.18.0.3:50010
2020-11-26 14:29:12,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33118, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741850_1026, duration: 50380337
2020-11-26 14:29:12,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:13,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741856_1032 src: /172.18.0.2:33130 dest: /172.18.0.3:50010
2020-11-26 14:29:13,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:33130, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741856_1032, duration: 26268835
2020-11-26 14:29:13,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:30:40,985 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741826_1002 for rescanning.
2020-11-26 14:30:49,915 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741828_1004 for rescanning.
2020-11-26 14:30:49,973 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741829_1005 for rescanning.
2020-11-26 14:30:58,386 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741831_1007 for rescanning.
2020-11-26 14:31:06,084 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741832_1008 for rescanning.
2020-11-26 14:31:23,822 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741837_1013 for rescanning.
2020-11-26 14:31:31,133 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741838_1014 for rescanning.
2020-11-26 14:31:32,042 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741839_1015 for rescanning.
2020-11-26 14:31:39,171 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741840_1016 for rescanning.
2020-11-26 14:31:40,214 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741841_1017 for rescanning.
2020-11-26 14:31:55,448 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741844_1020 for rescanning.
2020-11-26 14:31:56,674 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741845_1021 for rescanning.
2020-11-26 14:32:03,390 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741846_1022 for rescanning.
2020-11-26 14:32:04,905 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741847_1023 for rescanning.
2020-11-26 14:32:11,539 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741848_1024 for rescanning.
2020-11-26 14:32:19,681 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741850_1026 for rescanning.
2020-11-26 14:32:43,699 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-55ad6825-29d0-4a6c-b110-e4ba27d04973): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741856_1032 for rescanning.
2020-11-26 14:32:49,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741857_1033 src: /172.18.0.4:46586 dest: /172.18.0.3:50010
2020-11-26 14:32:49,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741858_1034 src: /172.18.0.3:52690 dest: /172.18.0.3:50010
2020-11-26 14:32:49,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46586, dest: /172.18.0.3:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741857_1033, duration: 61281862
2020-11-26 14:32:49,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:49,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52690, dest: /172.18.0.3:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741858_1034, duration: 29879791
2020-11-26 14:32:49,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:49,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741859_1035 src: /172.18.0.3:52696 dest: /172.18.0.3:50010
2020-11-26 14:32:49,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741860_1036 src: /172.18.0.4:46596 dest: /172.18.0.3:50010
2020-11-26 14:32:49,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46596, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741860_1036, duration: 29983009
2020-11-26 14:32:49,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:49,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52696, dest: /172.18.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741859_1035, duration: 33644916
2020-11-26 14:32:49,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741861_1037 src: /172.18.0.4:46600 dest: /172.18.0.3:50010
2020-11-26 14:32:49,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46600, dest: /172.18.0.3:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741861_1037, duration: 10216287
2020-11-26 14:32:49,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:49,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741862_1038 src: /172.18.0.3:52708 dest: /172.18.0.3:50010
2020-11-26 14:32:49,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52708, dest: /172.18.0.3:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741862_1038, duration: 26665295
2020-11-26 14:32:49,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:49,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741863_1039 src: /172.18.0.4:46608 dest: /172.18.0.3:50010
2020-11-26 14:32:50,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741864_1040 src: /172.18.0.3:52716 dest: /172.18.0.3:50010
2020-11-26 14:32:50,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46608, dest: /172.18.0.3:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741863_1039, duration: 10508599
2020-11-26 14:32:50,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52716, dest: /172.18.0.3:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741864_1040, duration: 3798680
2020-11-26 14:32:50,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741865_1041 src: /172.18.0.4:46616 dest: /172.18.0.3:50010
2020-11-26 14:32:50,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46616, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741865_1041, duration: 1478606
2020-11-26 14:32:50,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741866_1042 src: /172.18.0.3:52724 dest: /172.18.0.3:50010
2020-11-26 14:32:50,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52724, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741866_1042, duration: 31132482
2020-11-26 14:32:50,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741867_1043 src: /172.18.0.4:46624 dest: /172.18.0.3:50010
2020-11-26 14:32:50,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46624, dest: /172.18.0.3:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741867_1043, duration: 4201212
2020-11-26 14:32:50,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741868_1044 src: /172.18.0.3:52732 dest: /172.18.0.3:50010
2020-11-26 14:32:50,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52732, dest: /172.18.0.3:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741868_1044, duration: 4371910
2020-11-26 14:32:50,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741869_1045 src: /172.18.0.4:46632 dest: /172.18.0.3:50010
2020-11-26 14:32:50,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46632, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741869_1045, duration: 13558630
2020-11-26 14:32:50,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741870_1046 src: /172.18.0.3:52740 dest: /172.18.0.3:50010
2020-11-26 14:32:50,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52740, dest: /172.18.0.3:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741870_1046, duration: 48486601
2020-11-26 14:32:50,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741871_1047 src: /172.18.0.4:46640 dest: /172.18.0.3:50010
2020-11-26 14:32:50,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741872_1048 src: /172.18.0.3:52748 dest: /172.18.0.3:50010
2020-11-26 14:32:50,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46640, dest: /172.18.0.3:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741871_1047, duration: 18384730
2020-11-26 14:32:50,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52748, dest: /172.18.0.3:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741872_1048, duration: 37048179
2020-11-26 14:32:50,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741873_1049 src: /172.18.0.4:46648 dest: /172.18.0.3:50010
2020-11-26 14:32:50,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46648, dest: /172.18.0.3:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741873_1049, duration: 14312635
2020-11-26 14:32:50,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741874_1050 src: /172.18.0.3:52756 dest: /172.18.0.3:50010
2020-11-26 14:32:50,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52756, dest: /172.18.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741874_1050, duration: 21146940
2020-11-26 14:32:50,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741875_1051 src: /172.18.0.4:46656 dest: /172.18.0.3:50010
2020-11-26 14:32:51,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741876_1052 src: /172.18.0.3:52764 dest: /172.18.0.3:50010
2020-11-26 14:32:51,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46656, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741875_1051, duration: 31973123
2020-11-26 14:32:51,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52764, dest: /172.18.0.3:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741876_1052, duration: 19580530
2020-11-26 14:32:51,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741877_1053 src: /172.18.0.4:46664 dest: /172.18.0.3:50010
2020-11-26 14:32:51,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741878_1054 src: /172.18.0.3:52772 dest: /172.18.0.3:50010
2020-11-26 14:32:51,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46664, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741877_1053, duration: 17828105
2020-11-26 14:32:51,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52772, dest: /172.18.0.3:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741878_1054, duration: 37044553
2020-11-26 14:32:51,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741879_1055 src: /172.18.0.4:46672 dest: /172.18.0.3:50010
2020-11-26 14:32:51,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741880_1056 src: /172.18.0.3:52780 dest: /172.18.0.3:50010
2020-11-26 14:32:51,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46672, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741879_1055, duration: 14940713
2020-11-26 14:32:51,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52780, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741880_1056, duration: 28431687
2020-11-26 14:32:51,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741881_1057 src: /172.18.0.4:46680 dest: /172.18.0.3:50010
2020-11-26 14:32:51,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741882_1058 src: /172.18.0.3:52788 dest: /172.18.0.3:50010
2020-11-26 14:32:51,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46680, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741881_1057, duration: 18219411
2020-11-26 14:32:51,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52788, dest: /172.18.0.3:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741882_1058, duration: 4972188
2020-11-26 14:32:51,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741883_1059 src: /172.18.0.4:46688 dest: /172.18.0.3:50010
2020-11-26 14:32:51,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741884_1060 src: /172.18.0.3:52796 dest: /172.18.0.3:50010
2020-11-26 14:32:51,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46688, dest: /172.18.0.3:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741883_1059, duration: 7928388
2020-11-26 14:32:51,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52796, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741884_1060, duration: 3669860
2020-11-26 14:32:51,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741884_1060, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741885_1061 src: /172.18.0.4:46696 dest: /172.18.0.3:50010
2020-11-26 14:32:51,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46696, dest: /172.18.0.3:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741885_1061, duration: 9789958
2020-11-26 14:32:51,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741886_1062 src: /172.18.0.3:52804 dest: /172.18.0.3:50010
2020-11-26 14:32:51,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:52804, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741886_1062, duration: 25605796
2020-11-26 14:32:51,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741886_1062, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741887_1063 src: /172.18.0.4:46704 dest: /172.18.0.3:50010
2020-11-26 14:32:51,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46704, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 6b7e0787-cf64-4e20-81f3-92e456d74456, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741887_1063, duration: 4111208
2020-11-26 14:32:51,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:49:10,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-11-26 22:49:10,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-11-26 22:49:11,414 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-11-26 22:49:11,560 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-11-26 22:49:11,560 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-11-26 22:49:11,565 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-11-26 22:49:11,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-11-26 22:49:11,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-11-26 22:49:11,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-11-26 22:49:11,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-11-26 22:49:11,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-11-26 22:49:11,793 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-11-26 22:49:11,804 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-11-26 22:49:11,817 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-11-26 22:49:11,824 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-11-26 22:49:11,827 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-11-26 22:49:11,827 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-11-26 22:49:11,827 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-11-26 22:49:11,840 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45101
2020-11-26 22:49:11,841 INFO org.mortbay.log: jetty-6.1.26
2020-11-26 22:49:12,072 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45101
2020-11-26 22:49:12,242 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-11-26 22:49:12,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-11-26 22:49:12,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-11-26 22:49:12,430 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-11-26 22:49:12,462 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-11-26 22:49:12,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-11-26 22:49:12,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-11-26 22:49:12,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-11-26 22:49:12,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-11-26 22:49:12,661 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-11-26 22:49:12,669 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-11-26 22:49:13,267 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 84@slave1
2020-11-26 22:49:13,269 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,269 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 22:49:13,372 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,372 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,372 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-826070094-172.18.0.2-1606402143158 is not formatted for BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,372 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 22:49:13,372 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-826070094-172.18.0.2-1606402143158 directory /tmp/hadoop/dfs/data/current/BP-826070094-172.18.0.2-1606402143158/current
2020-11-26 22:49:13,381 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-11-26 22:49:13,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=644343777;bpid=BP-826070094-172.18.0.2-1606402143158;lv=-56;nsInfo=lv=-63;cid=CID-fb04172a-742b-4aef-b727-76c3b62004ab;nsid=644343777;c=0;bpid=BP-826070094-172.18.0.2-1606402143158;dnuuid=null
2020-11-26 22:49:13,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID b8561d8b-4f6c-4087-8949-09626010b949
2020-11-26 22:49:13,453 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-43906cdd-11ad-4523-ad3c-86c374db507d
2020-11-26 22:49:13,453 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-11-26 22:49:13,460 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-11-26 22:49:13,460 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,461 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 22:49:13,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-826070094-172.18.0.2-1606402143158 on /tmp/hadoop/dfs/data/current: 11ms
2020-11-26 22:49:13,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-826070094-172.18.0.2-1606402143158: 12ms
2020-11-26 22:49:13,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 22:49:13,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-11-26 22:49:13,474 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-11-26 22:49:13,697 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data
2020-11-26 22:49:13,699 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): finished scanning block pool BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,716 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1606416290716 with interval 21600000
2020-11-26 22:49:13,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-11-26 22:49:13,807 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): no suitable block pools found to scan.  Waiting 1814399883 ms.
2020-11-26 22:49:13,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-11-26 22:49:13,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-11-26 22:49:13,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid b8561d8b-4f6c-4087-8949-09626010b949) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-11-26 22:49:13,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid b8561d8b-4f6c-4087-8949-09626010b949) service to master/172.18.0.2:54310
2020-11-26 22:49:14,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1a6b9a3e1342,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 59 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-11-26 22:49:14,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:52:22,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741825_1001 src: /172.18.0.2:38018 dest: /172.18.0.3:50010
2020-11-26 22:52:22,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38018, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741825_1001, duration: 279979171
2020-11-26 22:52:22,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:23,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741828_1004 src: /172.18.0.2:38024 dest: /172.18.0.3:50010
2020-11-26 22:52:23,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38024, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741828_1004, duration: 97992570
2020-11-26 22:52:23,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:23,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741831_1007 src: /172.18.0.2:38030 dest: /172.18.0.3:50010
2020-11-26 22:52:24,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38030, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741831_1007, duration: 79851941
2020-11-26 22:52:24,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741832_1008 src: /172.18.0.2:38032 dest: /172.18.0.3:50010
2020-11-26 22:52:24,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38032, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741832_1008, duration: 81050147
2020-11-26 22:52:24,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741835_1011 src: /172.18.0.2:38038 dest: /172.18.0.3:50010
2020-11-26 22:52:24,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38038, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741835_1011, duration: 85815966
2020-11-26 22:52:24,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741836_1012 src: /172.18.0.2:38040 dest: /172.18.0.3:50010
2020-11-26 22:52:24,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38040, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741836_1012, duration: 58492461
2020-11-26 22:52:24,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741839_1015 src: /172.18.0.2:38046 dest: /172.18.0.3:50010
2020-11-26 22:52:24,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38046, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741839_1015, duration: 62372323
2020-11-26 22:52:24,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741840_1016 src: /172.18.0.2:38048 dest: /172.18.0.3:50010
2020-11-26 22:52:25,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38048, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741840_1016, duration: 78308590
2020-11-26 22:52:25,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741841_1017 src: /172.18.0.2:38050 dest: /172.18.0.3:50010
2020-11-26 22:52:25,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38050, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741841_1017, duration: 73437548
2020-11-26 22:52:25,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741842_1018 src: /172.18.0.2:38052 dest: /172.18.0.3:50010
2020-11-26 22:52:25,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38052, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741842_1018, duration: 105843659
2020-11-26 22:52:25,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741844_1020 src: /172.18.0.2:38056 dest: /172.18.0.3:50010
2020-11-26 22:52:25,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38056, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741844_1020, duration: 101911206
2020-11-26 22:52:25,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741847_1023 src: /172.18.0.2:38062 dest: /172.18.0.3:50010
2020-11-26 22:52:25,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38062, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741847_1023, duration: 52883553
2020-11-26 22:52:25,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741849_1025 src: /172.18.0.2:38066 dest: /172.18.0.3:50010
2020-11-26 22:52:25,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38066, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741849_1025, duration: 76761185
2020-11-26 22:52:25,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741850_1026 src: /172.18.0.2:38068 dest: /172.18.0.3:50010
2020-11-26 22:52:26,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38068, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741850_1026, duration: 69122853
2020-11-26 22:52:26,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741852_1028 src: /172.18.0.2:38072 dest: /172.18.0.3:50010
2020-11-26 22:52:26,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38072, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741852_1028, duration: 91264711
2020-11-26 22:52:26,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741853_1029 src: /172.18.0.2:38074 dest: /172.18.0.3:50010
2020-11-26 22:52:26,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38074, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741853_1029, duration: 43746534
2020-11-26 22:52:26,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741855_1031 src: /172.18.0.2:38078 dest: /172.18.0.3:50010
2020-11-26 22:52:26,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38078, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741855_1031, duration: 50824107
2020-11-26 22:52:26,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741858_1034 src: /172.18.0.2:38084 dest: /172.18.0.3:50010
2020-11-26 22:52:26,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38084, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741858_1034, duration: 72102498
2020-11-26 22:52:26,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741861_1037 src: /172.18.0.2:38090 dest: /172.18.0.3:50010
2020-11-26 22:52:26,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38090, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741861_1037, duration: 71999497
2020-11-26 22:52:26,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741865_1041 src: /172.18.0.2:38098 dest: /172.18.0.3:50010
2020-11-26 22:52:27,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38098, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741865_1041, duration: 82440076
2020-11-26 22:52:27,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741866_1042 src: /172.18.0.2:38100 dest: /172.18.0.3:50010
2020-11-26 22:52:27,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38100, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741866_1042, duration: 65927363
2020-11-26 22:52:27,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741867_1043 src: /172.18.0.2:38102 dest: /172.18.0.3:50010
2020-11-26 22:52:27,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38102, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741867_1043, duration: 59952469
2020-11-26 22:52:27,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741868_1044 src: /172.18.0.2:38104 dest: /172.18.0.3:50010
2020-11-26 22:52:27,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38104, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741868_1044, duration: 42522417
2020-11-26 22:52:27,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741870_1046 src: /172.18.0.2:38108 dest: /172.18.0.3:50010
2020-11-26 22:52:27,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38108, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741870_1046, duration: 62497784
2020-11-26 22:52:27,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741871_1047 src: /172.18.0.2:38110 dest: /172.18.0.3:50010
2020-11-26 22:52:27,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38110, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741871_1047, duration: 69231182
2020-11-26 22:52:27,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741872_1048 src: /172.18.0.2:38112 dest: /172.18.0.3:50010
2020-11-26 22:52:27,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38112, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741872_1048, duration: 47593729
2020-11-26 22:52:27,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741873_1049 src: /172.18.0.2:38114 dest: /172.18.0.3:50010
2020-11-26 22:52:27,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38114, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741873_1049, duration: 37183709
2020-11-26 22:52:27,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741874_1050 src: /172.18.0.2:38116 dest: /172.18.0.3:50010
2020-11-26 22:52:28,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38116, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741874_1050, duration: 47730784
2020-11-26 22:52:28,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741878_1054 src: /172.18.0.2:38124 dest: /172.18.0.3:50010
2020-11-26 22:52:28,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38124, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741878_1054, duration: 100819537
2020-11-26 22:52:28,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741879_1055 src: /172.18.0.2:38126 dest: /172.18.0.3:50010
2020-11-26 22:52:28,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38126, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741879_1055, duration: 57932312
2020-11-26 22:52:28,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741882_1058 src: /172.18.0.2:38132 dest: /172.18.0.3:50010
2020-11-26 22:52:28,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38132, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741882_1058, duration: 47072958
2020-11-26 22:52:28,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741884_1060 src: /172.18.0.2:38136 dest: /172.18.0.3:50010
2020-11-26 22:52:28,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38136, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741884_1060, duration: 64247973
2020-11-26 22:52:28,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741886_1062 src: /172.18.0.2:38140 dest: /172.18.0.3:50010
2020-11-26 22:52:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38140, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741886_1062, duration: 88494716
2020-11-26 22:52:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:29,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741887_1063 src: /172.18.0.2:38142 dest: /172.18.0.3:50010
2020-11-26 22:52:29,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38142, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741887_1063, duration: 46169147
2020-11-26 22:52:29,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:54:20,950 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741828_1004 for rescanning.
2020-11-26 22:54:33,827 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741831_1007 for rescanning.
2020-11-26 22:54:44,140 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741832_1008 for rescanning.
2020-11-26 22:54:57,320 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741835_1011 for rescanning.
2020-11-26 22:55:07,230 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741836_1012 for rescanning.
2020-11-26 22:55:20,552 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741839_1015 for rescanning.
2020-11-26 22:55:29,633 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741840_1016 for rescanning.
2020-11-26 22:55:32,209 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741841_1017 for rescanning.
2020-11-26 22:55:40,732 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741842_1018 for rescanning.
2020-11-26 22:55:52,322 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741844_1020 for rescanning.
2020-11-26 22:56:07,944 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741847_1023 for rescanning.
2020-11-26 22:56:19,767 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741849_1025 for rescanning.
2020-11-26 22:56:26,843 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741850_1026 for rescanning.
2020-11-26 22:56:37,752 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741852_1028 for rescanning.
2020-11-26 22:56:43,536 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741853_1029 for rescanning.
2020-11-26 22:56:55,453 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741855_1031 for rescanning.
2020-11-26 22:57:10,890 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741858_1034 for rescanning.
2020-11-26 22:57:30,756 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741861_1037 for rescanning.
2020-11-26 22:57:53,749 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741865_1041 for rescanning.
2020-11-26 22:57:55,272 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741866_1042 for rescanning.
2020-11-26 22:58:05,639 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741867_1043 for rescanning.
2020-11-26 22:58:05,862 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741868_1044 for rescanning.
2020-11-26 22:58:16,965 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741870_1046 for rescanning.
2020-11-26 22:58:27,787 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741872_1048 for rescanning.
2020-11-26 22:58:28,185 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741871_1047 for rescanning.
2020-11-26 22:58:38,644 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741873_1049 for rescanning.
2020-11-26 22:58:39,564 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741874_1050 for rescanning.
2020-11-26 22:59:02,758 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741878_1054 for rescanning.
2020-11-26 22:59:11,768 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741879_1055 for rescanning.
2020-11-26 22:59:26,078 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741882_1058 for rescanning.
2020-11-26 22:59:37,288 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741884_1060 for rescanning.
2020-11-26 22:59:48,840 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741886_1062 for rescanning.
2020-11-26 22:59:55,569 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-43906cdd-11ad-4523-ad3c-86c374db507d): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741887_1063 for rescanning.
2020-11-26 23:00:10,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741889_1065 src: /172.18.0.4:51876 dest: /172.18.0.3:50010
2020-11-26 23:00:10,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741890_1066 src: /172.18.0.3:57980 dest: /172.18.0.3:50010
2020-11-26 23:00:11,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51876, dest: /172.18.0.3:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741889_1065, duration: 86380015
2020-11-26 23:00:11,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741889_1065, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57980, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741890_1066, duration: 68229937
2020-11-26 23:00:11,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741890_1066, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741891_1067 src: /172.18.0.4:51882 dest: /172.18.0.3:50010
2020-11-26 23:00:11,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51882, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741891_1067, duration: 2332006
2020-11-26 23:00:11,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741891_1067, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741892_1068 src: /172.18.0.3:57990 dest: /172.18.0.3:50010
2020-11-26 23:00:11,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57990, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741892_1068, duration: 32801306
2020-11-26 23:00:11,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741892_1068, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741893_1069 src: /172.18.0.4:51890 dest: /172.18.0.3:50010
2020-11-26 23:00:11,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741894_1070 src: /172.18.0.3:57998 dest: /172.18.0.3:50010
2020-11-26 23:00:11,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51890, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741893_1069, duration: 9593601
2020-11-26 23:00:11,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741893_1069, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57998, dest: /172.18.0.3:50010, bytes: 98, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741894_1070, duration: 91817767
2020-11-26 23:00:11,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741894_1070, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741895_1071 src: /172.18.0.4:51898 dest: /172.18.0.3:50010
2020-11-26 23:00:11,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51898, dest: /172.18.0.3:50010, bytes: 81, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741895_1071, duration: 3114047
2020-11-26 23:00:11,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741895_1071, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741896_1072 src: /172.18.0.3:58006 dest: /172.18.0.3:50010
2020-11-26 23:00:12,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58006, dest: /172.18.0.3:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741896_1072, duration: 6801297
2020-11-26 23:00:12,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741896_1072, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741897_1073 src: /172.18.0.4:51906 dest: /172.18.0.3:50010
2020-11-26 23:00:12,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741898_1074 src: /172.18.0.3:58014 dest: /172.18.0.3:50010
2020-11-26 23:00:12,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51906, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741897_1073, duration: 10810446
2020-11-26 23:00:12,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741897_1073, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58014, dest: /172.18.0.3:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741898_1074, duration: 6099106
2020-11-26 23:00:12,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741898_1074, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741899_1075 src: /172.18.0.4:51914 dest: /172.18.0.3:50010
2020-11-26 23:00:12,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741900_1076 src: /172.18.0.3:58022 dest: /172.18.0.3:50010
2020-11-26 23:00:12,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51914, dest: /172.18.0.3:50010, bytes: 60, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741899_1075, duration: 24813307
2020-11-26 23:00:12,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741899_1075, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58022, dest: /172.18.0.3:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741900_1076, duration: 28060575
2020-11-26 23:00:12,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741900_1076, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741901_1077 src: /172.18.0.4:51922 dest: /172.18.0.3:50010
2020-11-26 23:00:12,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51922, dest: /172.18.0.3:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741901_1077, duration: 33257077
2020-11-26 23:00:12,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741901_1077, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741902_1078 src: /172.18.0.3:58030 dest: /172.18.0.3:50010
2020-11-26 23:00:12,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58030, dest: /172.18.0.3:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741902_1078, duration: 77475189
2020-11-26 23:00:12,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741902_1078, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741903_1079 src: /172.18.0.4:51930 dest: /172.18.0.3:50010
2020-11-26 23:00:12,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741904_1080 src: /172.18.0.3:58038 dest: /172.18.0.3:50010
2020-11-26 23:00:12,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51930, dest: /172.18.0.3:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741903_1079, duration: 10808385
2020-11-26 23:00:12,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741903_1079, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58038, dest: /172.18.0.3:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741904_1080, duration: 14653559
2020-11-26 23:00:12,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741904_1080, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741905_1081 src: /172.18.0.4:51938 dest: /172.18.0.3:50010
2020-11-26 23:00:13,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741906_1082 src: /172.18.0.3:58046 dest: /172.18.0.3:50010
2020-11-26 23:00:13,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51938, dest: /172.18.0.3:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741905_1081, duration: 9484078
2020-11-26 23:00:13,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741905_1081, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58046, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741906_1082, duration: 67532925
2020-11-26 23:00:13,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741906_1082, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741907_1083 src: /172.18.0.4:51946 dest: /172.18.0.3:50010
2020-11-26 23:00:13,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51946, dest: /172.18.0.3:50010, bytes: 55, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741907_1083, duration: 8170056
2020-11-26 23:00:13,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741907_1083, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741908_1084 src: /172.18.0.3:58054 dest: /172.18.0.3:50010
2020-11-26 23:00:13,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58054, dest: /172.18.0.3:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741908_1084, duration: 14982983
2020-11-26 23:00:13,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741908_1084, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741909_1085 src: /172.18.0.4:51954 dest: /172.18.0.3:50010
2020-11-26 23:00:13,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51954, dest: /172.18.0.3:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741909_1085, duration: 985377
2020-11-26 23:00:13,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741909_1085, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741910_1086 src: /172.18.0.3:58062 dest: /172.18.0.3:50010
2020-11-26 23:00:13,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58062, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741910_1086, duration: 60170031
2020-11-26 23:00:13,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741910_1086, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741911_1087 src: /172.18.0.4:51962 dest: /172.18.0.3:50010
2020-11-26 23:00:13,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51962, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741911_1087, duration: 4315189
2020-11-26 23:00:13,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741911_1087, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741912_1088 src: /172.18.0.3:58070 dest: /172.18.0.3:50010
2020-11-26 23:00:14,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58070, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741912_1088, duration: 20273986
2020-11-26 23:00:14,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741912_1088, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741913_1089 src: /172.18.0.4:51970 dest: /172.18.0.3:50010
2020-11-26 23:00:14,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51970, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741913_1089, duration: 6313511
2020-11-26 23:00:14,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741913_1089, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741914_1090 src: /172.18.0.3:58078 dest: /172.18.0.3:50010
2020-11-26 23:00:14,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58078, dest: /172.18.0.3:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741914_1090, duration: 12062906
2020-11-26 23:00:14,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741914_1090, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741915_1091 src: /172.18.0.4:51978 dest: /172.18.0.3:50010
2020-11-26 23:00:14,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51978, dest: /172.18.0.3:50010, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741915_1091, duration: 4600681
2020-11-26 23:00:14,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741915_1091, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741916_1092 src: /172.18.0.3:58086 dest: /172.18.0.3:50010
2020-11-26 23:00:14,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741917_1093 src: /172.18.0.4:51986 dest: /172.18.0.3:50010
2020-11-26 23:00:14,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58086, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741916_1092, duration: 40266289
2020-11-26 23:00:14,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741916_1092, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51986, dest: /172.18.0.3:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741917_1093, duration: 20210934
2020-11-26 23:00:14,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741917_1093, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741919_1095 src: /172.18.0.3:58094 dest: /172.18.0.3:50010
2020-11-26 23:00:14,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741918_1094 src: /172.18.0.4:51992 dest: /172.18.0.3:50010
2020-11-26 23:00:14,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:51992, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741918_1094, duration: 43065301
2020-11-26 23:00:14,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741918_1094, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58094, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741919_1095, duration: 9003893
2020-11-26 23:00:14,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741919_1095, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741920_1096 src: /172.18.0.3:58102 dest: /172.18.0.3:50010
2020-11-26 23:00:14,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58102, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741920_1096, duration: 14277620
2020-11-26 23:00:14,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741920_1096, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741921_1097 src: /172.18.0.3:58106 dest: /172.18.0.3:50010
2020-11-26 23:00:15,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58106, dest: /172.18.0.3:50010, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741921_1097, duration: 3803329
2020-11-26 23:00:15,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741921_1097, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741922_1098 src: /172.18.0.3:58110 dest: /172.18.0.3:50010
2020-11-26 23:00:15,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741923_1099 src: /172.18.0.4:52010 dest: /172.18.0.3:50010
2020-11-26 23:00:15,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58110, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741922_1098, duration: 18990742
2020-11-26 23:00:15,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741922_1098, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52010, dest: /172.18.0.3:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741923_1099, duration: 5677308
2020-11-26 23:00:15,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741923_1099, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741924_1100 src: /172.18.0.3:58118 dest: /172.18.0.3:50010
2020-11-26 23:00:15,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741925_1101 src: /172.18.0.4:52018 dest: /172.18.0.3:50010
2020-11-26 23:00:15,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58118, dest: /172.18.0.3:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741924_1100, duration: 17556619
2020-11-26 23:00:15,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741924_1100, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52018, dest: /172.18.0.3:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741925_1101, duration: 5356317
2020-11-26 23:00:15,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741925_1101, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741926_1102 src: /172.18.0.3:58126 dest: /172.18.0.3:50010
2020-11-26 23:00:15,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58126, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741926_1102, duration: 9602853
2020-11-26 23:00:15,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741926_1102, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741927_1103 src: /172.18.0.4:52026 dest: /172.18.0.3:50010
2020-11-26 23:00:15,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52026, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741927_1103, duration: 8433285
2020-11-26 23:00:15,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741927_1103, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741928_1104 src: /172.18.0.3:58134 dest: /172.18.0.3:50010
2020-11-26 23:00:15,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58134, dest: /172.18.0.3:50010, bytes: 75, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741928_1104, duration: 53295554
2020-11-26 23:00:15,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741928_1104, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741929_1105 src: /172.18.0.4:52034 dest: /172.18.0.3:50010
2020-11-26 23:00:16,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52034, dest: /172.18.0.3:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741929_1105, duration: 21227138
2020-11-26 23:00:16,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741929_1105, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741930_1106 src: /172.18.0.3:58142 dest: /172.18.0.3:50010
2020-11-26 23:00:16,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58142, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741930_1106, duration: 3802762
2020-11-26 23:00:16,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741930_1106, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741931_1107 src: /172.18.0.4:52042 dest: /172.18.0.3:50010
2020-11-26 23:00:16,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52042, dest: /172.18.0.3:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741931_1107, duration: 1561014
2020-11-26 23:00:16,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741931_1107, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741932_1108 src: /172.18.0.3:58150 dest: /172.18.0.3:50010
2020-11-26 23:00:16,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58150, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741932_1108, duration: 2064211
2020-11-26 23:00:16,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741932_1108, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741933_1109 src: /172.18.0.4:52050 dest: /172.18.0.3:50010
2020-11-26 23:00:16,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52050, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741933_1109, duration: 9537754
2020-11-26 23:00:16,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741933_1109, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741934_1110 src: /172.18.0.3:58158 dest: /172.18.0.3:50010
2020-11-26 23:00:16,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58158, dest: /172.18.0.3:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741934_1110, duration: 26076111
2020-11-26 23:00:16,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741934_1110, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741935_1111 src: /172.18.0.4:52058 dest: /172.18.0.3:50010
2020-11-26 23:00:16,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52058, dest: /172.18.0.3:50010, bytes: 59, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741935_1111, duration: 646301
2020-11-26 23:00:16,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741935_1111, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741936_1112 src: /172.18.0.3:58166 dest: /172.18.0.3:50010
2020-11-26 23:00:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58166, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741936_1112, duration: 14186833
2020-11-26 23:00:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741936_1112, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741937_1113 src: /172.18.0.4:52066 dest: /172.18.0.3:50010
2020-11-26 23:00:16,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52066, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741937_1113, duration: 818061
2020-11-26 23:00:16,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741937_1113, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741938_1114 src: /172.18.0.3:58174 dest: /172.18.0.3:50010
2020-11-26 23:00:16,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58174, dest: /172.18.0.3:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741938_1114, duration: 3192797
2020-11-26 23:00:16,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741938_1114, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741939_1115 src: /172.18.0.4:52074 dest: /172.18.0.3:50010
2020-11-26 23:00:16,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52074, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741939_1115, duration: 14905425
2020-11-26 23:00:16,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741939_1115, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741940_1116 src: /172.18.0.3:58182 dest: /172.18.0.3:50010
2020-11-26 23:00:17,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:58182, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: b8561d8b-4f6c-4087-8949-09626010b949, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741940_1116, duration: 17088055
2020-11-26 23:00:17,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741940_1116, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:02:48,581 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave1/172.18.0.3"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2020-11-26 23:02:51,350 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-11-26 23:02:51,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave1/172.18.0.3
************************************************************/
2020-12-01 21:47:43,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-12-01 21:47:43,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-01 21:47:44,739 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-01 21:47:44,897 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-01 21:47:44,897 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-01 21:47:44,902 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-01 21:47:44,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-12-01 21:47:44,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-01 21:47:44,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-01 21:47:44,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-01 21:47:44,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-01 21:47:45,133 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-01 21:47:45,143 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-01 21:47:45,161 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-01 21:47:45,168 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-01 21:47:45,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-01 21:47:45,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-01 21:47:45,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-01 21:47:45,199 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45693
2020-12-01 21:47:45,200 INFO org.mortbay.log: jetty-6.1.26
2020-12-01 21:47:45,469 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45693
2020-12-01 21:47:45,657 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-01 21:47:45,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-12-01 21:47:45,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-01 21:47:45,874 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-01 21:47:45,922 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-01 21:47:45,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-01 21:47:45,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-01 21:47:46,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-01 21:47:46,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-12-01 21:47:46,097 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-01 21:47:46,105 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-01 21:47:46,530 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 67@slave1
2020-12-01 21:47:46,531 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,531 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-01 21:47:46,655 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,655 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,656 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1191596377-172.18.0.2-1606830456145 is not formatted for BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,656 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-01 21:47:46,656 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1191596377-172.18.0.2-1606830456145 directory /tmp/hadoop/dfs/data/current/BP-1191596377-172.18.0.2-1606830456145/current
2020-12-01 21:47:46,662 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-12-01 21:47:46,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=299825135;bpid=BP-1191596377-172.18.0.2-1606830456145;lv=-56;nsInfo=lv=-63;cid=CID-36f672ce-16be-4137-95d3-b261fc7fbade;nsid=299825135;c=0;bpid=BP-1191596377-172.18.0.2-1606830456145;dnuuid=null
2020-12-01 21:47:46,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65
2020-12-01 21:47:46,732 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-8f497452-c458-446f-86ab-60d052cb01b8
2020-12-01 21:47:46,732 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-12-01 21:47:46,736 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-01 21:47:46,737 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,738 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data/current...
2020-12-01 21:47:46,749 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1191596377-172.18.0.2-1606830456145 on /tmp/hadoop/dfs/data/current: 11ms
2020-12-01 21:47:46,749 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1191596377-172.18.0.2-1606830456145: 12ms
2020-12-01 21:47:46,758 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data/current...
2020-12-01 21:47:46,759 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data/current: 1ms
2020-12-01 21:47:46,759 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 10ms
2020-12-01 21:47:46,981 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data
2020-12-01 21:47:46,984 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): finished scanning block pool BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:47,002 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1606837905002 with interval 21600000
2020-12-01 21:47:47,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-12-01 21:47:47,106 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): no suitable block pools found to scan.  Waiting 1814399875 ms.
2020-12-01 21:47:47,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-12-01 21:47:47,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-01 21:47:47,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-12-01 21:47:47,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65) service to master/172.18.0.2:54310
2020-12-01 21:47:47,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6ffe16dbb252,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 58 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-01 21:47:47,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:49:14,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741825_1001 src: /172.18.0.2:40280 dest: /172.18.0.3:50010
2020-12-01 21:49:14,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40280, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741825_1001, duration: 324402910
2020-12-01 21:49:14,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:14,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741826_1002 src: /172.18.0.2:40282 dest: /172.18.0.3:50010
2020-12-01 21:49:14,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40282, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741826_1002, duration: 135055438
2020-12-01 21:49:14,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741829_1005 src: /172.18.0.2:40288 dest: /172.18.0.3:50010
2020-12-01 21:49:15,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40288, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741829_1005, duration: 67394780
2020-12-01 21:49:15,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741830_1006 src: /172.18.0.2:40290 dest: /172.18.0.3:50010
2020-12-01 21:49:15,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40290, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741830_1006, duration: 82731733
2020-12-01 21:49:15,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741833_1009 src: /172.18.0.2:40296 dest: /172.18.0.3:50010
2020-12-01 21:49:15,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40296, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741833_1009, duration: 68037611
2020-12-01 21:49:15,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741834_1010 src: /172.18.0.2:40298 dest: /172.18.0.3:50010
2020-12-01 21:49:15,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40298, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741834_1010, duration: 93183823
2020-12-01 21:49:15,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741836_1012 src: /172.18.0.2:40302 dest: /172.18.0.3:50010
2020-12-01 21:49:16,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40302, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741836_1012, duration: 86002181
2020-12-01 21:49:16,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741837_1013 src: /172.18.0.2:40304 dest: /172.18.0.3:50010
2020-12-01 21:49:16,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40304, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741837_1013, duration: 96421122
2020-12-01 21:49:16,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741839_1015 src: /172.18.0.2:40308 dest: /172.18.0.3:50010
2020-12-01 21:49:16,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40308, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741839_1015, duration: 64618370
2020-12-01 21:49:16,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741844_1020 src: /172.18.0.2:40318 dest: /172.18.0.3:50010
2020-12-01 21:49:16,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40318, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741844_1020, duration: 87998959
2020-12-01 21:49:16,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741845_1021 src: /172.18.0.2:40320 dest: /172.18.0.3:50010
2020-12-01 21:49:17,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40320, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741845_1021, duration: 54574122
2020-12-01 21:49:17,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741847_1023 src: /172.18.0.2:40324 dest: /172.18.0.3:50010
2020-12-01 21:49:17,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40324, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741847_1023, duration: 73941954
2020-12-01 21:49:17,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741848_1024 src: /172.18.0.2:40326 dest: /172.18.0.3:50010
2020-12-01 21:49:17,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40326, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741848_1024, duration: 68624845
2020-12-01 21:49:17,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741849_1025 src: /172.18.0.2:40328 dest: /172.18.0.3:50010
2020-12-01 21:49:17,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40328, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741849_1025, duration: 78053099
2020-12-01 21:49:17,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741851_1027 src: /172.18.0.2:40332 dest: /172.18.0.3:50010
2020-12-01 21:49:17,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40332, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741851_1027, duration: 51795738
2020-12-01 21:49:17,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741852_1028 src: /172.18.0.2:40334 dest: /172.18.0.3:50010
2020-12-01 21:49:17,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40334, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741852_1028, duration: 100014481
2020-12-01 21:49:17,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741853_1029 src: /172.18.0.2:40336 dest: /172.18.0.3:50010
2020-12-01 21:49:17,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40336, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741853_1029, duration: 68534401
2020-12-01 21:49:17,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741857_1033 src: /172.18.0.2:40344 dest: /172.18.0.3:50010
2020-12-01 21:49:18,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40344, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741857_1033, duration: 72428280
2020-12-01 21:49:18,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741858_1034 src: /172.18.0.2:40346 dest: /172.18.0.3:50010
2020-12-01 21:49:18,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40346, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741858_1034, duration: 73821353
2020-12-01 21:49:18,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741860_1036 src: /172.18.0.2:40350 dest: /172.18.0.3:50010
2020-12-01 21:49:18,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40350, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741860_1036, duration: 80271114
2020-12-01 21:49:18,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741863_1039 src: /172.18.0.2:40360 dest: /172.18.0.3:50010
2020-12-01 21:49:18,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40360, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741863_1039, duration: 119964409
2020-12-01 21:49:18,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741873_1049 src: /172.18.0.2:40400 dest: /172.18.0.3:50010
2020-12-01 21:49:19,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40400, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741873_1049, duration: 103948375
2020-12-01 21:49:19,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741878_1054 src: /172.18.0.2:40410 dest: /172.18.0.3:50010
2020-12-01 21:49:20,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40410, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741878_1054, duration: 67150119
2020-12-01 21:49:20,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741881_1057 src: /172.18.0.2:40416 dest: /172.18.0.3:50010
2020-12-01 21:49:20,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40416, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741881_1057, duration: 59061786
2020-12-01 21:49:20,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741882_1058 src: /172.18.0.2:40418 dest: /172.18.0.3:50010
2020-12-01 21:49:20,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40418, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741882_1058, duration: 59601371
2020-12-01 21:49:20,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741884_1060 src: /172.18.0.2:40422 dest: /172.18.0.3:50010
2020-12-01 21:49:20,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40422, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741884_1060, duration: 73507935
2020-12-01 21:49:20,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741885_1061 src: /172.18.0.2:40424 dest: /172.18.0.3:50010
2020-12-01 21:49:20,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40424, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741885_1061, duration: 44779857
2020-12-01 21:49:20,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741886_1062 src: /172.18.0.2:40426 dest: /172.18.0.3:50010
2020-12-01 21:49:20,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40426, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741886_1062, duration: 69364802
2020-12-01 21:49:20,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741887_1063 src: /172.18.0.2:40428 dest: /172.18.0.3:50010
2020-12-01 21:49:20,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40428, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741887_1063, duration: 49911297
2020-12-01 21:49:20,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741888_1064 src: /172.18.0.2:40430 dest: /172.18.0.3:50010
2020-12-01 21:49:20,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:40430, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741888_1064, duration: 48661007
2020-12-01 21:49:20,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741888_1064, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:50:38,376 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741826_1002 for rescanning.
2020-12-01 21:50:50,353 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741829_1005 for rescanning.
2020-12-01 21:50:59,807 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741830_1006 for rescanning.
2020-12-01 21:51:12,079 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741833_1009 for rescanning.
2020-12-01 21:51:21,688 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741834_1010 for rescanning.
2020-12-01 21:51:33,385 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741836_1012 for rescanning.
2020-12-01 21:51:35,518 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741837_1013 for rescanning.
2020-12-01 21:51:46,862 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741839_1015 for rescanning.
2020-12-01 21:52:19,038 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741844_1020 for rescanning.
2020-12-01 21:52:22,146 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741845_1021 for rescanning.
2020-12-01 21:52:32,895 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741847_1023 for rescanning.
2020-12-01 21:52:39,877 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741848_1024 for rescanning.
2020-12-01 21:52:43,687 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741849_1025 for rescanning.
2020-12-01 21:52:53,978 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741851_1027 for rescanning.
2020-12-01 21:53:00,589 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741852_1028 for rescanning.
2020-12-01 21:53:04,729 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741853_1029 for rescanning.
2020-12-01 21:53:26,042 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741857_1033 for rescanning.
2020-12-01 21:53:31,709 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741858_1034 for rescanning.
2020-12-01 21:53:42,149 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741860_1036 for rescanning.
2020-12-01 21:53:57,283 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741863_1039 for rescanning.
2020-12-01 21:54:49,680 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741873_1049 for rescanning.
2020-12-01 21:55:15,922 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741878_1054 for rescanning.
2020-12-01 21:55:31,590 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741881_1057 for rescanning.
2020-12-01 21:55:36,597 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741882_1058 for rescanning.
2020-12-01 21:55:46,754 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741884_1060 for rescanning.
2020-12-01 21:55:52,449 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741885_1061 for rescanning.
2020-12-01 21:55:57,099 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741886_1062 for rescanning.
2020-12-01 21:56:03,347 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741887_1063 for rescanning.
2020-12-01 21:56:07,557 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741888_1064 for rescanning.
2020-12-01 21:56:18,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741889_1065 src: /172.18.0.4:46292 dest: /172.18.0.3:50010
2020-12-01 21:56:18,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741890_1066 src: /172.18.0.3:43034 dest: /172.18.0.3:50010
2020-12-01 21:56:18,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46292, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741889_1065, duration: 64970993
2020-12-01 21:56:18,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741889_1065, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:18,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43034, dest: /172.18.0.3:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741890_1066, duration: 85335135
2020-12-01 21:56:18,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741890_1066, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:18,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741891_1067 src: /172.18.0.4:46298 dest: /172.18.0.3:50010
2020-12-01 21:56:18,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46298, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741891_1067, duration: 3343983
2020-12-01 21:56:18,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741891_1067, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:18,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741892_1068 src: /172.18.0.3:43044 dest: /172.18.0.3:50010
2020-12-01 21:56:18,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43044, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741892_1068, duration: 24430955
2020-12-01 21:56:18,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741892_1068, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741893_1069 src: /172.18.0.4:46306 dest: /172.18.0.3:50010
2020-12-01 21:56:19,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46306, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741893_1069, duration: 1465301
2020-12-01 21:56:19,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741893_1069, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741894_1070 src: /172.18.0.3:43052 dest: /172.18.0.3:50010
2020-12-01 21:56:19,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43052, dest: /172.18.0.3:50010, bytes: 98, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741894_1070, duration: 25799948
2020-12-01 21:56:19,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741894_1070, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741895_1071 src: /172.18.0.4:46314 dest: /172.18.0.3:50010
2020-12-01 21:56:19,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46314, dest: /172.18.0.3:50010, bytes: 81, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741895_1071, duration: 72488018
2020-12-01 21:56:19,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741895_1071, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741896_1072 src: /172.18.0.3:43060 dest: /172.18.0.3:50010
2020-12-01 21:56:19,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43060, dest: /172.18.0.3:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741896_1072, duration: 35033992
2020-12-01 21:56:19,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741896_1072, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741897_1073 src: /172.18.0.4:46322 dest: /172.18.0.3:50010
2020-12-01 21:56:19,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46322, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741897_1073, duration: 10495972
2020-12-01 21:56:19,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741897_1073, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741898_1074 src: /172.18.0.3:43068 dest: /172.18.0.3:50010
2020-12-01 21:56:19,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43068, dest: /172.18.0.3:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741898_1074, duration: 23595011
2020-12-01 21:56:19,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741898_1074, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741899_1075 src: /172.18.0.4:46330 dest: /172.18.0.3:50010
2020-12-01 21:56:19,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46330, dest: /172.18.0.3:50010, bytes: 60, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741899_1075, duration: 3563754
2020-12-01 21:56:19,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741899_1075, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741900_1076 src: /172.18.0.3:43076 dest: /172.18.0.3:50010
2020-12-01 21:56:19,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43076, dest: /172.18.0.3:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741900_1076, duration: 36549557
2020-12-01 21:56:19,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741900_1076, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741901_1077 src: /172.18.0.4:46338 dest: /172.18.0.3:50010
2020-12-01 21:56:20,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46338, dest: /172.18.0.3:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741901_1077, duration: 2341157
2020-12-01 21:56:20,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741901_1077, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741902_1078 src: /172.18.0.3:43084 dest: /172.18.0.3:50010
2020-12-01 21:56:20,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43084, dest: /172.18.0.3:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741902_1078, duration: 26258318
2020-12-01 21:56:20,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741902_1078, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741903_1079 src: /172.18.0.4:46346 dest: /172.18.0.3:50010
2020-12-01 21:56:20,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46346, dest: /172.18.0.3:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741903_1079, duration: 1713629
2020-12-01 21:56:20,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741903_1079, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741904_1080 src: /172.18.0.3:43092 dest: /172.18.0.3:50010
2020-12-01 21:56:20,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43092, dest: /172.18.0.3:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741904_1080, duration: 9810952
2020-12-01 21:56:20,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741904_1080, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741905_1081 src: /172.18.0.4:46354 dest: /172.18.0.3:50010
2020-12-01 21:56:20,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46354, dest: /172.18.0.3:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741905_1081, duration: 1041217
2020-12-01 21:56:20,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741905_1081, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741906_1082 src: /172.18.0.3:43100 dest: /172.18.0.3:50010
2020-12-01 21:56:20,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43100, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741906_1082, duration: 9732535
2020-12-01 21:56:20,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741906_1082, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741908_1084 src: /172.18.0.3:43106 dest: /172.18.0.3:50010
2020-12-01 21:56:20,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741907_1083 src: /172.18.0.4:46366 dest: /172.18.0.3:50010
2020-12-01 21:56:20,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46366, dest: /172.18.0.3:50010, bytes: 55, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741907_1083, duration: 33776066
2020-12-01 21:56:20,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741907_1083, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43106, dest: /172.18.0.3:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741908_1084, duration: 4037099
2020-12-01 21:56:20,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741908_1084, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741909_1085 src: /172.18.0.4:46370 dest: /172.18.0.3:50010
2020-12-01 21:56:20,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741910_1086 src: /172.18.0.3:43116 dest: /172.18.0.3:50010
2020-12-01 21:56:20,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46370, dest: /172.18.0.3:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741909_1085, duration: 9274739
2020-12-01 21:56:20,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741909_1085, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43116, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741910_1086, duration: 26874593
2020-12-01 21:56:21,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741910_1086, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741911_1087 src: /172.18.0.4:46378 dest: /172.18.0.3:50010
2020-12-01 21:56:21,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46378, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741911_1087, duration: 2975533
2020-12-01 21:56:21,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741911_1087, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741912_1088 src: /172.18.0.3:43124 dest: /172.18.0.3:50010
2020-12-01 21:56:21,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43124, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741912_1088, duration: 15234097
2020-12-01 21:56:21,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741912_1088, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741913_1089 src: /172.18.0.4:46386 dest: /172.18.0.3:50010
2020-12-01 21:56:21,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46386, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741913_1089, duration: 4272329
2020-12-01 21:56:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741913_1089, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741914_1090 src: /172.18.0.3:43132 dest: /172.18.0.3:50010
2020-12-01 21:56:21,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43132, dest: /172.18.0.3:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741914_1090, duration: 16477105
2020-12-01 21:56:21,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741914_1090, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741915_1091 src: /172.18.0.4:46394 dest: /172.18.0.3:50010
2020-12-01 21:56:21,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46394, dest: /172.18.0.3:50010, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741915_1091, duration: 1390234
2020-12-01 21:56:21,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741915_1091, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741916_1092 src: /172.18.0.3:43140 dest: /172.18.0.3:50010
2020-12-01 21:56:21,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43140, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741916_1092, duration: 7833569
2020-12-01 21:56:21,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741916_1092, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741917_1093 src: /172.18.0.4:46402 dest: /172.18.0.3:50010
2020-12-01 21:56:21,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46402, dest: /172.18.0.3:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741917_1093, duration: 20246060
2020-12-01 21:56:21,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741917_1093, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741918_1094 src: /172.18.0.3:43148 dest: /172.18.0.3:50010
2020-12-01 21:56:22,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43148, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741918_1094, duration: 30016619
2020-12-01 21:56:22,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741918_1094, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741919_1095 src: /172.18.0.4:46410 dest: /172.18.0.3:50010
2020-12-01 21:56:22,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46410, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741919_1095, duration: 1874043
2020-12-01 21:56:22,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741919_1095, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741920_1096 src: /172.18.0.3:43156 dest: /172.18.0.3:50010
2020-12-01 21:56:22,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43156, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741920_1096, duration: 21157305
2020-12-01 21:56:22,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741920_1096, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741921_1097 src: /172.18.0.4:46418 dest: /172.18.0.3:50010
2020-12-01 21:56:22,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741922_1098 src: /172.18.0.3:43164 dest: /172.18.0.3:50010
2020-12-01 21:56:22,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46418, dest: /172.18.0.3:50010, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741921_1097, duration: 23705255
2020-12-01 21:56:22,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741921_1097, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43164, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741922_1098, duration: 7226331
2020-12-01 21:56:22,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741922_1098, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741923_1099 src: /172.18.0.4:46426 dest: /172.18.0.3:50010
2020-12-01 21:56:22,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46426, dest: /172.18.0.3:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741923_1099, duration: 1296510
2020-12-01 21:56:22,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741923_1099, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741924_1100 src: /172.18.0.3:43172 dest: /172.18.0.3:50010
2020-12-01 21:56:22,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43172, dest: /172.18.0.3:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741924_1100, duration: 22350845
2020-12-01 21:56:22,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741924_1100, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741925_1101 src: /172.18.0.4:46434 dest: /172.18.0.3:50010
2020-12-01 21:56:22,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46434, dest: /172.18.0.3:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741925_1101, duration: 26491352
2020-12-01 21:56:22,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741925_1101, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741926_1102 src: /172.18.0.3:43180 dest: /172.18.0.3:50010
2020-12-01 21:56:22,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43180, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741926_1102, duration: 20335400
2020-12-01 21:56:22,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741926_1102, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741927_1103 src: /172.18.0.4:46442 dest: /172.18.0.3:50010
2020-12-01 21:56:23,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741928_1104 src: /172.18.0.3:43188 dest: /172.18.0.3:50010
2020-12-01 21:56:23,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46442, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741927_1103, duration: 30298195
2020-12-01 21:56:23,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741927_1103, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43188, dest: /172.18.0.3:50010, bytes: 75, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741928_1104, duration: 30862906
2020-12-01 21:56:23,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741928_1104, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741929_1105 src: /172.18.0.4:46450 dest: /172.18.0.3:50010
2020-12-01 21:56:23,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46450, dest: /172.18.0.3:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741929_1105, duration: 4892014
2020-12-01 21:56:23,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741929_1105, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741930_1106 src: /172.18.0.3:43196 dest: /172.18.0.3:50010
2020-12-01 21:56:23,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43196, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741930_1106, duration: 12537056
2020-12-01 21:56:23,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741930_1106, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741931_1107 src: /172.18.0.4:46458 dest: /172.18.0.3:50010
2020-12-01 21:56:23,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46458, dest: /172.18.0.3:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741931_1107, duration: 11143913
2020-12-01 21:56:23,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741931_1107, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741932_1108 src: /172.18.0.3:43204 dest: /172.18.0.3:50010
2020-12-01 21:56:23,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43204, dest: /172.18.0.3:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741932_1108, duration: 43938502
2020-12-01 21:56:23,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741932_1108, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741933_1109 src: /172.18.0.4:46466 dest: /172.18.0.3:50010
2020-12-01 21:56:23,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46466, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741933_1109, duration: 2200236
2020-12-01 21:56:23,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741933_1109, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741934_1110 src: /172.18.0.3:43212 dest: /172.18.0.3:50010
2020-12-01 21:56:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43212, dest: /172.18.0.3:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741934_1110, duration: 21599154
2020-12-01 21:56:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741934_1110, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741935_1111 src: /172.18.0.4:46474 dest: /172.18.0.3:50010
2020-12-01 21:56:23,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46474, dest: /172.18.0.3:50010, bytes: 59, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741935_1111, duration: 7037428
2020-12-01 21:56:23,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741935_1111, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741936_1112 src: /172.18.0.3:43220 dest: /172.18.0.3:50010
2020-12-01 21:56:24,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43220, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741936_1112, duration: 16407879
2020-12-01 21:56:24,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741936_1112, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:24,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741937_1113 src: /172.18.0.4:46482 dest: /172.18.0.3:50010
2020-12-01 21:56:24,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46482, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741937_1113, duration: 770513
2020-12-01 21:56:24,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741937_1113, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:24,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741938_1114 src: /172.18.0.3:43228 dest: /172.18.0.3:50010
2020-12-01 21:56:24,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43228, dest: /172.18.0.3:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741938_1114, duration: 7419477
2020-12-01 21:56:24,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741938_1114, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:24,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741939_1115 src: /172.18.0.4:46490 dest: /172.18.0.3:50010
2020-12-01 21:56:24,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46490, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741939_1115, duration: 1380779
2020-12-01 21:56:24,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741939_1115, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:24,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741940_1116 src: /172.18.0.3:43236 dest: /172.18.0.3:50010
2020-12-01 21:56:24,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43236, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: fe1d07dd-cd9c-47fb-b36f-3eeb662f0a65, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741940_1116, duration: 13990562
2020-12-01 21:56:24,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741940_1116, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:58:26,380 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f497452-c458-446f-86ab-60d052cb01b8): no suitable block pools found to scan.  Waiting 1813760601 ms.
2020-12-02 01:13:38,120 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1191596377-172.18.0.2-1606830456145 Total blocks: 82, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-12-07 21:30:41,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-12-07 21:30:41,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-07 21:30:42,845 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-07 21:30:43,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-07 21:30:43,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-07 21:30:43,008 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-07 21:30:43,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2020-12-07 21:30:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-07 21:30:43,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-07 21:30:43,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-07 21:30:43,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-07 21:30:43,221 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-07 21:30:43,235 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-07 21:30:43,253 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-07 21:30:43,259 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-07 21:30:43,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-07 21:30:43,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-07 21:30:43,264 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-07 21:30:43,284 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35775
2020-12-07 21:30:43,285 INFO org.mortbay.log: jetty-6.1.26
2020-12-07 21:30:43,530 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35775
2020-12-07 21:30:43,669 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-07 21:30:43,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-12-07 21:30:43,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-07 21:30:43,837 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-07 21:30:43,874 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-07 21:30:43,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-07 21:30:43,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-07 21:30:43,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-07 21:30:43,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-12-07 21:30:44,029 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-07 21:30:44,031 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-07 21:30:44,609 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 88@slave1
2020-12-07 21:30:44,610 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,610 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-07 21:30:44,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1798038798-172.18.0.2-1607347834556 is not formatted for BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,725 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-07 21:30:44,725 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1798038798-172.18.0.2-1607347834556 directory /tmp/hadoop/dfs/data/current/BP-1798038798-172.18.0.2-1607347834556/current
2020-12-07 21:30:44,733 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-12-07 21:30:44,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=828757604;bpid=BP-1798038798-172.18.0.2-1607347834556;lv=-56;nsInfo=lv=-63;cid=CID-cc84c8e7-2264-425c-ba9f-37caf69f3ba8;nsid=828757604;c=0;bpid=BP-1798038798-172.18.0.2-1607347834556;dnuuid=null
2020-12-07 21:30:44,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 44394f8f-9265-4f0e-bace-d3b4573d2e26
2020-12-07 21:30:44,796 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b699900e-cd40-477b-9d61-dba43b104704
2020-12-07 21:30:44,796 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-12-07 21:30:44,801 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-07 21:30:44,802 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,803 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data/current...
2020-12-07 21:30:44,814 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1798038798-172.18.0.2-1607347834556 on /tmp/hadoop/dfs/data/current: 10ms
2020-12-07 21:30:44,814 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1798038798-172.18.0.2-1607347834556: 11ms
2020-12-07 21:30:44,815 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data/current...
2020-12-07 21:30:44,815 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-12-07 21:30:44,816 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2020-12-07 21:30:45,014 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data
2020-12-07 21:30:45,018 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): finished scanning block pool BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:45,035 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607349031035 with interval 21600000
2020-12-07 21:30:45,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-12-07 21:30:45,128 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): no suitable block pools found to scan.  Waiting 1814399886 ms.
2020-12-07 21:30:45,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-12-07 21:30:45,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-07 21:30:45,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid 44394f8f-9265-4f0e-bace-d3b4573d2e26) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-12-07 21:30:45,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid 44394f8f-9265-4f0e-bace-d3b4573d2e26) service to master/172.18.0.2:54310
2020-12-07 21:30:45,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2421d380c322,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 89 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-07 21:30:45,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:34:08,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741825_1001 src: /172.18.0.2:38238 dest: /172.18.0.3:50010
2020-12-07 21:34:08,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38238, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741825_1001, duration: 270440691
2020-12-07 21:34:08,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:08,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741826_1002 src: /172.18.0.2:38240 dest: /172.18.0.3:50010
2020-12-07 21:34:08,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38240, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741826_1002, duration: 122651865
2020-12-07 21:34:08,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741828_1004 src: /172.18.0.2:38244 dest: /172.18.0.3:50010
2020-12-07 21:34:09,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38244, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741828_1004, duration: 77812473
2020-12-07 21:34:09,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741830_1006 src: /172.18.0.2:38248 dest: /172.18.0.3:50010
2020-12-07 21:34:09,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38248, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741830_1006, duration: 78813946
2020-12-07 21:34:09,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741834_1010 src: /172.18.0.2:38256 dest: /172.18.0.3:50010
2020-12-07 21:34:10,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38256, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741834_1010, duration: 82047311
2020-12-07 21:34:10,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:10,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741835_1011 src: /172.18.0.2:38258 dest: /172.18.0.3:50010
2020-12-07 21:34:10,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38258, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741835_1011, duration: 53469149
2020-12-07 21:34:10,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:10,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741836_1012 src: /172.18.0.2:38260 dest: /172.18.0.3:50010
2020-12-07 21:34:10,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38260, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741836_1012, duration: 64816775
2020-12-07 21:34:10,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:10,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741840_1016 src: /172.18.0.2:38268 dest: /172.18.0.3:50010
2020-12-07 21:34:10,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38268, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741840_1016, duration: 60353766
2020-12-07 21:34:10,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:36:41,766 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741826_1002 for rescanning.
2020-12-07 21:36:53,905 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741828_1004 for rescanning.
2020-12-07 21:37:04,904 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741830_1006 for rescanning.
2020-12-07 21:37:26,292 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741834_1010 for rescanning.
2020-12-07 21:37:29,124 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741835_1011 for rescanning.
2020-12-07 21:37:38,441 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741836_1012 for rescanning.
2020-12-07 21:38:00,313 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741840_1016 for rescanning.
2020-12-07 21:38:07,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741841_1017 src: /172.18.0.3:59464 dest: /172.18.0.3:50010
2020-12-07 21:38:08,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741842_1018 src: /172.18.0.4:45368 dest: /172.18.0.3:50010
2020-12-07 21:38:08,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59464, dest: /172.18.0.3:50010, bytes: 233, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741841_1017, duration: 81439923
2020-12-07 21:38:08,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45368, dest: /172.18.0.3:50010, bytes: 207, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741842_1018, duration: 67534605
2020-12-07 21:38:08,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741843_1019 src: /172.18.0.3:59472 dest: /172.18.0.3:50010
2020-12-07 21:38:08,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59472, dest: /172.18.0.3:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741843_1019, duration: 22849116
2020-12-07 21:38:08,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741844_1020 src: /172.18.0.4:45376 dest: /172.18.0.3:50010
2020-12-07 21:38:08,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45376, dest: /172.18.0.3:50010, bytes: 210, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741844_1020, duration: 2514761
2020-12-07 21:38:08,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741845_1021 src: /172.18.0.3:59480 dest: /172.18.0.3:50010
2020-12-07 21:38:08,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59480, dest: /172.18.0.3:50010, bytes: 119, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741845_1021, duration: 10451107
2020-12-07 21:38:08,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741846_1022 src: /172.18.0.4:45384 dest: /172.18.0.3:50010
2020-12-07 21:38:08,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45384, dest: /172.18.0.3:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741846_1022, duration: 1639586
2020-12-07 21:38:08,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741847_1023 src: /172.18.0.3:59488 dest: /172.18.0.3:50010
2020-12-07 21:38:08,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59488, dest: /172.18.0.3:50010, bytes: 129, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741847_1023, duration: 15731636
2020-12-07 21:38:08,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741848_1024 src: /172.18.0.4:45392 dest: /172.18.0.3:50010
2020-12-07 21:38:08,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45392, dest: /172.18.0.3:50010, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741848_1024, duration: 25052926
2020-12-07 21:38:08,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741849_1025 src: /172.18.0.3:59496 dest: /172.18.0.3:50010
2020-12-07 21:38:09,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59496, dest: /172.18.0.3:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741849_1025, duration: 25239242
2020-12-07 21:38:09,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741850_1026 src: /172.18.0.4:45400 dest: /172.18.0.3:50010
2020-12-07 21:38:09,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45400, dest: /172.18.0.3:50010, bytes: 88, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741850_1026, duration: 27887393
2020-12-07 21:38:09,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741851_1027 src: /172.18.0.3:59504 dest: /172.18.0.3:50010
2020-12-07 21:38:09,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59504, dest: /172.18.0.3:50010, bytes: 144, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741851_1027, duration: 5627458
2020-12-07 21:38:09,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741852_1028 src: /172.18.0.4:45408 dest: /172.18.0.3:50010
2020-12-07 21:38:09,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45408, dest: /172.18.0.3:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741852_1028, duration: 14250192
2020-12-07 21:38:09,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741853_1029 src: /172.18.0.3:59512 dest: /172.18.0.3:50010
2020-12-07 21:38:09,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59512, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741853_1029, duration: 15611390
2020-12-07 21:38:09,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741854_1030 src: /172.18.0.4:45416 dest: /172.18.0.3:50010
2020-12-07 21:38:09,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45416, dest: /172.18.0.3:50010, bytes: 193, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741854_1030, duration: 12179248
2020-12-07 21:38:09,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741855_1031 src: /172.18.0.3:59520 dest: /172.18.0.3:50010
2020-12-07 21:38:09,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:59520, dest: /172.18.0.3:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741855_1031, duration: 2178869
2020-12-07 21:38:09,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741856_1032 src: /172.18.0.4:45424 dest: /172.18.0.3:50010
2020-12-07 21:38:09,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45424, dest: /172.18.0.3:50010, bytes: 87, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 44394f8f-9265-4f0e-bace-d3b4573d2e26, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741856_1032, duration: 19971434
2020-12-07 21:38:09,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:34,269 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b699900e-cd40-477b-9d61-dba43b104704): no suitable block pools found to scan.  Waiting 1813930745 ms.
2020-12-07 21:50:31,071 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1798038798-172.18.0.2-1607347834556 Total blocks: 24, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-01-23 18:13:16,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:13:16,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:13:17,892 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:13:18,013 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:13:18,013 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:13:18,017 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:13:18,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:13:18,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:13:18,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:13:18,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:13:18,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:13:18,231 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:13:18,239 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:13:18,258 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:13:18,264 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:13:18,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:13:18,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:13:18,267 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:13:18,284 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41571
2021-01-23 18:13:18,284 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:13:18,491 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41571
2021-01-23 18:13:18,663 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:13:19,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:13:19,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:13:19,096 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:13:19,116 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:13:19,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:13:19,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:13:19,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:13:19,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:13:19,260 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:13:19,289 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:13:19,659 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 143@slave1
2021-01-23 18:13:19,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:13:19,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-661382008-172.18.0.2-1611425590339 is not formatted for BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:13:19,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-661382008-172.18.0.2-1611425590339 directory /tmp/hadoop/dfs/data/current/BP-661382008-172.18.0.2-1611425590339/current
2021-01-23 18:13:19,725 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:13:19,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=941365349;bpid=BP-661382008-172.18.0.2-1611425590339;lv=-56;nsInfo=lv=-63;cid=CID-fe118d50-7a06-4140-920f-c73a086893b7;nsid=941365349;c=0;bpid=BP-661382008-172.18.0.2-1611425590339;dnuuid=null
2021-01-23 18:13:19,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 3b65bbab-e49a-4017-aece-5b34c34350bb
2021-01-23 18:13:19,763 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-45f34548-a5e0-4de1-9e6c-dbcc77e9ca4e
2021-01-23 18:13:19,763 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:13:19,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:13:19,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,767 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:13:19,774 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-661382008-172.18.0.2-1611425590339 on /tmp/hadoop/dfs/data/current: 6ms
2021-01-23 18:13:19,774 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-661382008-172.18.0.2-1611425590339: 7ms
2021-01-23 18:13:19,774 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:13:19,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:13:19,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-01-23 18:13:19,914 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data
2021-01-23 18:13:19,914 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-45f34548-a5e0-4de1-9e6c-dbcc77e9ca4e): finished scanning block pool BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,937 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611429675937 with interval 21600000
2021-01-23 18:13:19,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:13:19,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:13:19,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:13:19,985 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-45f34548-a5e0-4de1-9e6c-dbcc77e9ca4e): no suitable block pools found to scan.  Waiting 1814399929 ms.
2021-01-23 18:13:20,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid 3b65bbab-e49a-4017-aece-5b34c34350bb) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:13:20,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid 3b65bbab-e49a-4017-aece-5b34c34350bb) service to master/172.18.0.2:54310
2021-01-23 18:13:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e1646813f44,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 37 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:13:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:14:13,234 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave1/172.18.0.3"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2021-01-23 18:14:16,973 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-01-23 18:14:16,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave1/172.18.0.3
************************************************************/
2021-01-23 18:15:06,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:15:06,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:15:07,087 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:15:07,188 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:15:07,188 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:15:07,191 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:15:07,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:15:07,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:15:07,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:15:07,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:15:07,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:15:07,360 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:15:07,367 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:15:07,386 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:15:07,390 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:15:07,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:15:07,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:15:07,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:15:07,400 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41171
2021-01-23 18:15:07,400 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:15:07,591 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41171
2021-01-23 18:15:07,691 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:15:08,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:15:08,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:15:08,122 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:15:08,146 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:15:08,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:15:08,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:15:08,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:15:08,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:15:08,283 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:15:08,312 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:15:08,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 344@slave1
2021-01-23 18:15:08,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:15:08,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-466924295-172.18.0.2-1611425699514 is not formatted for BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:15:08,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-466924295-172.18.0.2-1611425699514 directory /tmp/hadoop/dfs/data/current/BP-466924295-172.18.0.2-1611425699514/current
2021-01-23 18:15:08,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:15:08,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=767045300;bpid=BP-466924295-172.18.0.2-1611425699514;lv=-56;nsInfo=lv=-63;cid=CID-07353671-4518-42c4-b437-17e5e4081e03;nsid=767045300;c=0;bpid=BP-466924295-172.18.0.2-1611425699514;dnuuid=null
2021-01-23 18:15:08,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 605c1f7c-76c7-4402-917d-3d946fa601c1
2021-01-23 18:15:08,823 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-eb597a00-1cea-4c90-84ae-9517edae9ac2
2021-01-23 18:15:08,824 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:15:08,828 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:15:08,828 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,829 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:15:08,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-466924295-172.18.0.2-1611425699514 on /tmp/hadoop/dfs/data/current: 6ms
2021-01-23 18:15:08,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-466924295-172.18.0.2-1611425699514: 8ms
2021-01-23 18:15:08,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:15:08,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:15:08,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-01-23 18:15:09,014 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data
2021-01-23 18:15:09,015 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-eb597a00-1cea-4c90-84ae-9517edae9ac2): finished scanning block pool BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:09,030 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611443215030 with interval 21600000
2021-01-23 18:15:09,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:15:09,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:15:09,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:15:09,097 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-eb597a00-1cea-4c90-84ae-9517edae9ac2): no suitable block pools found to scan.  Waiting 1814399917 ms.
2021-01-23 18:15:09,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid 605c1f7c-76c7-4402-917d-3d946fa601c1) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:15:09,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid 605c1f7c-76c7-4402-917d-3d946fa601c1) service to master/172.18.0.2:54310
2021-01-23 18:15:09,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e2faf4bde3c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 55 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:15:09,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:16:33,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741826_1002 src: /172.18.0.2:43510 dest: /172.18.0.3:50010
2021-01-23 18:16:34,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:43510, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 605c1f7c-76c7-4402-917d-3d946fa601c1, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741826_1002, duration: 323061269
2021-01-23 18:16:34,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741830_1006 src: /172.18.0.2:43518 dest: /172.18.0.3:50010
2021-01-23 18:16:34,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:43518, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 605c1f7c-76c7-4402-917d-3d946fa601c1, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741830_1006, duration: 83514439
2021-01-23 18:16:34,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741834_1010 src: /172.18.0.2:43526 dest: /172.18.0.3:50010
2021-01-23 18:16:35,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:43526, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 605c1f7c-76c7-4402-917d-3d946fa601c1, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741834_1010, duration: 52336050
2021-01-23 18:16:35,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:35,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741836_1012 src: /172.18.0.2:43530 dest: /172.18.0.3:50010
2021-01-23 18:16:35,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:43530, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 605c1f7c-76c7-4402-917d-3d946fa601c1, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741836_1012, duration: 60371447
2021-01-23 18:16:35,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:35,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741837_1013 src: /172.18.0.2:43532 dest: /172.18.0.3:50010
2021-01-23 18:16:35,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:43532, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 605c1f7c-76c7-4402-917d-3d946fa601c1, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741837_1013, duration: 66507825
2021-01-23 18:16:35,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:35,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741838_1014 src: /172.18.0.2:43534 dest: /172.18.0.3:50010
2021-01-23 18:16:35,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:43534, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 605c1f7c-76c7-4402-917d-3d946fa601c1, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741838_1014, duration: 44701162
2021-01-23 18:16:35,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:19:05,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:19:05,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:19:06,146 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:19:06,243 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:19:06,244 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:19:06,248 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:19:06,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:19:06,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:19:06,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-01-23 18:19:06,324 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:721)
	at org.apache.hadoop.ipc.Server.bind(Server.java:425)
	at org.apache.hadoop.ipc.Server.bind(Server.java:397)
	at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:111)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:893)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1107)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:428)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2373)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2260)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2307)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2484)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2508)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.apache.hadoop.ipc.Server.bind(Server.java:408)
	... 10 more
2021-01-23 18:19:06,327 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-01-23 18:19:06,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave1/172.18.0.3
************************************************************/
2021-01-23 18:19:50,255 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "slave1/172.18.0.3"; destination host is: "master":54310; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2021-01-23 18:19:54,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:55,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:56,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:57,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:58,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:59,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:00,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:01,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:02,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:03,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:03,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From slave1/172.18.0.3 to master:54310 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2021-01-23 18:20:04,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:33,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:20:33,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:20:34,824 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:20:34,927 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:20:34,928 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:20:34,931 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:20:34,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:20:34,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:20:34,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:20:34,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:20:34,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:20:35,098 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:20:35,120 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:20:35,124 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:20:35,129 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:20:35,131 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:20:35,131 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:20:35,131 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:20:35,154 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37731
2021-01-23 18:20:35,154 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:20:35,351 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37731
2021-01-23 18:20:35,448 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:20:35,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:20:35,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:20:35,893 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:20:35,938 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:20:35,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:20:35,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:20:36,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:20:36,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:20:36,038 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:20:36,080 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:20:37,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:38,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:39,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:40,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:41,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:42,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:43,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:44,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:45,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:46,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:46,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:20:52,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:53,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:54,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:55,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:56,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:57,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:58,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:59,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:00,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:01,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:01,208 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:07,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:08,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:09,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:10,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:11,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:12,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:13,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:14,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:15,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:16,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:16,228 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:22,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:23,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:24,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:25,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:26,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:27,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:28,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:29,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:30,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:31,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:31,246 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:37,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:38,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:39,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:40,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:41,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:42,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:43,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:44,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:45,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:46,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:46,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:52,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:53,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:54,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:55,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:56,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:57,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:58,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:59,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:00,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:01,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:01,284 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:22:07,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:08,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:09,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:10,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:11,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:12,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:13,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:14,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:15,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:16,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:16,304 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:22:19,274 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-01-23 18:22:19,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave1/172.18.0.3
************************************************************/
2021-01-23 18:22:53,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:22:53,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:22:54,968 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:22:55,055 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:22:55,055 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:22:55,059 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:22:55,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:22:55,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:22:55,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:22:55,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:22:55,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:22:55,224 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:22:55,231 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:22:55,250 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:22:55,254 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:22:55,255 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:22:55,255 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:22:55,256 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:22:55,264 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46131
2021-01-23 18:22:55,264 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:22:55,475 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46131
2021-01-23 18:22:55,582 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:22:55,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:22:55,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:22:56,016 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:22:56,040 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:22:56,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:22:56,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:22:56,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:22:56,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:22:56,151 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:22:56,184 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:22:56,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 871@slave1
2021-01-23 18:22:56,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:22:56,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-876748488-172.18.0.2-1611426167385 is not formatted for BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:22:56,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-876748488-172.18.0.2-1611426167385 directory /tmp/hadoop/dfs/data/current/BP-876748488-172.18.0.2-1611426167385/current
2021-01-23 18:22:56,630 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:22:56,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=460839116;bpid=BP-876748488-172.18.0.2-1611426167385;lv=-56;nsInfo=lv=-63;cid=CID-83b1748a-0185-426e-8406-b2e797cd3ba0;nsid=460839116;c=0;bpid=BP-876748488-172.18.0.2-1611426167385;dnuuid=null
2021-01-23 18:22:56,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 74907d78-11c8-417d-af02-d3ca0173a0d4
2021-01-23 18:22:56,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-da105129-fbb2-4565-a78d-d01b4dc863fb
2021-01-23 18:22:56,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:22:56,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:22:56,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,711 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:22:56,735 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-876748488-172.18.0.2-1611426167385 on /tmp/hadoop/dfs/data/current: 23ms
2021-01-23 18:22:56,735 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-876748488-172.18.0.2-1611426167385: 41ms
2021-01-23 18:22:56,736 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:22:56,736 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:22:56,736 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-01-23 18:22:56,857 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data
2021-01-23 18:22:56,858 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-da105129-fbb2-4565-a78d-d01b4dc863fb): finished scanning block pool BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,865 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611437311865 with interval 21600000
2021-01-23 18:22:56,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:22:56,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:22:56,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:22:56,948 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-da105129-fbb2-4565-a78d-d01b4dc863fb): no suitable block pools found to scan.  Waiting 1814399909 ms.
2021-01-23 18:22:56,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid 74907d78-11c8-417d-af02-d3ca0173a0d4) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:22:56,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid 74907d78-11c8-417d-af02-d3ca0173a0d4) service to master/172.18.0.2:54310
2021-01-23 18:22:57,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e9c99d8bd69,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:22:57,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:32:56,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:32:56,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:32:57,141 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:32:57,230 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:32:57,230 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:32:57,234 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:32:57,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:32:57,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:32:57,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:32:57,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:32:57,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:32:57,440 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:32:57,448 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:32:57,466 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:32:57,471 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:32:57,473 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:32:57,473 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:32:57,474 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:32:57,494 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35329
2021-01-23 18:32:57,494 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:32:57,724 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35329
2021-01-23 18:32:57,849 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:32:58,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:32:58,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:32:58,323 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:32:58,364 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:32:58,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:32:58,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:32:58,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:32:58,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:32:58,544 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:32:58,564 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:32:59,025 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 43@slave1
2021-01-23 18:32:59,026 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,026 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:32:59,098 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,098 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,098 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1299640566-172.18.0.2-1611426769503 is not formatted for BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,098 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:32:59,098 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1299640566-172.18.0.2-1611426769503 directory /tmp/hadoop/dfs/data/current/BP-1299640566-172.18.0.2-1611426769503/current
2021-01-23 18:32:59,100 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:32:59,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=629590770;bpid=BP-1299640566-172.18.0.2-1611426769503;lv=-56;nsInfo=lv=-63;cid=CID-f5bdc4db-1e67-4bfa-b5be-12664398e087;nsid=629590770;c=0;bpid=BP-1299640566-172.18.0.2-1611426769503;dnuuid=null
2021-01-23 18:32:59,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 255eec5f-6ad0-45d0-bc3d-f0dcf406478f
2021-01-23 18:32:59,169 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b5da0522-a7f0-4cc3-b669-8919a14503e6
2021-01-23 18:32:59,169 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:32:59,188 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:32:59,188 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,189 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:32:59,220 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1299640566-172.18.0.2-1611426769503 on /tmp/hadoop/dfs/data/current: 30ms
2021-01-23 18:32:59,220 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1299640566-172.18.0.2-1611426769503: 31ms
2021-01-23 18:32:59,220 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:32:59,221 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:32:59,221 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-01-23 18:32:59,357 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data
2021-01-23 18:32:59,358 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): finished scanning block pool BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,381 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611441398381 with interval 21600000
2021-01-23 18:32:59,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:32:59,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:32:59,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:32:59,437 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): no suitable block pools found to scan.  Waiting 1814399920 ms.
2021-01-23 18:32:59,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid 255eec5f-6ad0-45d0-bc3d-f0dcf406478f) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:32:59,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid 255eec5f-6ad0-45d0-bc3d-f0dcf406478f) service to master/172.18.0.2:54310
2021-01-23 18:32:59,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2f28e105fbcc,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:32:59,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:35:19,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741825_1001 src: /172.18.0.2:44300 dest: /172.18.0.3:50010
2021-01-23 18:35:19,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44300, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741825_1001, duration: 220385407
2021-01-23 18:35:19,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:19,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741827_1003 src: /172.18.0.2:44304 dest: /172.18.0.3:50010
2021-01-23 18:35:20,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44304, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741827_1003, duration: 91167193
2021-01-23 18:35:20,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741828_1004 src: /172.18.0.2:44306 dest: /172.18.0.3:50010
2021-01-23 18:35:20,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44306, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741828_1004, duration: 64359052
2021-01-23 18:35:20,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741830_1006 src: /172.18.0.2:44310 dest: /172.18.0.3:50010
2021-01-23 18:35:20,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44310, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741830_1006, duration: 55359071
2021-01-23 18:35:20,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741831_1007 src: /172.18.0.2:44312 dest: /172.18.0.3:50010
2021-01-23 18:35:20,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44312, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741831_1007, duration: 54651781
2021-01-23 18:35:20,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741832_1008 src: /172.18.0.2:44314 dest: /172.18.0.3:50010
2021-01-23 18:35:20,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44314, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741832_1008, duration: 42136904
2021-01-23 18:35:20,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741833_1009 src: /172.18.0.2:44316 dest: /172.18.0.3:50010
2021-01-23 18:35:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44316, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741833_1009, duration: 39252917
2021-01-23 18:35:20,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741834_1010 src: /172.18.0.2:44318 dest: /172.18.0.3:50010
2021-01-23 18:35:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44318, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741834_1010, duration: 74775714
2021-01-23 18:35:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741836_1012 src: /172.18.0.2:44322 dest: /172.18.0.3:50010
2021-01-23 18:35:20,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44322, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741836_1012, duration: 60227240
2021-01-23 18:35:20,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741837_1013 src: /172.18.0.2:44324 dest: /172.18.0.3:50010
2021-01-23 18:35:20,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44324, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741837_1013, duration: 80803158
2021-01-23 18:35:20,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:48,981 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741827_1003 for rescanning.
2021-01-23 18:35:55,464 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741828_1004 for rescanning.
2021-01-23 18:36:01,312 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741830_1006 for rescanning.
2021-01-23 18:36:01,693 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741831_1007 for rescanning.
2021-01-23 18:36:07,042 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741832_1008 for rescanning.
2021-01-23 18:36:08,562 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741833_1009 for rescanning.
2021-01-23 18:36:13,248 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741834_1010 for rescanning.
2021-01-23 18:36:19,484 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741836_1012 for rescanning.
2021-01-23 18:36:20,525 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741837_1013 for rescanning.
2021-01-23 18:36:35,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741841_1017 src: /172.18.0.4:50014 dest: /172.18.0.3:50010
2021-01-23 18:36:35,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741842_1018 src: /172.18.0.3:44452 dest: /172.18.0.3:50010
2021-01-23 18:36:35,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50014, dest: /172.18.0.3:50010, bytes: 233, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741841_1017, duration: 53952713
2021-01-23 18:36:35,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:35,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44452, dest: /172.18.0.3:50010, bytes: 207, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741842_1018, duration: 18046118
2021-01-23 18:36:35,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:35,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741843_1019 src: /172.18.0.3:44458 dest: /172.18.0.3:50010
2021-01-23 18:36:36,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741844_1020 src: /172.18.0.4:50024 dest: /172.18.0.3:50010
2021-01-23 18:36:36,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44458, dest: /172.18.0.3:50010, bytes: 210, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741843_1019, duration: 31524598
2021-01-23 18:36:36,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50024, dest: /172.18.0.3:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741844_1020, duration: 28664635
2021-01-23 18:36:36,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741845_1021 src: /172.18.0.3:44466 dest: /172.18.0.3:50010
2021-01-23 18:36:36,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741846_1022 src: /172.18.0.4:50032 dest: /172.18.0.3:50010
2021-01-23 18:36:36,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44466, dest: /172.18.0.3:50010, bytes: 119, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741845_1021, duration: 9809064
2021-01-23 18:36:36,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50032, dest: /172.18.0.3:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741846_1022, duration: 58281360
2021-01-23 18:36:36,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741847_1023 src: /172.18.0.3:44474 dest: /172.18.0.3:50010
2021-01-23 18:36:36,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44474, dest: /172.18.0.3:50010, bytes: 129, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741847_1023, duration: 4113799
2021-01-23 18:36:36,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741848_1024 src: /172.18.0.4:50040 dest: /172.18.0.3:50010
2021-01-23 18:36:36,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50040, dest: /172.18.0.3:50010, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741848_1024, duration: 1300342
2021-01-23 18:36:36,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741849_1025 src: /172.18.0.3:44482 dest: /172.18.0.3:50010
2021-01-23 18:36:36,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44482, dest: /172.18.0.3:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741849_1025, duration: 20368504
2021-01-23 18:36:36,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741850_1026 src: /172.18.0.4:50048 dest: /172.18.0.3:50010
2021-01-23 18:36:36,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50048, dest: /172.18.0.3:50010, bytes: 88, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741850_1026, duration: 11544028
2021-01-23 18:36:36,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741851_1027 src: /172.18.0.3:44490 dest: /172.18.0.3:50010
2021-01-23 18:36:36,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44490, dest: /172.18.0.3:50010, bytes: 144, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741851_1027, duration: 21225877
2021-01-23 18:36:36,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741852_1028 src: /172.18.0.4:50056 dest: /172.18.0.3:50010
2021-01-23 18:36:36,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50056, dest: /172.18.0.3:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741852_1028, duration: 4843661
2021-01-23 18:36:36,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741853_1029 src: /172.18.0.3:44498 dest: /172.18.0.3:50010
2021-01-23 18:36:36,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44498, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741853_1029, duration: 11884675
2021-01-23 18:36:36,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:37,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741854_1030 src: /172.18.0.4:50064 dest: /172.18.0.3:50010
2021-01-23 18:36:37,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50064, dest: /172.18.0.3:50010, bytes: 193, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741854_1030, duration: 12379250
2021-01-23 18:36:37,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:37,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741855_1031 src: /172.18.0.3:44506 dest: /172.18.0.3:50010
2021-01-23 18:36:37,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44506, dest: /172.18.0.3:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741855_1031, duration: 8288548
2021-01-23 18:36:37,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:37,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741856_1032 src: /172.18.0.4:50072 dest: /172.18.0.3:50010
2021-01-23 18:36:37,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:50072, dest: /172.18.0.3:50010, bytes: 87, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 255eec5f-6ad0-45d0-bc3d-f0dcf406478f, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741856_1032, duration: 10556296
2021-01-23 18:36:37,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:38:13,985 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b5da0522-a7f0-4cc3-b669-8919a14503e6): no suitable block pools found to scan.  Waiting 1814085372 ms.
2021-01-23 18:43:23,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:43:23,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:43:24,281 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:43:24,372 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:43:24,372 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:43:24,375 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:43:24,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-23 18:43:24,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:43:24,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:43:24,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:43:24,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:43:24,555 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:43:24,563 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:43:24,582 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:43:24,586 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:43:24,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:43:24,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:43:24,587 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:43:24,596 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44893
2021-01-23 18:43:24,596 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:43:24,783 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44893
2021-01-23 18:43:24,906 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:43:25,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:43:25,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:43:25,347 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:43:25,371 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:43:25,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:43:25,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:43:25,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:43:25,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:43:25,494 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:43:25,504 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:43:25,921 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2021-01-23 18:43:25,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:25,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:43:26,004 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,004 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,005 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1520537408-172.18.0.2-1611427396672 is not formatted for BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,005 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:43:26,006 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1520537408-172.18.0.2-1611427396672 directory /tmp/hadoop/dfs/data/current/BP-1520537408-172.18.0.2-1611427396672/current
2021-01-23 18:43:26,009 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:43:26,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1020823805;bpid=BP-1520537408-172.18.0.2-1611427396672;lv=-56;nsInfo=lv=-63;cid=CID-1b155ced-ce84-468a-b3c8-042c1a2a88cf;nsid=1020823805;c=0;bpid=BP-1520537408-172.18.0.2-1611427396672;dnuuid=null
2021-01-23 18:43:26,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 24d6c4b1-3ada-42dc-bf92-9e436eb6d372
2021-01-23 18:43:26,075 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-be9fc9bd-ae4d-4165-afcf-693f4f3a0cfb
2021-01-23 18:43:26,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:43:26,090 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:43:26,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,107 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:43:26,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1520537408-172.18.0.2-1611427396672 on /tmp/hadoop/dfs/data/current: 22ms
2021-01-23 18:43:26,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1520537408-172.18.0.2-1611427396672: 40ms
2021-01-23 18:43:26,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:43:26,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data/current: 1ms
2021-01-23 18:43:26,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2021-01-23 18:43:26,308 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data
2021-01-23 18:43:26,309 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-be9fc9bd-ae4d-4165-afcf-693f4f3a0cfb): finished scanning block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,324 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611443295324 with interval 21600000
2021-01-23 18:43:26,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:43:26,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:43:26,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:43:26,391 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-be9fc9bd-ae4d-4165-afcf-693f4f3a0cfb): no suitable block pools found to scan.  Waiting 1814399917 ms.
2021-01-23 18:43:26,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid 24d6c4b1-3ada-42dc-bf92-9e436eb6d372) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:43:26,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid 24d6c4b1-3ada-42dc-bf92-9e436eb6d372) service to master/172.18.0.2:54310
2021-01-23 18:43:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2fbadd5c436a,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:43:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:44:07,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741825_1001 src: /172.18.0.2:44636 dest: /172.18.0.3:50010
2021-01-23 18:44:08,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44636, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741825_1001, duration: 214681149
2021-01-23 18:44:08,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741826_1002 src: /172.18.0.2:44638 dest: /172.18.0.3:50010
2021-01-23 18:44:08,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44638, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741826_1002, duration: 76853740
2021-01-23 18:44:08,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741828_1004 src: /172.18.0.2:44642 dest: /172.18.0.3:50010
2021-01-23 18:44:08,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44642, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741828_1004, duration: 45885061
2021-01-23 18:44:08,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741830_1006 src: /172.18.0.2:44646 dest: /172.18.0.3:50010
2021-01-23 18:44:08,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44646, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741830_1006, duration: 59556112
2021-01-23 18:44:08,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741832_1008 src: /172.18.0.2:44650 dest: /172.18.0.3:50010
2021-01-23 18:44:08,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44650, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741832_1008, duration: 39277052
2021-01-23 18:44:08,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:09,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741837_1013 src: /172.18.0.2:44660 dest: /172.18.0.3:50010
2021-01-23 18:44:09,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44660, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741837_1013, duration: 63487184
2021-01-23 18:44:09,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:09,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741838_1014 src: /172.18.0.2:44662 dest: /172.18.0.3:50010
2021-01-23 18:44:09,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44662, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741838_1014, duration: 69567301
2021-01-23 18:44:09,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:09,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741839_1015 src: /172.18.0.2:44664 dest: /172.18.0.3:50010
2021-01-23 18:44:09,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44664, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 24d6c4b1-3ada-42dc-bf92-9e436eb6d372, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741839_1015, duration: 37417250
2021-01-23 18:44:09,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:41,425 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-be9fc9bd-ae4d-4165-afcf-693f4f3a0cfb): Scheduling suspect block BP-1520537408-172.18.0.2-1611427396672:blk_1073741826_1002 for rescanning.
2021-01-23 18:44:57,429 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-be9fc9bd-ae4d-4165-afcf-693f4f3a0cfb): no suitable block pools found to scan.  Waiting 1814308879 ms.
2021-01-23 20:02:16,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3408267b77d5,  containing 1 storage report(s), of which we sent 1. The reports had 8 total blocks and used 1 RPC(s). This took 2 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 20:02:16,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-27 08:53:33,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-27 08:53:33,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-27 08:53:34,396 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-27 08:53:34,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-27 08:53:34,506 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-27 08:53:34,509 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-27 08:53:34,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2021-01-27 08:53:34,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-27 08:53:34,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-27 08:53:34,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-27 08:53:34,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-27 08:53:34,636 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-27 08:53:34,644 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-27 08:53:34,648 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-27 08:53:34,652 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-27 08:53:34,659 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-27 08:53:34,659 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-27 08:53:34,664 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-27 08:53:34,671 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34615
2021-01-27 08:53:34,672 INFO org.mortbay.log: jetty-6.1.26
2021-01-27 08:53:34,829 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34615
2021-01-27 08:53:34,936 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-27 08:53:35,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-27 08:53:35,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-27 08:53:35,345 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-27 08:53:35,390 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-27 08:53:35,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-27 08:53:35,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-27 08:53:35,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-27 08:53:35,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-27 08:53:35,493 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-27 08:53:35,512 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-27 08:53:35,968 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2021-01-27 08:53:35,969 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:35,969 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-27 08:53:36,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,042 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,042 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-798846186-172.18.0.2-1611737607458 is not formatted for BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,042 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-27 08:53:36,042 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-798846186-172.18.0.2-1611737607458 directory /tmp/hadoop/dfs/data/current/BP-798846186-172.18.0.2-1611737607458/current
2021-01-27 08:53:36,047 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-27 08:53:36,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1826582023;bpid=BP-798846186-172.18.0.2-1611737607458;lv=-56;nsInfo=lv=-63;cid=CID-ae6077e4-015e-44b3-8712-a06ddf744854;nsid=1826582023;c=0;bpid=BP-798846186-172.18.0.2-1611737607458;dnuuid=null
2021-01-27 08:53:36,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID ee7f03f5-730f-401b-9fda-1996325e676f
2021-01-27 08:53:36,105 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-2eb468b7-4105-46da-803c-4121f2f4da49
2021-01-27 08:53:36,106 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-27 08:53:36,117 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-27 08:53:36,117 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data/current...
2021-01-27 08:53:36,159 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-798846186-172.18.0.2-1611737607458 on /tmp/hadoop/dfs/data/current: 34ms
2021-01-27 08:53:36,159 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-798846186-172.18.0.2-1611737607458: 42ms
2021-01-27 08:53:36,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data/current...
2021-01-27 08:53:36,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-27 08:53:36,165 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 6ms
2021-01-27 08:53:36,315 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data
2021-01-27 08:53:36,316 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-2eb468b7-4105-46da-803c-4121f2f4da49): finished scanning block pool BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,331 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611756389331 with interval 21600000
2021-01-27 08:53:36,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-27 08:53:36,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-27 08:53:36,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-27 08:53:36,384 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-2eb468b7-4105-46da-803c-4121f2f4da49): no suitable block pools found to scan.  Waiting 1814399927 ms.
2021-01-27 08:53:36,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid ee7f03f5-730f-401b-9fda-1996325e676f) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-27 08:53:36,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid ee7f03f5-730f-401b-9fda-1996325e676f) service to master/172.18.0.2:54310
2021-01-27 08:53:36,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4d7f7484a873,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-27 08:53:36,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-798846186-172.18.0.2-1611737607458
2022-12-18 08:03:53,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2022-12-18 08:03:53,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-18 08:03:53,889 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-18 08:03:53,984 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2022-12-18 08:03:53,984 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-18 08:03:54,007 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-18 08:03:54,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2022-12-18 08:03:54,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-18 08:03:54,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-18 08:03:54,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2022-12-18 08:03:54,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2022-12-18 08:03:54,126 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-18 08:03:54,130 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-18 08:03:54,137 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-18 08:03:54,143 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-18 08:03:54,157 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-18 08:03:54,157 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-18 08:03:54,157 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-18 08:03:54,164 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37097
2022-12-18 08:03:54,164 INFO org.mortbay.log: jetty-6.1.26
2022-12-18 08:03:54,334 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37097
2022-12-18 08:03:54,465 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-18 08:03:54,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-12-18 08:03:54,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-18 08:03:54,807 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2022-12-18 08:03:54,855 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-18 08:03:54,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-18 08:03:54,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-18 08:03:54,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-18 08:03:54,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2022-12-18 08:03:54,938 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-18 08:03:54,946 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-18 08:03:55,313 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2022-12-18 08:03:55,314 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,314 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:03:55,367 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,367 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,368 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1689137157-172.18.0.2-1671350626907 is not formatted for BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,368 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:03:55,368 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1689137157-172.18.0.2-1671350626907 directory /tmp/hadoop/dfs/data/current/BP-1689137157-172.18.0.2-1671350626907/current
2022-12-18 08:03:55,371 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2022-12-18 08:03:55,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=986042096;bpid=BP-1689137157-172.18.0.2-1671350626907;lv=-56;nsInfo=lv=-63;cid=CID-52e7924c-17d4-4d95-8d84-341aece6ea1a;nsid=986042096;c=0;bpid=BP-1689137157-172.18.0.2-1671350626907;dnuuid=null
2022-12-18 08:03:55,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 8cffac09-1eba-45bf-b915-43df748e02f4
2022-12-18 08:03:55,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d
2022-12-18 08:03:55,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2022-12-18 08:03:55,433 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-18 08:03:55,433 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,434 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:03:55,479 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1689137157-172.18.0.2-1671350626907 on /tmp/hadoop/dfs/data/current: 45ms
2022-12-18 08:03:55,479 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1689137157-172.18.0.2-1671350626907: 46ms
2022-12-18 08:03:55,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:03:55,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data/current: 0ms
2022-12-18 08:03:55,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2022-12-18 08:03:55,609 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data
2022-12-18 08:03:55,610 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): finished scanning block pool BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,627 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1671368761627 with interval 21600000
2022-12-18 08:03:55,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2022-12-18 08:03:55,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2022-12-18 08:03:55,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-18 08:03:55,689 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): no suitable block pools found to scan.  Waiting 1814399920 ms.
2022-12-18 08:03:55,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid 8cffac09-1eba-45bf-b915-43df748e02f4) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2022-12-18 08:03:55,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid 8cffac09-1eba-45bf-b915-43df748e02f4) service to master/172.18.0.2:54310
2022-12-18 08:03:55,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3c848790a415,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 37 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-18 08:03:55,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:06:05,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002 src: /172.18.0.2:37748 dest: /172.18.0.3:50010
2022-12-18 08:06:05,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:37748, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002, duration: 133729926
2022-12-18 08:06:05,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:06:05,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741829_1005 src: /172.18.0.2:37758 dest: /172.18.0.3:50010
2022-12-18 08:06:05,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:37758, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741829_1005, duration: 62523472
2022-12-18 08:06:05,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:06:05,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741832_1008 src: /172.18.0.2:37768 dest: /172.18.0.3:50010
2022-12-18 08:06:05,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:37768, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741832_1008, duration: 52776508
2022-12-18 08:06:05,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:11:47,686 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002 for rescanning.
2022-12-18 08:11:48,046 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002 for rescanning, because we rescanned it recently.
2022-12-18 08:11:48,142 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002 for rescanning, because we rescanned it recently.
2022-12-18 08:11:48,234 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002 for rescanning, because we rescanned it recently.
2022-12-18 08:12:03,711 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): no suitable block pools found to scan.  Waiting 1813911898 ms.
2022-12-18 08:14:21,031 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741826_1002 for rescanning, because we rescanned it recently.
2022-12-18 08:14:25,300 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741829_1005 for rescanning.
2022-12-18 08:14:32,036 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741832_1008 for rescanning.
2022-12-18 08:14:34,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741833_1009 src: /172.18.0.4:35286 dest: /172.18.0.3:50010
2022-12-18 08:14:34,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:35286, dest: /172.18.0.3:50010, bytes: 319, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741833_1009, duration: 70587870
2022-12-18 08:14:34,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741834_1010 src: /172.18.0.3:42540 dest: /172.18.0.3:50010
2022-12-18 08:14:34,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42540, dest: /172.18.0.3:50010, bytes: 274, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741834_1010, duration: 20412875
2022-12-18 08:14:34,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741835_1011 src: /172.18.0.4:35296 dest: /172.18.0.3:50010
2022-12-18 08:14:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:35296, dest: /172.18.0.3:50010, bytes: 247, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741835_1011, duration: 1022558
2022-12-18 08:14:34,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741836_1012 src: /172.18.0.3:42556 dest: /172.18.0.3:50010
2022-12-18 08:14:34,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42556, dest: /172.18.0.3:50010, bytes: 313, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741836_1012, duration: 2275228
2022-12-18 08:14:34,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741837_1013 src: /172.18.0.4:35312 dest: /172.18.0.3:50010
2022-12-18 08:14:34,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:35312, dest: /172.18.0.3:50010, bytes: 195, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741837_1013, duration: 2801738
2022-12-18 08:14:34,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741838_1014 src: /172.18.0.3:42566 dest: /172.18.0.3:50010
2022-12-18 08:14:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42566, dest: /172.18.0.3:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741838_1014, duration: 3827156
2022-12-18 08:14:34,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741839_1015 src: /172.18.0.4:35322 dest: /172.18.0.3:50010
2022-12-18 08:14:34,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:35322, dest: /172.18.0.3:50010, bytes: 252, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741839_1015, duration: 1795212
2022-12-18 08:14:34,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741840_1016 src: /172.18.0.3:42580 dest: /172.18.0.3:50010
2022-12-18 08:14:34,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42580, dest: /172.18.0.3:50010, bytes: 214, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: 8cffac09-1eba-45bf-b915-43df748e02f4, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741840_1016, duration: 3790340
2022-12-18 08:14:34,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:56,804 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c7e50c05-81ff-488d-b0cb-e01d9668db0d): no suitable block pools found to scan.  Waiting 1813738805 ms.
2022-12-18 08:20:16,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2022-12-18 08:20:17,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-18 08:20:17,767 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-18 08:20:17,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2022-12-18 08:20:17,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-18 08:20:17,883 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-18 08:20:17,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2022-12-18 08:20:17,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-18 08:20:17,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-18 08:20:17,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2022-12-18 08:20:17,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2022-12-18 08:20:18,022 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-18 08:20:18,028 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-18 08:20:18,042 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-18 08:20:18,046 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-18 08:20:18,047 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-18 08:20:18,048 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-18 08:20:18,048 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-18 08:20:18,067 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38389
2022-12-18 08:20:18,067 INFO org.mortbay.log: jetty-6.1.26
2022-12-18 08:20:18,243 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38389
2022-12-18 08:20:18,344 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-18 08:20:18,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-12-18 08:20:18,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-18 08:20:18,707 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2022-12-18 08:20:18,763 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-18 08:20:18,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-18 08:20:18,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-18 08:20:18,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-18 08:20:18,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2022-12-18 08:20:18,884 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-18 08:20:18,888 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-18 08:20:19,239 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2022-12-18 08:20:19,240 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,240 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:20:19,283 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,283 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,283 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1055401500-172.18.0.2-1671351610662 is not formatted for BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,283 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:20:19,283 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1055401500-172.18.0.2-1671351610662 directory /tmp/hadoop/dfs/data/current/BP-1055401500-172.18.0.2-1671351610662/current
2022-12-18 08:20:19,296 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2022-12-18 08:20:19,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1512424922;bpid=BP-1055401500-172.18.0.2-1671351610662;lv=-56;nsInfo=lv=-63;cid=CID-cc203620-c2ce-413b-96a0-d04a3dcbf0af;nsid=1512424922;c=0;bpid=BP-1055401500-172.18.0.2-1671351610662;dnuuid=null
2022-12-18 08:20:19,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 2b56237b-a108-4734-ae13-db686bf336d3
2022-12-18 08:20:19,346 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228
2022-12-18 08:20:19,346 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2022-12-18 08:20:19,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-18 08:20:19,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,364 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:20:19,396 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1055401500-172.18.0.2-1671351610662 on /tmp/hadoop/dfs/data/current: 32ms
2022-12-18 08:20:19,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1055401500-172.18.0.2-1671351610662: 33ms
2022-12-18 08:20:19,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:20:19,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data/current: 0ms
2022-12-18 08:20:19,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2022-12-18 08:20:19,529 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data
2022-12-18 08:20:19,530 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228): finished scanning block pool BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,543 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1671357938543 with interval 21600000
2022-12-18 08:20:19,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2022-12-18 08:20:19,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2022-12-18 08:20:19,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-18 08:20:19,582 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228): no suitable block pools found to scan.  Waiting 1814399941 ms.
2022-12-18 08:20:19,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid 2b56237b-a108-4734-ae13-db686bf336d3) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2022-12-18 08:20:19,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid 2b56237b-a108-4734-ae13-db686bf336d3) service to master/172.18.0.2:54310
2022-12-18 08:20:19,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3d699ab36150,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-18 08:20:19,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:21:11,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741825_1001 src: /172.18.0.2:59824 dest: /172.18.0.3:50010
2022-12-18 08:21:11,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:59824, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741825_1001, duration: 217954971
2022-12-18 08:21:11,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:12,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741828_1004 src: /172.18.0.2:59836 dest: /172.18.0.3:50010
2022-12-18 08:21:12,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:59836, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741828_1004, duration: 72264107
2022-12-18 08:21:12,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:12,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741830_1006 src: /172.18.0.2:59838 dest: /172.18.0.3:50010
2022-12-18 08:21:12,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:59838, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741830_1006, duration: 45339996
2022-12-18 08:21:12,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:12,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741831_1007 src: /172.18.0.2:59852 dest: /172.18.0.3:50010
2022-12-18 08:21:12,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:59852, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741831_1007, duration: 59139039
2022-12-18 08:21:12,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:51,594 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741828_1004 for rescanning.
2022-12-18 08:21:55,246 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741830_1006 for rescanning.
2022-12-18 08:21:55,911 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741831_1007 for rescanning.
2022-12-18 08:22:01,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741833_1009 src: /172.18.0.3:42214 dest: /172.18.0.3:50010
2022-12-18 08:22:01,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741834_1010 src: /172.18.0.4:34486 dest: /172.18.0.3:50010
2022-12-18 08:22:01,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:34486, dest: /172.18.0.3:50010, bytes: 319, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741834_1010, duration: 63168011
2022-12-18 08:22:01,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:01,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42214, dest: /172.18.0.3:50010, bytes: 274, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741833_1009, duration: 26583295
2022-12-18 08:22:01,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:01,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741835_1011 src: /172.18.0.4:34502 dest: /172.18.0.3:50010
2022-12-18 08:22:01,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741836_1012 src: /172.18.0.3:42226 dest: /172.18.0.3:50010
2022-12-18 08:22:01,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:34502, dest: /172.18.0.3:50010, bytes: 247, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741835_1011, duration: 4814835
2022-12-18 08:22:01,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:01,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42226, dest: /172.18.0.3:50010, bytes: 313, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741836_1012, duration: 38644670
2022-12-18 08:22:01,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:01,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741837_1013 src: /172.18.0.4:34510 dest: /172.18.0.3:50010
2022-12-18 08:22:01,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:34510, dest: /172.18.0.3:50010, bytes: 195, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741837_1013, duration: 1330658
2022-12-18 08:22:01,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:01,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741838_1014 src: /172.18.0.3:42234 dest: /172.18.0.3:50010
2022-12-18 08:22:01,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42234, dest: /172.18.0.3:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741838_1014, duration: 41533958
2022-12-18 08:22:01,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:01,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741839_1015 src: /172.18.0.4:34526 dest: /172.18.0.3:50010
2022-12-18 08:22:01,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:34526, dest: /172.18.0.3:50010, bytes: 252, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741839_1015, duration: 3374152
2022-12-18 08:22:01,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:02,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741840_1016 src: /172.18.0.3:42246 dest: /172.18.0.3:50010
2022-12-18 08:22:02,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:42246, dest: /172.18.0.3:50010, bytes: 214, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 2b56237b-a108-4734-ae13-db686bf336d3, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741840_1016, duration: 3381317
2022-12-18 08:22:02,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:39,597 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b2a1d8ea-06d6-4e60-8b00-840d4532b228): no suitable block pools found to scan.  Waiting 1814259926 ms.
2022-12-18 09:46:36,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2022-12-18 09:46:36,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-18 09:46:37,019 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-18 09:46:37,101 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2022-12-18 09:46:37,101 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-18 09:46:37,104 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-18 09:46:37,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2022-12-18 09:46:37,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-18 09:46:37,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-18 09:46:37,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2022-12-18 09:46:37,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2022-12-18 09:46:37,250 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-18 09:46:37,268 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-18 09:46:37,271 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-18 09:46:37,275 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-18 09:46:37,276 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-18 09:46:37,276 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-18 09:46:37,276 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-18 09:46:37,286 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40973
2022-12-18 09:46:37,286 INFO org.mortbay.log: jetty-6.1.26
2022-12-18 09:46:37,451 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40973
2022-12-18 09:46:37,572 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-18 09:46:37,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-12-18 09:46:37,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-18 09:46:37,919 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2022-12-18 09:46:37,942 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-18 09:46:37,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-18 09:46:37,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-18 09:46:38,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-18 09:46:38,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2022-12-18 09:46:38,041 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-18 09:46:38,070 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-18 09:46:38,348 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2022-12-18 09:46:38,349 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,349 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 09:46:38,389 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,389 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,389 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-558954561-172.18.0.2-1671356790058 is not formatted for BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,389 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 09:46:38,389 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-558954561-172.18.0.2-1671356790058 directory /tmp/hadoop/dfs/data/current/BP-558954561-172.18.0.2-1671356790058/current
2022-12-18 09:46:38,395 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2022-12-18 09:46:38,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=755013202;bpid=BP-558954561-172.18.0.2-1671356790058;lv=-56;nsInfo=lv=-63;cid=CID-fd2d1757-d3ec-4c41-bc3b-9a90a68f1dcf;nsid=755013202;c=0;bpid=BP-558954561-172.18.0.2-1671356790058;dnuuid=null
2022-12-18 09:46:38,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID bd2ec7a4-21e7-42ae-b248-030a497a66a5
2022-12-18 09:46:38,437 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-7f1ff6ba-f227-4541-81cb-e47615aada9f
2022-12-18 09:46:38,438 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2022-12-18 09:46:38,450 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-18 09:46:38,450 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,451 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 09:46:38,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-558954561-172.18.0.2-1671356790058 on /tmp/hadoop/dfs/data/current: 6ms
2022-12-18 09:46:38,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-558954561-172.18.0.2-1671356790058: 7ms
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data/current: 0ms
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2022-12-18 09:46:38,593 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data
2022-12-18 09:46:38,594 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): finished scanning block pool BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,615 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1671371358615 with interval 21600000
2022-12-18 09:46:38,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2022-12-18 09:46:38,643 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): no suitable block pools found to scan.  Waiting 1814399938 ms.
2022-12-18 09:46:38,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2022-12-18 09:46:38,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-18 09:46:38,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid bd2ec7a4-21e7-42ae-b248-030a497a66a5) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2022-12-18 09:46:38,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid bd2ec7a4-21e7-42ae-b248-030a497a66a5) service to master/172.18.0.2:54310
2022-12-18 09:46:38,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3eeba3deaa17,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-18 09:46:38,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:49:31,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741826_1002 src: /172.18.0.2:44142 dest: /172.18.0.3:50010
2022-12-18 09:49:31,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44142, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741826_1002, duration: 146071349
2022-12-18 09:49:31,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:49:31,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741827_1003 src: /172.18.0.2:44148 dest: /172.18.0.3:50010
2022-12-18 09:49:31,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44148, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741827_1003, duration: 90689411
2022-12-18 09:49:31,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:49:31,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741828_1004 src: /172.18.0.2:44152 dest: /172.18.0.3:50010
2022-12-18 09:49:31,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44152, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741828_1004, duration: 59570054
2022-12-18 09:49:31,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:49:31,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741829_1005 src: /172.18.0.2:44166 dest: /172.18.0.3:50010
2022-12-18 09:49:31,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44166, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741829_1005, duration: 45555888
2022-12-18 09:49:31,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:49:31,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741830_1006 src: /172.18.0.2:44168 dest: /172.18.0.3:50010
2022-12-18 09:49:31,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44168, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741830_1006, duration: 60088816
2022-12-18 09:49:31,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:49:31,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741832_1008 src: /172.18.0.2:44170 dest: /172.18.0.3:50010
2022-12-18 09:49:31,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44170, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741832_1008, duration: 41384110
2022-12-18 09:49:31,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:24,754 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741827_1003 for rescanning.
2022-12-18 09:50:25,056 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741826_1002 for rescanning.
2022-12-18 09:50:28,870 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741829_1005 for rescanning.
2022-12-18 09:50:29,024 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741828_1004 for rescanning.
2022-12-18 09:50:32,206 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741830_1006 for rescanning.
2022-12-18 09:50:35,503 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741832_1008 for rescanning.
2022-12-18 09:50:37,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741833_1009 src: /172.18.0.4:38888 dest: /172.18.0.3:50010
2022-12-18 09:50:37,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741834_1010 src: /172.18.0.3:43088 dest: /172.18.0.3:50010
2022-12-18 09:50:37,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:38888, dest: /172.18.0.3:50010, bytes: 274, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741833_1009, duration: 59686281
2022-12-18 09:50:37,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:37,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43088, dest: /172.18.0.3:50010, bytes: 319, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741834_1010, duration: 18593092
2022-12-18 09:50:37,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:37,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741835_1011 src: /172.18.0.4:38896 dest: /172.18.0.3:50010
2022-12-18 09:50:37,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:38896, dest: /172.18.0.3:50010, bytes: 247, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741835_1011, duration: 1179862
2022-12-18 09:50:37,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:37,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741836_1012 src: /172.18.0.3:44918 dest: /172.18.0.3:50010
2022-12-18 09:50:38,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44918, dest: /172.18.0.3:50010, bytes: 313, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741836_1012, duration: 40884687
2022-12-18 09:50:38,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:38,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741837_1013 src: /172.18.0.4:44982 dest: /172.18.0.3:50010
2022-12-18 09:50:38,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44982, dest: /172.18.0.3:50010, bytes: 195, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741837_1013, duration: 2186366
2022-12-18 09:50:38,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:38,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741838_1014 src: /172.18.0.3:44934 dest: /172.18.0.3:50010
2022-12-18 09:50:38,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44934, dest: /172.18.0.3:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741838_1014, duration: 10405324
2022-12-18 09:50:38,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:38,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741839_1015 src: /172.18.0.4:44996 dest: /172.18.0.3:50010
2022-12-18 09:50:38,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44996, dest: /172.18.0.3:50010, bytes: 252, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741839_1015, duration: 26284819
2022-12-18 09:50:38,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:38,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741840_1016 src: /172.18.0.3:44942 dest: /172.18.0.3:50010
2022-12-18 09:50:38,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44942, dest: /172.18.0.3:50010, bytes: 214, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: bd2ec7a4-21e7-42ae-b248-030a497a66a5, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741840_1016, duration: 3412116
2022-12-18 09:50:38,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:52:01,258 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7f1ff6ba-f227-4541-81cb-e47615aada9f): no suitable block pools found to scan.  Waiting 1814077323 ms.
2023-12-10 22:12:10,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2023-12-10 22:12:10,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-10 22:12:11,981 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-12-10 22:12:12,124 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2023-12-10 22:12:12,124 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-12-10 22:12:12,128 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-12-10 22:12:12,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2023-12-10 22:12:12,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-12-10 22:12:12,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-12-10 22:12:12,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2023-12-10 22:12:12,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2023-12-10 22:12:12,313 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-12-10 22:12:12,320 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-12-10 22:12:12,335 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-12-10 22:12:12,340 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-12-10 22:12:12,342 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-12-10 22:12:12,342 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-12-10 22:12:12,342 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-12-10 22:12:12,369 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35105
2023-12-10 22:12:12,370 INFO org.mortbay.log: jetty-6.1.26
2023-12-10 22:12:12,575 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35105
2023-12-10 22:12:12,757 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-12-10 22:12:13,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-12-10 22:12:13,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-12-10 22:12:13,247 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2023-12-10 22:12:13,288 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-12-10 22:12:13,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-12-10 22:12:13,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-12-10 22:12:13,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-12-10 22:12:13,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2023-12-10 22:12:13,430 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-12-10 22:12:13,433 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-12-10 22:12:13,904 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2023-12-10 22:12:13,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-10 22:12:13,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-97103087-172.18.0.2-1702246324889 is not formatted for BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-10 22:12:13,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-97103087-172.18.0.2-1702246324889 directory /tmp/hadoop/dfs/data/current/BP-97103087-172.18.0.2-1702246324889/current
2023-12-10 22:12:13,988 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2023-12-10 22:12:13,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1807287671;bpid=BP-97103087-172.18.0.2-1702246324889;lv=-56;nsInfo=lv=-63;cid=CID-dfb45879-218e-4e95-b6d1-4970483b32da;nsid=1807287671;c=0;bpid=BP-97103087-172.18.0.2-1702246324889;dnuuid=null
2023-12-10 22:12:13,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2
2023-12-10 22:12:14,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-48e2783b-9293-49f5-8844-914ac63b02a7
2023-12-10 22:12:14,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2023-12-10 22:12:14,075 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-12-10 22:12:14,075 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:14,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data/current...
2023-12-10 22:12:14,096 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-97103087-172.18.0.2-1702246324889 on /tmp/hadoop/dfs/data/current: 20ms
2023-12-10 22:12:14,096 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-97103087-172.18.0.2-1702246324889: 21ms
2023-12-10 22:12:14,097 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data/current...
2023-12-10 22:12:14,097 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data/current: 0ms
2023-12-10 22:12:14,097 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2023-12-10 22:12:14,268 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data
2023-12-10 22:12:14,269 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): finished scanning block pool BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:14,298 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1702258914298 with interval 21600000
2023-12-10 22:12:14,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2023-12-10 22:12:14,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2023-12-10 22:12:14,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-12-10 22:12:14,366 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): no suitable block pools found to scan.  Waiting 1814399892 ms.
2023-12-10 22:12:14,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2023-12-10 22:12:14,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2) service to master/172.18.0.2:54310
2023-12-10 22:12:14,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7d5ee45b43,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 25 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-10 22:12:14,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:23:32,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741826_1002 src: /172.18.0.2:48692 dest: /172.18.0.3:50010
2023-12-10 22:23:32,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48692, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741826_1002, duration: 195152940
2023-12-10 22:23:32,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:32,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741827_1003 src: /172.18.0.2:48702 dest: /172.18.0.3:50010
2023-12-10 22:23:32,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48702, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741827_1003, duration: 93537502
2023-12-10 22:23:32,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:32,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741828_1004 src: /172.18.0.2:48718 dest: /172.18.0.3:50010
2023-12-10 22:23:32,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48718, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741828_1004, duration: 55420388
2023-12-10 22:23:32,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:32,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741829_1005 src: /172.18.0.2:48726 dest: /172.18.0.3:50010
2023-12-10 22:23:33,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48726, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741829_1005, duration: 86986391
2023-12-10 22:23:33,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741830_1006 src: /172.18.0.2:48740 dest: /172.18.0.3:50010
2023-12-10 22:23:33,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48740, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741830_1006, duration: 64514618
2023-12-10 22:23:33,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741831_1007 src: /172.18.0.2:48742 dest: /172.18.0.3:50010
2023-12-10 22:23:33,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48742, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741831_1007, duration: 97588463
2023-12-10 22:23:33,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741834_1010 src: /172.18.0.2:48758 dest: /172.18.0.3:50010
2023-12-10 22:23:33,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48758, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741834_1010, duration: 70037391
2023-12-10 22:23:33,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741836_1012 src: /172.18.0.2:48768 dest: /172.18.0.3:50010
2023-12-10 22:23:33,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48768, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741836_1012, duration: 76070060
2023-12-10 22:23:33,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741839_1015 src: /172.18.0.2:48772 dest: /172.18.0.3:50010
2023-12-10 22:23:34,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48772, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741839_1015, duration: 93334384
2023-12-10 22:23:34,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741845_1021 src: /172.18.0.2:48778 dest: /172.18.0.3:50010
2023-12-10 22:23:34,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48778, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741845_1021, duration: 75049229
2023-12-10 22:23:34,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741846_1022 src: /172.18.0.2:48786 dest: /172.18.0.3:50010
2023-12-10 22:23:34,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48786, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741846_1022, duration: 51622521
2023-12-10 22:23:34,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741848_1024 src: /172.18.0.2:48802 dest: /172.18.0.3:50010
2023-12-10 22:23:34,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48802, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741848_1024, duration: 40000409
2023-12-10 22:23:34,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741851_1027 src: /172.18.0.2:48808 dest: /172.18.0.3:50010
2023-12-10 22:23:35,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48808, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741851_1027, duration: 66533600
2023-12-10 22:23:35,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741854_1030 src: /172.18.0.2:48820 dest: /172.18.0.3:50010
2023-12-10 22:23:35,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48820, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741854_1030, duration: 66797385
2023-12-10 22:23:35,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741856_1032 src: /172.18.0.2:48826 dest: /172.18.0.3:50010
2023-12-10 22:23:35,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:48826, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741856_1032, duration: 39440837
2023-12-10 22:23:35,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:24:04,756 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741827_1003 for rescanning.
2023-12-10 22:24:05,235 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741826_1002 for rescanning.
2023-12-10 22:24:09,403 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741828_1004 for rescanning.
2023-12-10 22:24:09,695 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741829_1005 for rescanning.
2023-12-10 22:24:12,999 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741830_1006 for rescanning.
2023-12-10 22:24:13,611 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741831_1007 for rescanning.
2023-12-10 22:24:20,283 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741834_1010 for rescanning.
2023-12-10 22:24:23,659 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741836_1012 for rescanning.
2023-12-10 22:24:27,691 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741839_1015 for rescanning.
2023-12-10 22:24:38,096 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741845_1021 for rescanning.
2023-12-10 22:24:41,473 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741846_1022 for rescanning.
2023-12-10 22:24:44,860 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741848_1024 for rescanning.
2023-12-10 22:24:48,663 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741851_1027 for rescanning.
2023-12-10 22:24:55,484 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741854_1030 for rescanning.
2023-12-10 22:24:58,792 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-48e2783b-9293-49f5-8844-914ac63b02a7): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741856_1032 for rescanning.
2023-12-10 22:25:01,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741858_1034 src: /172.18.0.3:57162 dest: /172.18.0.3:50010
2023-12-10 22:25:01,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741857_1033 src: /172.18.0.4:47422 dest: /172.18.0.3:50010
2023-12-10 22:25:01,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47422, dest: /172.18.0.3:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741857_1033, duration: 41657259
2023-12-10 22:25:01,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:01,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57162, dest: /172.18.0.3:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741858_1034, duration: 71523986
2023-12-10 22:25:01,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:01,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741860_1036 src: /172.18.0.3:57176 dest: /172.18.0.3:50010
2023-12-10 22:25:01,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741859_1035 src: /172.18.0.4:47430 dest: /172.18.0.3:50010
2023-12-10 22:25:01,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47430, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741859_1035, duration: 49120045
2023-12-10 22:25:01,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:01,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57176, dest: /172.18.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741860_1036, duration: 13444534
2023-12-10 22:25:01,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:01,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741861_1037 src: /172.18.0.3:57188 dest: /172.18.0.3:50010
2023-12-10 22:25:01,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741862_1038 src: /172.18.0.4:47440 dest: /172.18.0.3:50010
2023-12-10 22:25:01,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57188, dest: /172.18.0.3:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741861_1037, duration: 13080707
2023-12-10 22:25:01,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:01,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47440, dest: /172.18.0.3:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741862_1038, duration: 7768666
2023-12-10 22:25:01,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741863_1039 src: /172.18.0.3:57192 dest: /172.18.0.3:50010
2023-12-10 22:25:02,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741864_1040 src: /172.18.0.4:47446 dest: /172.18.0.3:50010
2023-12-10 22:25:02,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47446, dest: /172.18.0.3:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741864_1040, duration: 32367790
2023-12-10 22:25:02,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57192, dest: /172.18.0.3:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741863_1039, duration: 34715614
2023-12-10 22:25:02,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741865_1041 src: /172.18.0.3:57200 dest: /172.18.0.3:50010
2023-12-10 22:25:02,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741866_1042 src: /172.18.0.4:47454 dest: /172.18.0.3:50010
2023-12-10 22:25:02,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47454, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741866_1042, duration: 41483085
2023-12-10 22:25:02,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57200, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741865_1041, duration: 30200538
2023-12-10 22:25:02,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741867_1043 src: /172.18.0.3:57206 dest: /172.18.0.3:50010
2023-12-10 22:25:02,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57206, dest: /172.18.0.3:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741867_1043, duration: 11796050
2023-12-10 22:25:02,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741868_1044 src: /172.18.0.4:47456 dest: /172.18.0.3:50010
2023-12-10 22:25:02,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47456, dest: /172.18.0.3:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741868_1044, duration: 51005440
2023-12-10 22:25:02,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741869_1045 src: /172.18.0.3:57220 dest: /172.18.0.3:50010
2023-12-10 22:25:02,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57220, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741869_1045, duration: 2164548
2023-12-10 22:25:02,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741870_1046 src: /172.18.0.4:47462 dest: /172.18.0.3:50010
2023-12-10 22:25:02,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47462, dest: /172.18.0.3:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741870_1046, duration: 10393594
2023-12-10 22:25:02,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741871_1047 src: /172.18.0.3:57232 dest: /172.18.0.3:50010
2023-12-10 22:25:03,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57232, dest: /172.18.0.3:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741871_1047, duration: 29520816
2023-12-10 22:25:03,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741872_1048 src: /172.18.0.4:47474 dest: /172.18.0.3:50010
2023-12-10 22:25:03,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47474, dest: /172.18.0.3:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741872_1048, duration: 42748173
2023-12-10 22:25:03,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741873_1049 src: /172.18.0.3:57234 dest: /172.18.0.3:50010
2023-12-10 22:25:03,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57234, dest: /172.18.0.3:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741873_1049, duration: 3801447
2023-12-10 22:25:03,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741874_1050 src: /172.18.0.4:47476 dest: /172.18.0.3:50010
2023-12-10 22:25:03,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47476, dest: /172.18.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741874_1050, duration: 11770066
2023-12-10 22:25:03,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741875_1051 src: /172.18.0.3:57246 dest: /172.18.0.3:50010
2023-12-10 22:25:03,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57246, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741875_1051, duration: 8074189
2023-12-10 22:25:03,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741876_1052 src: /172.18.0.4:47480 dest: /172.18.0.3:50010
2023-12-10 22:25:03,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47480, dest: /172.18.0.3:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741876_1052, duration: 2181694
2023-12-10 22:25:03,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741877_1053 src: /172.18.0.3:57256 dest: /172.18.0.3:50010
2023-12-10 22:25:03,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57256, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741877_1053, duration: 8736197
2023-12-10 22:25:03,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741878_1054 src: /172.18.0.4:47492 dest: /172.18.0.3:50010
2023-12-10 22:25:04,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47492, dest: /172.18.0.3:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741878_1054, duration: 1268705
2023-12-10 22:25:04,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741879_1055 src: /172.18.0.3:57262 dest: /172.18.0.3:50010
2023-12-10 22:25:04,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57262, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741879_1055, duration: 10798524
2023-12-10 22:25:04,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741881_1057 src: /172.18.0.3:57268 dest: /172.18.0.3:50010
2023-12-10 22:25:04,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741880_1056 src: /172.18.0.4:47504 dest: /172.18.0.3:50010
2023-12-10 22:25:04,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47504, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741880_1056, duration: 52709267
2023-12-10 22:25:04,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57268, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741881_1057, duration: 3921829
2023-12-10 22:25:04,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741883_1059 src: /172.18.0.3:57270 dest: /172.18.0.3:50010
2023-12-10 22:25:04,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741882_1058 src: /172.18.0.4:47520 dest: /172.18.0.3:50010
2023-12-10 22:25:04,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47520, dest: /172.18.0.3:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741882_1058, duration: 33719654
2023-12-10 22:25:04,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57270, dest: /172.18.0.3:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741883_1059, duration: 10231821
2023-12-10 22:25:04,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741885_1061 src: /172.18.0.3:57284 dest: /172.18.0.3:50010
2023-12-10 22:25:04,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741884_1060 src: /172.18.0.4:47530 dest: /172.18.0.3:50010
2023-12-10 22:25:04,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47530, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741884_1060, duration: 36178263
2023-12-10 22:25:04,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57284, dest: /172.18.0.3:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741885_1061, duration: 10832511
2023-12-10 22:25:04,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741885_1061, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:05,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741886_1062 src: /172.18.0.3:57288 dest: /172.18.0.3:50010
2023-12-10 22:25:05,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741887_1063 src: /172.18.0.4:47542 dest: /172.18.0.3:50010
2023-12-10 22:25:05,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47542, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741887_1063, duration: 11719213
2023-12-10 22:25:05,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:05,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57288, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 480f1eab-05ad-45cd-8d97-8cc7aa8bb0b2, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741886_1062, duration: 22516065
2023-12-10 22:25:05,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741886_1062, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:40,549 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "slave1/172.18.0.3"; destination host is: "master":54310; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2023-12-10 22:25:44,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-12-10 22:25:45,382 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-12-10 22:25:45,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave1/172.18.0.3
************************************************************/
2023-12-16 08:09:55,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.19.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2023-12-16 08:09:55,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-16 08:09:56,556 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-12-16 08:09:56,616 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2023-12-16 08:09:56,616 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-12-16 08:09:56,618 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-12-16 08:09:56,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2023-12-16 08:09:56,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-12-16 08:09:56,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-12-16 08:09:56,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2023-12-16 08:09:56,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2023-12-16 08:09:56,724 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-12-16 08:09:56,732 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-12-16 08:09:56,735 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-12-16 08:09:56,738 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-12-16 08:09:56,739 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-12-16 08:09:56,739 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-12-16 08:09:56,740 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-12-16 08:09:56,746 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46517
2023-12-16 08:09:56,746 INFO org.mortbay.log: jetty-6.1.26
2023-12-16 08:09:56,886 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46517
2023-12-16 08:09:57,005 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-12-16 08:09:57,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-12-16 08:09:57,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-12-16 08:09:57,290 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2023-12-16 08:09:57,304 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-12-16 08:09:57,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-12-16 08:09:57,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-12-16 08:09:57,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-12-16 08:09:57,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.19.0.2:54310 starting to offer service
2023-12-16 08:09:57,367 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-12-16 08:09:57,368 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-12-16 08:09:58,627 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 51@slave1
2023-12-16 08:09:58,629 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,629 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-16 08:09:58,782 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-855300685-172.19.0.2-1702714189155 is not formatted for BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-16 08:09:58,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-855300685-172.19.0.2-1702714189155 directory /tmp/hadoop/dfs/data/current/BP-855300685-172.19.0.2-1702714189155/current
2023-12-16 08:09:58,795 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2023-12-16 08:09:58,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1110687171;bpid=BP-855300685-172.19.0.2-1702714189155;lv=-56;nsInfo=lv=-63;cid=CID-2bbcc24e-5268-42cb-b63f-a0eb25f33987;nsid=1110687171;c=0;bpid=BP-855300685-172.19.0.2-1702714189155;dnuuid=null
2023-12-16 08:09:58,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID f3cff374-8623-4a46-98c7-bc5d12e7c9c3
2023-12-16 08:09:58,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-cd3fa1ef-eeaa-4e5b-b4ac-fe55d26e2753
2023-12-16 08:09:58,919 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2023-12-16 08:09:58,929 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-12-16 08:09:58,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,933 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data/current...
2023-12-16 08:09:58,957 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-855300685-172.19.0.2-1702714189155 on /tmp/hadoop/dfs/data/current: 25ms
2023-12-16 08:09:58,958 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-855300685-172.19.0.2-1702714189155: 28ms
2023-12-16 08:09:58,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data/current...
2023-12-16 08:09:58,960 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data/current: 0ms
2023-12-16 08:09:58,960 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2023-12-16 08:09:59,343 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data
2023-12-16 08:09:59,345 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-cd3fa1ef-eeaa-4e5b-b4ac-fe55d26e2753): finished scanning block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:59,372 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1702728906372 with interval 21600000
2023-12-16 08:09:59,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid null) service to master/172.19.0.2:54310 beginning handshake with NN
2023-12-16 08:09:59,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid null) service to master/172.19.0.2:54310 successfully registered with NN
2023-12-16 08:09:59,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.19.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-12-16 08:09:59,618 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-cd3fa1ef-eeaa-4e5b-b4ac-fe55d26e2753): no suitable block pools found to scan.  Waiting 1814399711 ms.
2023-12-16 08:09:59,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid f3cff374-8623-4a46-98c7-bc5d12e7c9c3) service to master/172.19.0.2:54310 trying to claim ACTIVE state with txid=1
2023-12-16 08:09:59,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid f3cff374-8623-4a46-98c7-bc5d12e7c9c3) service to master/172.19.0.2:54310
2023-12-16 08:10:00,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2c37179b30f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 198 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-16 08:10:00,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:11:10,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741825_1001 src: /172.19.0.2:60222 dest: /172.19.0.3:50010
2023-12-16 08:11:11,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:60222, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_853522575_1, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741825_1001, duration: 137396148
2023-12-16 08:11:11,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:11:11,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741826_1002 src: /172.19.0.2:60238 dest: /172.19.0.3:50010
2023-12-16 08:11:11,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:60238, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_853522575_1, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741826_1002, duration: 70853673
2023-12-16 08:11:11,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:11:11,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741828_1004 src: /172.19.0.2:60242 dest: /172.19.0.3:50010
2023-12-16 08:11:11,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:60242, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_853522575_1, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741828_1004, duration: 45663480
2023-12-16 08:11:11,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:12:22,975 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-cd3fa1ef-eeaa-4e5b-b4ac-fe55d26e2753): Scheduling suspect block BP-855300685-172.19.0.2-1702714189155:blk_1073741826_1002 for rescanning.
2023-12-16 08:12:29,883 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-cd3fa1ef-eeaa-4e5b-b4ac-fe55d26e2753): Scheduling suspect block BP-855300685-172.19.0.2-1702714189155:blk_1073741828_1004 for rescanning.
2023-12-16 08:12:36,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741829_1005 src: /172.19.0.3:49732 dest: /172.19.0.3:50010
2023-12-16 08:12:36,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741830_1006 src: /172.19.0.4:52090 dest: /172.19.0.3:50010
2023-12-16 08:12:36,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:49732, dest: /172.19.0.3:50010, bytes: 448, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000001_0_497024143_26, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741829_1005, duration: 39842742
2023-12-16 08:12:36,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-16 08:12:36,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:52090, dest: /172.19.0.3:50010, bytes: 580, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000000_0_1389196456_26, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741830_1006, duration: 88929463
2023-12-16 08:12:36,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:12:36,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741831_1007 src: /172.19.0.3:49742 dest: /172.19.0.3:50010
2023-12-16 08:12:36,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:49742, dest: /172.19.0.3:50010, bytes: 481, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000001_0_497024143_26, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741831_1007, duration: 3622267
2023-12-16 08:12:36,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-16 08:12:36,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741832_1008 src: /172.19.0.4:52092 dest: /172.19.0.3:50010
2023-12-16 08:12:36,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:52092, dest: /172.19.0.3:50010, bytes: 505, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000000_0_1389196456_26, offset: 0, srvID: f3cff374-8623-4a46-98c7-bc5d12e7c9c3, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741832_1008, duration: 19460960
2023-12-16 08:12:36,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:12:54,978 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-cd3fa1ef-eeaa-4e5b-b4ac-fe55d26e2753): no suitable block pools found to scan.  Waiting 1814224351 ms.
2023-12-16 08:49:13,607 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1707ms
No GCs detected
2023-12-19 14:14:33,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.19.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2023-12-19 14:14:33,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-19 14:14:33,779 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-12-19 14:14:33,843 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2023-12-19 14:14:33,843 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-12-19 14:14:33,846 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-12-19 14:14:33,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2023-12-19 14:14:33,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-12-19 14:14:33,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-12-19 14:14:33,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2023-12-19 14:14:33,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2023-12-19 14:14:33,991 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-12-19 14:14:34,006 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-12-19 14:14:34,011 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-12-19 14:14:34,015 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-12-19 14:14:34,016 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-12-19 14:14:34,016 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-12-19 14:14:34,016 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-12-19 14:14:34,025 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35185
2023-12-19 14:14:34,025 INFO org.mortbay.log: jetty-6.1.26
2023-12-19 14:14:34,208 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35185
2023-12-19 14:14:34,306 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-12-19 14:14:34,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-12-19 14:14:34,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-12-19 14:14:34,643 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2023-12-19 14:14:34,654 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-12-19 14:14:34,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-12-19 14:14:34,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-12-19 14:14:34,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-12-19 14:14:34,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.19.0.2:54310 starting to offer service
2023-12-19 14:14:34,758 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-12-19 14:14:34,776 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-12-19 14:14:35,066 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2023-12-19 14:14:35,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-19 14:14:35,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1931797428-172.19.0.2-1702995266959 is not formatted for BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-19 14:14:35,112 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1931797428-172.19.0.2-1702995266959 directory /tmp/hadoop/dfs/data/current/BP-1931797428-172.19.0.2-1702995266959/current
2023-12-19 14:14:35,114 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2023-12-19 14:14:35,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=470937626;bpid=BP-1931797428-172.19.0.2-1702995266959;lv=-56;nsInfo=lv=-63;cid=CID-0970c588-93a0-43a8-ba25-6e35d5178fa9;nsid=470937626;c=0;bpid=BP-1931797428-172.19.0.2-1702995266959;dnuuid=null
2023-12-19 14:14:35,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 307c3e9e-8c08-4691-a747-c068b4803654
2023-12-19 14:14:35,147 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932
2023-12-19 14:14:35,147 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2023-12-19 14:14:35,150 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-12-19 14:14:35,150 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,151 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data/current...
2023-12-19 14:14:35,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1931797428-172.19.0.2-1702995266959 on /tmp/hadoop/dfs/data/current: 5ms
2023-12-19 14:14:35,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1931797428-172.19.0.2-1702995266959: 6ms
2023-12-19 14:14:35,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data/current...
2023-12-19 14:14:35,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data/current: 0ms
2023-12-19 14:14:35,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2023-12-19 14:14:35,266 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data
2023-12-19 14:14:35,267 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): finished scanning block pool BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,280 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1703010599280 with interval 21600000
2023-12-19 14:14:35,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid null) service to master/172.19.0.2:54310 beginning handshake with NN
2023-12-19 14:14:35,323 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): no suitable block pools found to scan.  Waiting 1814399928 ms.
2023-12-19 14:14:35,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid null) service to master/172.19.0.2:54310 successfully registered with NN
2023-12-19 14:14:35,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.19.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-12-19 14:14:35,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid 307c3e9e-8c08-4691-a747-c068b4803654) service to master/172.19.0.2:54310 trying to claim ACTIVE state with txid=1
2023-12-19 14:14:35,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid 307c3e9e-8c08-4691-a747-c068b4803654) service to master/172.19.0.2:54310
2023-12-19 14:14:35,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x414413c1479,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-19 14:14:35,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:16:39,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741825_1001 src: /172.19.0.2:59044 dest: /172.19.0.3:50010
2023-12-19 14:16:39,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59044, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741825_1001, duration: 135921797
2023-12-19 14:16:39,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:39,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741827_1003 src: /172.19.0.2:59052 dest: /172.19.0.3:50010
2023-12-19 14:16:39,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59052, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741827_1003, duration: 92520082
2023-12-19 14:16:39,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:39,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741828_1004 src: /172.19.0.2:59054 dest: /172.19.0.3:50010
2023-12-19 14:16:39,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59054, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741828_1004, duration: 53483030
2023-12-19 14:16:39,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:39,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741829_1005 src: /172.19.0.2:59060 dest: /172.19.0.3:50010
2023-12-19 14:16:39,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59060, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741829_1005, duration: 43715656
2023-12-19 14:16:39,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741834_1010 src: /172.19.0.2:59062 dest: /172.19.0.3:50010
2023-12-19 14:16:40,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59062, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741834_1010, duration: 36205843
2023-12-19 14:16:40,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741835_1011 src: /172.19.0.2:59070 dest: /172.19.0.3:50010
2023-12-19 14:16:40,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59070, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741835_1011, duration: 53874805
2023-12-19 14:16:40,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741837_1013 src: /172.19.0.2:59074 dest: /172.19.0.3:50010
2023-12-19 14:16:40,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59074, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741837_1013, duration: 56451971
2023-12-19 14:16:40,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741839_1015 src: /172.19.0.2:59076 dest: /172.19.0.3:50010
2023-12-19 14:16:40,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59076, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741839_1015, duration: 63023727
2023-12-19 14:16:40,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741840_1016 src: /172.19.0.2:59090 dest: /172.19.0.3:50010
2023-12-19 14:16:40,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59090, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741840_1016, duration: 54255301
2023-12-19 14:16:40,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741842_1018 src: /172.19.0.2:59096 dest: /172.19.0.3:50010
2023-12-19 14:16:40,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59096, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741842_1018, duration: 52141437
2023-12-19 14:16:40,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741843_1019 src: /172.19.0.2:59102 dest: /172.19.0.3:50010
2023-12-19 14:16:40,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59102, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741843_1019, duration: 73855311
2023-12-19 14:16:40,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741845_1021 src: /172.19.0.2:59112 dest: /172.19.0.3:50010
2023-12-19 14:16:41,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59112, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741845_1021, duration: 63455873
2023-12-19 14:16:41,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741848_1024 src: /172.19.0.2:59116 dest: /172.19.0.3:50010
2023-12-19 14:16:41,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59116, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741848_1024, duration: 39564559
2023-12-19 14:16:41,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741850_1026 src: /172.19.0.2:59118 dest: /172.19.0.3:50010
2023-12-19 14:16:41,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:59118, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741850_1026, duration: 67259629
2023-12-19 14:16:41,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741852_1028 src: /172.19.0.2:36496 dest: /172.19.0.3:50010
2023-12-19 14:16:41,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:36496, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741852_1028, duration: 31662493
2023-12-19 14:16:41,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741853_1029 src: /172.19.0.2:36498 dest: /172.19.0.3:50010
2023-12-19 14:16:41,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:36498, dest: /172.19.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741853_1029, duration: 38364231
2023-12-19 14:16:41,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:03,756 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741827_1003 for rescanning.
2023-12-19 14:17:07,145 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741828_1004 for rescanning.
2023-12-19 14:17:07,441 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741829_1005 for rescanning.
2023-12-19 14:17:16,038 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741834_1010 for rescanning.
2023-12-19 14:17:16,627 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741835_1011 for rescanning.
2023-12-19 14:17:19,458 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741837_1013 for rescanning.
2023-12-19 14:17:22,295 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741839_1015 for rescanning.
2023-12-19 14:17:24,375 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741840_1016 for rescanning.
2023-12-19 14:17:27,637 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741842_1018 for rescanning.
2023-12-19 14:17:28,525 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741843_1019 for rescanning.
2023-12-19 14:17:31,501 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741845_1021 for rescanning.
2023-12-19 14:17:36,039 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741848_1024 for rescanning.
2023-12-19 14:17:38,824 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741850_1026 for rescanning.
2023-12-19 14:17:41,576 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741852_1028 for rescanning.
2023-12-19 14:17:42,810 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c217d529-0e7e-46a4-8f5e-3f10fefe3932): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741853_1029 for rescanning.
2023-12-19 14:17:50,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741857_1033 src: /172.19.0.3:40074 dest: /172.19.0.3:50010
2023-12-19 14:17:50,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741858_1034 src: /172.19.0.4:56184 dest: /172.19.0.3:50010
2023-12-19 14:17:50,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56184, dest: /172.19.0.3:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741858_1034, duration: 3371255
2023-12-19 14:17:50,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40074, dest: /172.19.0.3:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741857_1033, duration: 21730696
2023-12-19 14:17:50,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741860_1036 src: /172.19.0.3:40082 dest: /172.19.0.3:50010
2023-12-19 14:17:50,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741859_1035 src: /172.19.0.4:56192 dest: /172.19.0.3:50010
2023-12-19 14:17:50,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56192, dest: /172.19.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741859_1035, duration: 51133944
2023-12-19 14:17:50,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40082, dest: /172.19.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741860_1036, duration: 20851691
2023-12-19 14:17:50,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741861_1037 src: /172.19.0.3:40086 dest: /172.19.0.3:50010
2023-12-19 14:17:50,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741862_1038 src: /172.19.0.4:56202 dest: /172.19.0.3:50010
2023-12-19 14:17:50,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40086, dest: /172.19.0.3:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741861_1037, duration: 3094286
2023-12-19 14:17:50,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56202, dest: /172.19.0.3:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741862_1038, duration: 5084337
2023-12-19 14:17:50,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741863_1039 src: /172.19.0.3:40098 dest: /172.19.0.3:50010
2023-12-19 14:17:50,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741864_1040 src: /172.19.0.4:56212 dest: /172.19.0.3:50010
2023-12-19 14:17:50,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56212, dest: /172.19.0.3:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741864_1040, duration: 10371549
2023-12-19 14:17:50,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40098, dest: /172.19.0.3:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741863_1039, duration: 11376639
2023-12-19 14:17:50,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741865_1041 src: /172.19.0.3:40110 dest: /172.19.0.3:50010
2023-12-19 14:17:50,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40110, dest: /172.19.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741865_1041, duration: 4316493
2023-12-19 14:17:50,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741866_1042 src: /172.19.0.4:56226 dest: /172.19.0.3:50010
2023-12-19 14:17:50,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56226, dest: /172.19.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741866_1042, duration: 30583340
2023-12-19 14:17:50,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741867_1043 src: /172.19.0.3:40120 dest: /172.19.0.3:50010
2023-12-19 14:17:51,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40120, dest: /172.19.0.3:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741867_1043, duration: 8993403
2023-12-19 14:17:51,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741868_1044 src: /172.19.0.4:56232 dest: /172.19.0.3:50010
2023-12-19 14:17:51,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56232, dest: /172.19.0.3:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741868_1044, duration: 1065157
2023-12-19 14:17:51,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741869_1045 src: /172.19.0.3:40136 dest: /172.19.0.3:50010
2023-12-19 14:17:51,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:40136, dest: /172.19.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741869_1045, duration: 31594347
2023-12-19 14:17:51,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741870_1046 src: /172.19.0.4:56242 dest: /172.19.0.3:50010
2023-12-19 14:17:51,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:56242, dest: /172.19.0.3:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741870_1046, duration: 4014334
2023-12-19 14:17:51,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741871_1047 src: /172.19.0.3:46790 dest: /172.19.0.3:50010
2023-12-19 14:17:51,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46790, dest: /172.19.0.3:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741871_1047, duration: 26017344
2023-12-19 14:17:51,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741872_1048 src: /172.19.0.4:40346 dest: /172.19.0.3:50010
2023-12-19 14:17:51,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40346, dest: /172.19.0.3:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741872_1048, duration: 2651030
2023-12-19 14:17:51,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741873_1049 src: /172.19.0.3:46796 dest: /172.19.0.3:50010
2023-12-19 14:17:51,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46796, dest: /172.19.0.3:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741873_1049, duration: 42430977
2023-12-19 14:17:51,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741874_1050 src: /172.19.0.4:40348 dest: /172.19.0.3:50010
2023-12-19 14:17:51,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40348, dest: /172.19.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741874_1050, duration: 1243050
2023-12-19 14:17:51,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741875_1051 src: /172.19.0.3:46812 dest: /172.19.0.3:50010
2023-12-19 14:17:51,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46812, dest: /172.19.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741875_1051, duration: 32971998
2023-12-19 14:17:51,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741876_1052 src: /172.19.0.4:40360 dest: /172.19.0.3:50010
2023-12-19 14:17:51,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40360, dest: /172.19.0.3:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741876_1052, duration: 2586363
2023-12-19 14:17:51,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741877_1053 src: /172.19.0.3:46816 dest: /172.19.0.3:50010
2023-12-19 14:17:52,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46816, dest: /172.19.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741877_1053, duration: 33744518
2023-12-19 14:17:52,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741878_1054 src: /172.19.0.4:40364 dest: /172.19.0.3:50010
2023-12-19 14:17:52,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40364, dest: /172.19.0.3:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741878_1054, duration: 21691533
2023-12-19 14:17:52,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741879_1055 src: /172.19.0.3:46830 dest: /172.19.0.3:50010
2023-12-19 14:17:52,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46830, dest: /172.19.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741879_1055, duration: 3655096
2023-12-19 14:17:52,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741880_1056 src: /172.19.0.4:40368 dest: /172.19.0.3:50010
2023-12-19 14:17:52,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40368, dest: /172.19.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741880_1056, duration: 3308680
2023-12-19 14:17:52,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741881_1057 src: /172.19.0.3:46838 dest: /172.19.0.3:50010
2023-12-19 14:17:52,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46838, dest: /172.19.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741881_1057, duration: 3435583
2023-12-19 14:17:52,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741882_1058 src: /172.19.0.4:40374 dest: /172.19.0.3:50010
2023-12-19 14:17:52,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40374, dest: /172.19.0.3:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741882_1058, duration: 19437905
2023-12-19 14:17:52,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741883_1059 src: /172.19.0.3:46848 dest: /172.19.0.3:50010
2023-12-19 14:17:52,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46848, dest: /172.19.0.3:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741883_1059, duration: 7768527
2023-12-19 14:17:52,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741884_1060 src: /172.19.0.4:40386 dest: /172.19.0.3:50010
2023-12-19 14:17:52,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40386, dest: /172.19.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741884_1060, duration: 3917226
2023-12-19 14:17:52,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741885_1061 src: /172.19.0.3:46860 dest: /172.19.0.3:50010
2023-12-19 14:17:52,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46860, dest: /172.19.0.3:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741885_1061, duration: 13771711
2023-12-19 14:17:52,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741885_1061, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741886_1062 src: /172.19.0.4:40392 dest: /172.19.0.3:50010
2023-12-19 14:17:52,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:40392, dest: /172.19.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741886_1062, duration: 561428
2023-12-19 14:17:52,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741887_1063 src: /172.19.0.3:46864 dest: /172.19.0.3:50010
2023-12-19 14:17:53,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:46864, dest: /172.19.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 307c3e9e-8c08-4691-a747-c068b4803654, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741887_1063, duration: 31907902
2023-12-19 14:17:53,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741887_1063, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:19:16,715 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave1/172.19.0.3"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2023-12-19 14:19:19,314 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-12-19 14:19:19,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave1/172.19.0.3
************************************************************/
2024-01-09 14:42:00,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-09 14:42:00,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-09 14:42:00,979 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-09 14:42:01,074 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-09 14:42:01,074 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-09 14:42:01,077 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-09 14:42:01,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-09 14:42:01,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-09 14:42:01,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-09 14:42:01,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-09 14:42:01,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-09 14:42:01,263 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-09 14:42:01,268 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-09 14:42:01,284 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-09 14:42:01,289 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-09 14:42:01,290 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-09 14:42:01,290 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-09 14:42:01,297 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-09 14:42:01,318 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40497
2024-01-09 14:42:01,318 INFO org.mortbay.log: jetty-6.1.26
2024-01-09 14:42:01,556 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40497
2024-01-09 14:42:01,784 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-09 14:42:02,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-09 14:42:02,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-09 14:42:02,217 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-09 14:42:02,246 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-09 14:42:02,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-09 14:42:02,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-09 14:42:02,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-09 14:42:02,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-09 14:42:02,437 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-09 14:42:02,438 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-09 14:42:03,191 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-09 14:42:03,192 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,192 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-09 14:42:03,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1699754691-172.18.0.2-1704811312624 is not formatted for BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-09 14:42:03,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1699754691-172.18.0.2-1704811312624 directory /tmp/hadoop/dfs/data/current/BP-1699754691-172.18.0.2-1704811312624/current
2024-01-09 14:42:03,414 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-09 14:42:03,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1675739272;bpid=BP-1699754691-172.18.0.2-1704811312624;lv=-56;nsInfo=lv=-63;cid=CID-e260f19a-81d4-4697-8a04-de9a411d3aba;nsid=1675739272;c=0;bpid=BP-1699754691-172.18.0.2-1704811312624;dnuuid=null
2024-01-09 14:42:03,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 2413845c-6810-4457-b89a-db11054c2b05
2024-01-09 14:42:03,606 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-86666c3a-6e11-4068-adb3-bec2903792c2
2024-01-09 14:42:03,606 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-09 14:42:03,609 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-09 14:42:03,610 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,617 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data/current...
2024-01-09 14:42:03,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1699754691-172.18.0.2-1704811312624 on /tmp/hadoop/dfs/data/current: 29ms
2024-01-09 14:42:03,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1699754691-172.18.0.2-1704811312624: 36ms
2024-01-09 14:42:03,647 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data/current...
2024-01-09 14:42:03,647 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-09 14:42:03,647 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-01-09 14:42:03,843 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data
2024-01-09 14:42:03,844 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): finished scanning block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,861 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1704828082861 with interval 21600000
2024-01-09 14:42:03,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-09 14:42:03,945 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): no suitable block pools found to scan.  Waiting 1814399898 ms.
2024-01-09 14:42:03,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-09 14:42:03,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-09 14:42:04,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid 2413845c-6810-4457-b89a-db11054c2b05) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-09 14:42:04,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid 2413845c-6810-4457-b89a-db11054c2b05) service to master/172.18.0.2:54310
2024-01-09 14:42:04,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd523058078,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-09 14:42:04,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:44:59,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741829_1005 src: /172.18.0.2:38810 dest: /172.18.0.3:50010
2024-01-09 14:44:59,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38810, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741829_1005, duration: 186455491
2024-01-09 14:44:59,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:00,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741831_1007 src: /172.18.0.2:38814 dest: /172.18.0.3:50010
2024-01-09 14:45:00,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38814, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741831_1007, duration: 173258052
2024-01-09 14:45:00,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:00,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741833_1009 src: /172.18.0.2:38820 dest: /172.18.0.3:50010
2024-01-09 14:45:00,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38820, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741833_1009, duration: 153904900
2024-01-09 14:45:00,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:01,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741835_1011 src: /172.18.0.2:38832 dest: /172.18.0.3:50010
2024-01-09 14:45:01,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38832, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741835_1011, duration: 177308519
2024-01-09 14:45:01,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:02,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741842_1018 src: /172.18.0.2:38846 dest: /172.18.0.3:50010
2024-01-09 14:45:02,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38846, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741842_1018, duration: 225404187
2024-01-09 14:45:02,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:03,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741844_1020 src: /172.18.0.2:38860 dest: /172.18.0.3:50010
2024-01-09 14:45:03,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38860, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741844_1020, duration: 172253783
2024-01-09 14:45:03,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:03,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741846_1022 src: /172.18.0.2:38866 dest: /172.18.0.3:50010
2024-01-09 14:45:03,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38866, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741846_1022, duration: 182870285
2024-01-09 14:45:03,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:03,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741847_1023 src: /172.18.0.2:38868 dest: /172.18.0.3:50010
2024-01-09 14:45:03,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38868, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741847_1023, duration: 185460361
2024-01-09 14:45:03,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:04,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741850_1026 src: /172.18.0.2:38870 dest: /172.18.0.3:50010
2024-01-09 14:45:04,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38870, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741850_1026, duration: 168352580
2024-01-09 14:45:04,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:04,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741852_1028 src: /172.18.0.2:38872 dest: /172.18.0.3:50010
2024-01-09 14:45:05,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38872, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741852_1028, duration: 376492678
2024-01-09 14:45:05,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:06,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741855_1031 src: /172.18.0.2:38888 dest: /172.18.0.3:50010
2024-01-09 14:45:06,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38888, dest: /172.18.0.3:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741855_1031, duration: 357151051
2024-01-09 14:45:06,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:46:44,267 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741829_1005 for rescanning.
2024-01-09 14:46:48,716 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741831_1007 for rescanning.
2024-01-09 14:46:52,928 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741833_1009 for rescanning.
2024-01-09 14:46:57,382 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741835_1011 for rescanning.
2024-01-09 14:47:13,527 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741842_1018 for rescanning.
2024-01-09 14:47:17,764 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741844_1020 for rescanning.
2024-01-09 14:47:22,116 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741846_1022 for rescanning.
2024-01-09 14:47:24,122 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741847_1023 for rescanning.
2024-01-09 14:47:30,842 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741850_1026 for rescanning.
2024-01-09 14:47:35,337 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741852_1028 for rescanning.
2024-01-09 14:47:41,232 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741855_1031 for rescanning.
2024-01-09 14:47:47,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741858_1034 src: /172.18.0.3:33592 dest: /172.18.0.3:50010
2024-01-09 14:47:47,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741857_1033 src: /172.18.0.4:48160 dest: /172.18.0.3:50010
2024-01-09 14:47:47,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33592, dest: /172.18.0.3:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741858_1034, duration: 46617271
2024-01-09 14:47:47,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:47,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48160, dest: /172.18.0.3:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741857_1033, duration: 58766510
2024-01-09 14:47:47,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741859_1035 src: /172.18.0.3:33608 dest: /172.18.0.3:50010
2024-01-09 14:47:48,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33608, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741859_1035, duration: 5394403
2024-01-09 14:47:48,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741860_1036 src: /172.18.0.4:48164 dest: /172.18.0.3:50010
2024-01-09 14:47:48,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48164, dest: /172.18.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741860_1036, duration: 18253319
2024-01-09 14:47:48,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741861_1037 src: /172.18.0.3:33612 dest: /172.18.0.3:50010
2024-01-09 14:47:48,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33612, dest: /172.18.0.3:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741861_1037, duration: 6168875
2024-01-09 14:47:48,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741862_1038 src: /172.18.0.4:48166 dest: /172.18.0.3:50010
2024-01-09 14:47:48,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48166, dest: /172.18.0.3:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741862_1038, duration: 3390068
2024-01-09 14:47:48,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741863_1039 src: /172.18.0.3:33620 dest: /172.18.0.3:50010
2024-01-09 14:47:48,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33620, dest: /172.18.0.3:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741863_1039, duration: 2212812
2024-01-09 14:47:48,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741864_1040 src: /172.18.0.4:48176 dest: /172.18.0.3:50010
2024-01-09 14:47:48,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48176, dest: /172.18.0.3:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741864_1040, duration: 9347968
2024-01-09 14:47:48,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741865_1041 src: /172.18.0.3:33624 dest: /172.18.0.3:50010
2024-01-09 14:47:48,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33624, dest: /172.18.0.3:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741865_1041, duration: 2090754
2024-01-09 14:47:48,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741866_1042 src: /172.18.0.4:48184 dest: /172.18.0.3:50010
2024-01-09 14:47:48,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48184, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741866_1042, duration: 28366577
2024-01-09 14:47:48,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741867_1043 src: /172.18.0.3:33636 dest: /172.18.0.3:50010
2024-01-09 14:47:49,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33636, dest: /172.18.0.3:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741867_1043, duration: 14189737
2024-01-09 14:47:49,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741868_1044 src: /172.18.0.4:48192 dest: /172.18.0.3:50010
2024-01-09 14:47:49,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48192, dest: /172.18.0.3:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741868_1044, duration: 28093394
2024-01-09 14:47:49,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741869_1045 src: /172.18.0.3:33652 dest: /172.18.0.3:50010
2024-01-09 14:47:49,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33652, dest: /172.18.0.3:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741869_1045, duration: 25396201
2024-01-09 14:47:49,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741870_1046 src: /172.18.0.4:48198 dest: /172.18.0.3:50010
2024-01-09 14:47:49,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:48198, dest: /172.18.0.3:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741870_1046, duration: 3409210
2024-01-09 14:47:49,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741871_1047 src: /172.18.0.3:33662 dest: /172.18.0.3:50010
2024-01-09 14:47:49,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:33662, dest: /172.18.0.3:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741871_1047, duration: 37779512
2024-01-09 14:47:49,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741872_1048 src: /172.18.0.4:45082 dest: /172.18.0.3:50010
2024-01-09 14:47:49,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741873_1049 src: /172.18.0.3:55054 dest: /172.18.0.3:50010
2024-01-09 14:47:49,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45082, dest: /172.18.0.3:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741872_1048, duration: 24257333
2024-01-09 14:47:49,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55054, dest: /172.18.0.3:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741873_1049, duration: 4276327
2024-01-09 14:47:49,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741874_1050 src: /172.18.0.3:55068 dest: /172.18.0.3:50010
2024-01-09 14:47:49,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55068, dest: /172.18.0.3:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741874_1050, duration: 18442327
2024-01-09 14:47:49,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741875_1051 src: /172.18.0.4:45084 dest: /172.18.0.3:50010
2024-01-09 14:47:50,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45084, dest: /172.18.0.3:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741875_1051, duration: 41799461
2024-01-09 14:47:50,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741876_1052 src: /172.18.0.3:55082 dest: /172.18.0.3:50010
2024-01-09 14:47:50,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55082, dest: /172.18.0.3:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741876_1052, duration: 11572502
2024-01-09 14:47:50,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741877_1053 src: /172.18.0.4:45088 dest: /172.18.0.3:50010
2024-01-09 14:47:50,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45088, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741877_1053, duration: 2961899
2024-01-09 14:47:50,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741878_1054 src: /172.18.0.3:55086 dest: /172.18.0.3:50010
2024-01-09 14:47:50,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55086, dest: /172.18.0.3:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741878_1054, duration: 2350809
2024-01-09 14:47:50,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741879_1055 src: /172.18.0.4:45100 dest: /172.18.0.3:50010
2024-01-09 14:47:50,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45100, dest: /172.18.0.3:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741879_1055, duration: 9096725
2024-01-09 14:47:50,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741880_1056 src: /172.18.0.3:55094 dest: /172.18.0.3:50010
2024-01-09 14:47:50,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55094, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741880_1056, duration: 4775090
2024-01-09 14:47:50,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741881_1057 src: /172.18.0.4:45116 dest: /172.18.0.3:50010
2024-01-09 14:47:50,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45116, dest: /172.18.0.3:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741881_1057, duration: 1430342
2024-01-09 14:47:50,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741882_1058 src: /172.18.0.3:55110 dest: /172.18.0.3:50010
2024-01-09 14:47:50,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55110, dest: /172.18.0.3:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741882_1058, duration: 1610564
2024-01-09 14:47:50,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741883_1059 src: /172.18.0.4:45132 dest: /172.18.0.3:50010
2024-01-09 14:47:51,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45132, dest: /172.18.0.3:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741883_1059, duration: 1267058
2024-01-09 14:47:51,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:51,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741884_1060 src: /172.18.0.3:55126 dest: /172.18.0.3:50010
2024-01-09 14:47:51,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55126, dest: /172.18.0.3:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741884_1060, duration: 10979056
2024-01-09 14:47:51,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741884_1060, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:51,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741885_1061 src: /172.18.0.4:45138 dest: /172.18.0.3:50010
2024-01-09 14:47:51,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45138, dest: /172.18.0.3:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741885_1061, duration: 8101609
2024-01-09 14:47:51,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:51,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741886_1062 src: /172.18.0.3:55138 dest: /172.18.0.3:50010
2024-01-09 14:47:51,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:55138, dest: /172.18.0.3:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741886_1062, duration: 3389133
2024-01-09 14:47:51,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741886_1062, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:51,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741887_1063 src: /172.18.0.4:45150 dest: /172.18.0.3:50010
2024-01-09 14:47:51,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45150, dest: /172.18.0.3:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 2413845c-6810-4457-b89a-db11054c2b05, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741887_1063, duration: 12248329
2024-01-09 14:47:51,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:49:41,785 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-86666c3a-6e11-4068-adb3-bec2903792c2): no suitable block pools found to scan.  Waiting 1813942058 ms.
2024-01-09 19:21:22,882 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1699754691-172.18.0.2-1704811312624 Total blocks: 42, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-20 13:35:18,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 13:35:18,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 13:35:19,826 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 13:35:19,913 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 13:35:19,913 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 13:35:19,917 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 13:35:19,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 13:35:19,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 13:35:19,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 13:35:19,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 13:35:19,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 13:35:20,142 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 13:35:20,164 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 13:35:20,182 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 13:35:20,188 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 13:35:20,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 13:35:20,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 13:35:20,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 13:35:20,217 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37921
2024-01-20 13:35:20,217 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 13:35:20,508 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37921
2024-01-20 13:35:20,728 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 13:35:21,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 13:35:21,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 13:35:21,177 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 13:35:21,192 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 13:35:21,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 13:35:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 13:35:21,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 13:35:21,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 13:35:21,333 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 13:35:21,334 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 13:35:21,987 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 13:35:21,988 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:21,989 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 13:35:22,144 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,145 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,145 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-469528286-172.18.0.2-1705757711645 is not formatted for BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,145 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 13:35:22,145 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-469528286-172.18.0.2-1705757711645 directory /tmp/hadoop/dfs/data/current/BP-469528286-172.18.0.2-1705757711645/current
2024-01-20 13:35:22,228 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 13:35:22,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1692160234;bpid=BP-469528286-172.18.0.2-1705757711645;lv=-56;nsInfo=lv=-63;cid=CID-389d0ca0-b953-4d93-ae1e-d64cf269b391;nsid=1692160234;c=0;bpid=BP-469528286-172.18.0.2-1705757711645;dnuuid=null
2024-01-20 13:35:22,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 3e4d8b25-3327-4e50-afa6-cd99930bfa82
2024-01-20 13:35:22,466 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-5560514a-94ef-4076-a94c-27b944584263
2024-01-20 13:35:22,466 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 13:35:22,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 13:35:22,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 13:35:22,519 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-469528286-172.18.0.2-1705757711645 on /tmp/hadoop/dfs/data/current: 41ms
2024-01-20 13:35:22,519 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-469528286-172.18.0.2-1705757711645: 49ms
2024-01-20 13:35:22,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 13:35:22,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 13:35:22,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 13:35:22,738 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data
2024-01-20 13:35:22,738 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5560514a-94ef-4076-a94c-27b944584263): finished scanning block pool BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,752 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705767568752 with interval 21600000
2024-01-20 13:35:22,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 13:35:22,826 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5560514a-94ef-4076-a94c-27b944584263): no suitable block pools found to scan.  Waiting 1814399902 ms.
2024-01-20 13:35:22,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 13:35:22,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 13:35:23,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid 3e4d8b25-3327-4e50-afa6-cd99930bfa82) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 13:35:23,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid 3e4d8b25-3327-4e50-afa6-cd99930bfa82) service to master/172.18.0.2:54310
2024-01-20 13:35:23,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6d56fabe310,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 13:35:23,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-469528286-172.18.0.2-1705757711645
2024-01-20 16:19:37,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 16:19:37,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 16:19:38,608 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 16:19:38,700 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 16:19:38,700 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 16:19:38,704 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 16:19:38,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 16:19:38,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 16:19:38,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 16:19:38,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 16:19:38,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 16:19:38,938 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 16:19:38,945 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 16:19:38,957 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 16:19:38,962 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 16:19:38,963 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 16:19:38,963 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 16:19:38,976 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 16:19:38,986 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33267
2024-01-20 16:19:38,986 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 16:19:39,206 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33267
2024-01-20 16:19:39,384 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 16:19:39,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 16:19:39,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 16:19:39,777 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 16:19:39,812 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 16:19:39,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 16:19:39,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 16:19:39,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 16:19:39,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 16:19:39,937 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 16:19:39,938 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 16:19:40,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 16:19:40,555 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,555 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 16:19:40,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1309909280-172.18.0.2-1705767570687 is not formatted for BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 16:19:40,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1309909280-172.18.0.2-1705767570687 directory /tmp/hadoop/dfs/data/current/BP-1309909280-172.18.0.2-1705767570687/current
2024-01-20 16:19:40,820 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 16:19:40,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2024432647;bpid=BP-1309909280-172.18.0.2-1705767570687;lv=-56;nsInfo=lv=-63;cid=CID-9a37a394-0884-486e-9b78-814b7ed43dbe;nsid=2024432647;c=0;bpid=BP-1309909280-172.18.0.2-1705767570687;dnuuid=null
2024-01-20 16:19:40,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 905d38c6-3ed8-4994-b740-baed0e8781c9
2024-01-20 16:19:41,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-f1c6d22a-a7db-4e29-967f-5c7ca7435419
2024-01-20 16:19:41,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 16:19:41,053 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 16:19:41,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:41,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 16:19:41,075 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1309909280-172.18.0.2-1705767570687 on /tmp/hadoop/dfs/data/current: 21ms
2024-01-20 16:19:41,075 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1309909280-172.18.0.2-1705767570687: 22ms
2024-01-20 16:19:41,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 16:19:41,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 16:19:41,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 16:19:41,288 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data
2024-01-20 16:19:41,289 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f1c6d22a-a7db-4e29-967f-5c7ca7435419): finished scanning block pool BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:41,301 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705787757301 with interval 21600000
2024-01-20 16:19:41,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 16:19:41,372 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f1c6d22a-a7db-4e29-967f-5c7ca7435419): no suitable block pools found to scan.  Waiting 1814399899 ms.
2024-01-20 16:19:41,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 16:19:41,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 16:19:41,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid 905d38c6-3ed8-4994-b740-baed0e8781c9) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 16:19:41,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid 905d38c6-3ed8-4994-b740-baed0e8781c9) service to master/172.18.0.2:54310
2024-01-20 16:19:41,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x30e29658d03,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 57 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 16:19:41,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1309909280-172.18.0.2-1705767570687
2024-01-20 17:00:27,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 17:00:27,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 17:00:28,495 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 17:00:28,575 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 17:00:28,575 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 17:00:28,579 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 17:00:28,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 17:00:28,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 17:00:28,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 17:00:28,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 17:00:28,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 17:00:28,737 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 17:00:28,743 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 17:00:28,748 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 17:00:28,754 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 17:00:28,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 17:00:28,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 17:00:28,766 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 17:00:28,778 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33657
2024-01-20 17:00:28,778 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 17:00:28,971 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33657
2024-01-20 17:00:29,115 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 17:00:29,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 17:00:29,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 17:00:29,516 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 17:00:29,553 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 17:00:29,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 17:00:29,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 17:00:29,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 17:00:29,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 17:00:29,671 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 17:00:29,675 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 17:00:30,224 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 17:00:30,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:00:30,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1983476275-172.18.0.2-1705770021146 is not formatted for BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:00:30,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1983476275-172.18.0.2-1705770021146 directory /tmp/hadoop/dfs/data/current/BP-1983476275-172.18.0.2-1705770021146/current
2024-01-20 17:00:30,448 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 17:00:30,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=757749215;bpid=BP-1983476275-172.18.0.2-1705770021146;lv=-56;nsInfo=lv=-63;cid=CID-770b6b9f-afc4-4233-a71d-9fdb943b02b5;nsid=757749215;c=0;bpid=BP-1983476275-172.18.0.2-1705770021146;dnuuid=null
2024-01-20 17:00:30,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 1f9a6ae9-ec68-496e-b824-fa3f9c707a3e
2024-01-20 17:00:30,602 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-71a4883e-6128-47b8-92af-ab914e2d7a22
2024-01-20 17:00:30,602 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 17:00:30,606 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 17:00:30,606 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,607 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:00:30,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1983476275-172.18.0.2-1705770021146 on /tmp/hadoop/dfs/data/current: 7ms
2024-01-20 17:00:30,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1983476275-172.18.0.2-1705770021146: 9ms
2024-01-20 17:00:30,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:00:30,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 17:00:30,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-01-20 17:00:30,778 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data
2024-01-20 17:00:30,779 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-71a4883e-6128-47b8-92af-ab914e2d7a22): finished scanning block pool BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,790 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705789478790 with interval 21600000
2024-01-20 17:00:30,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 17:00:30,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 17:00:30,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 17:00:30,843 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-71a4883e-6128-47b8-92af-ab914e2d7a22): no suitable block pools found to scan.  Waiting 1814399935 ms.
2024-01-20 17:00:30,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid 1f9a6ae9-ec68-496e-b824-fa3f9c707a3e) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 17:00:30,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid 1f9a6ae9-ec68-496e-b824-fa3f9c707a3e) service to master/172.18.0.2:54310
2024-01-20 17:00:30,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x54870d3c00f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 17:00:30,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:16:17,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 17:16:17,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 17:16:18,063 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 17:16:18,157 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 17:16:18,157 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 17:16:18,162 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 17:16:18,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 17:16:18,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 17:16:18,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 17:16:18,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 17:16:18,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 17:16:18,316 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 17:16:18,332 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 17:16:18,340 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 17:16:18,345 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 17:16:18,346 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 17:16:18,346 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 17:16:18,356 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 17:16:18,367 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35955
2024-01-20 17:16:18,367 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 17:16:18,579 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35955
2024-01-20 17:16:18,684 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 17:16:19,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 17:16:19,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 17:16:19,079 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 17:16:19,113 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 17:16:19,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 17:16:19,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 17:16:19,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 17:16:19,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 17:16:19,195 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 17:16:19,206 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 17:16:19,844 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 17:16:19,845 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,845 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:16:19,990 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,990 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,990 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1198635670-172.18.0.2-1705770970464 is not formatted for BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,990 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:16:19,990 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1198635670-172.18.0.2-1705770970464 directory /tmp/hadoop/dfs/data/current/BP-1198635670-172.18.0.2-1705770970464/current
2024-01-20 17:16:20,076 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 17:16:20,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2096026784;bpid=BP-1198635670-172.18.0.2-1705770970464;lv=-56;nsInfo=lv=-63;cid=CID-b8843bbc-681b-4a29-bd0f-a3d3dd4bfc1f;nsid=2096026784;c=0;bpid=BP-1198635670-172.18.0.2-1705770970464;dnuuid=null
2024-01-20 17:16:20,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 246d9baa-5d08-440d-a82d-3d837b0e5c44
2024-01-20 17:16:20,242 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-316c1a1d-771c-45de-81a1-d427aa5efcc5
2024-01-20 17:16:20,242 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 17:16:20,246 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 17:16:20,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:20,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:16:20,255 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1198635670-172.18.0.2-1705770970464 on /tmp/hadoop/dfs/data/current: 7ms
2024-01-20 17:16:20,255 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1198635670-172.18.0.2-1705770970464: 9ms
2024-01-20 17:16:20,256 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:16:20,256 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 17:16:20,256 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-01-20 17:16:20,420 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data
2024-01-20 17:16:20,421 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-316c1a1d-771c-45de-81a1-d427aa5efcc5): finished scanning block pool BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:20,433 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705775027433 with interval 21600000
2024-01-20 17:16:20,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 17:16:20,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 17:16:20,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 17:16:20,495 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-316c1a1d-771c-45de-81a1-d427aa5efcc5): no suitable block pools found to scan.  Waiting 1814399912 ms.
2024-01-20 17:16:20,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid 246d9baa-5d08-440d-a82d-3d837b0e5c44) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 17:16:20,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid 246d9baa-5d08-440d-a82d-3d837b0e5c44) service to master/172.18.0.2:54310
2024-01-20 17:16:20,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6258d820acc,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 17:16:20,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1198635670-172.18.0.2-1705770970464
2024-01-20 21:11:47,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 21:11:48,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 21:11:48,955 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 21:11:49,056 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 21:11:49,056 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 21:11:49,060 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 21:11:49,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 21:11:49,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 21:11:49,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 21:11:49,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 21:11:49,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 21:11:49,252 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 21:11:49,259 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 21:11:49,278 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 21:11:49,284 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 21:11:49,285 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 21:11:49,285 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 21:11:49,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 21:11:49,323 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41141
2024-01-20 21:11:49,323 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 21:11:49,602 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41141
2024-01-20 21:11:49,789 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 21:11:50,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 21:11:50,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 21:11:50,227 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 21:11:50,251 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 21:11:50,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 21:11:50,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 21:11:50,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 21:11:50,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 21:11:50,374 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 21:11:50,375 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 21:11:51,003 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 21:11:51,004 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,004 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 21:11:51,157 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,157 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,158 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-449117960-172.18.0.2-1705785100612 is not formatted for BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,158 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 21:11:51,158 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-449117960-172.18.0.2-1705785100612 directory /tmp/hadoop/dfs/data/current/BP-449117960-172.18.0.2-1705785100612/current
2024-01-20 21:11:51,211 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 21:11:51,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2087465963;bpid=BP-449117960-172.18.0.2-1705785100612;lv=-56;nsInfo=lv=-63;cid=CID-9e37cee3-5766-489c-898a-40c8b8b382be;nsid=2087465963;c=0;bpid=BP-449117960-172.18.0.2-1705785100612;dnuuid=null
2024-01-20 21:11:51,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID e88a49bd-e34e-4336-a9b4-fa0c5def2621
2024-01-20 21:11:51,389 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9541843e-9944-4191-9fe0-abeef55bde37
2024-01-20 21:11:51,389 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 21:11:51,392 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 21:11:51,393 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,394 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 21:11:51,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-449117960-172.18.0.2-1705785100612 on /tmp/hadoop/dfs/data/current: 26ms
2024-01-20 21:11:51,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-449117960-172.18.0.2-1705785100612: 27ms
2024-01-20 21:11:51,421 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 21:11:51,421 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-01-20 21:11:51,421 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 21:11:51,689 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data
2024-01-20 21:11:51,690 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9541843e-9944-4191-9fe0-abeef55bde37): finished scanning block pool BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,705 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705787420705 with interval 21600000
2024-01-20 21:11:51,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 21:11:51,793 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9541843e-9944-4191-9fe0-abeef55bde37): no suitable block pools found to scan.  Waiting 1814399896 ms.
2024-01-20 21:11:51,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 21:11:51,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 21:11:51,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid e88a49bd-e34e-4336-a9b4-fa0c5def2621) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 21:11:51,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid e88a49bd-e34e-4336-a9b4-fa0c5def2621) service to master/172.18.0.2:54310
2024-01-20 21:11:52,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1dc24e709f8,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 67 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 21:11:52,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:50:20,728 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-449117960-172.18.0.2-1705785100612 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-20 22:16:42,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 22:16:42,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 22:16:43,515 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 22:16:43,614 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 22:16:43,614 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 22:16:43,618 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 22:16:43,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 22:16:43,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 22:16:43,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 22:16:43,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 22:16:43,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 22:16:43,793 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 22:16:43,800 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 22:16:43,816 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 22:16:43,822 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 22:16:43,823 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 22:16:43,823 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 22:16:43,823 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 22:16:43,841 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39551
2024-01-20 22:16:43,841 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 22:16:44,126 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39551
2024-01-20 22:16:44,303 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 22:16:44,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 22:16:44,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 22:16:44,742 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 22:16:44,777 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 22:16:44,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 22:16:44,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 22:16:44,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 22:16:44,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 22:16:44,927 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 22:16:44,928 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 22:16:45,513 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 22:16:45,514 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,514 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:16:45,647 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,647 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,648 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-171478855-172.18.0.2-1705788995744 is not formatted for BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,648 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:16:45,648 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-171478855-172.18.0.2-1705788995744 directory /tmp/hadoop/dfs/data/current/BP-171478855-172.18.0.2-1705788995744/current
2024-01-20 22:16:45,737 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 22:16:45,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=842859768;bpid=BP-171478855-172.18.0.2-1705788995744;lv=-56;nsInfo=lv=-63;cid=CID-089f6790-0632-4a14-b372-671e4247dc3d;nsid=842859768;c=0;bpid=BP-171478855-172.18.0.2-1705788995744;dnuuid=null
2024-01-20 22:16:45,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 768cd4ba-c7dc-426b-a8c8-483fcdf2227f
2024-01-20 22:16:45,904 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-eeecef26-18d2-4030-afc5-4ebfcfe3ceb5
2024-01-20 22:16:45,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 22:16:45,908 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 22:16:45,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,910 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:16:45,917 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-171478855-172.18.0.2-1705788995744 on /tmp/hadoop/dfs/data/current: 8ms
2024-01-20 22:16:45,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-171478855-172.18.0.2-1705788995744: 9ms
2024-01-20 22:16:45,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:16:45,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 22:16:45,918 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 22:16:46,061 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data
2024-01-20 22:16:46,062 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-eeecef26-18d2-4030-afc5-4ebfcfe3ceb5): finished scanning block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:46,074 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705803858074 with interval 21600000
2024-01-20 22:16:46,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 22:16:46,118 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-eeecef26-18d2-4030-afc5-4ebfcfe3ceb5): no suitable block pools found to scan.  Waiting 1814399933 ms.
2024-01-20 22:16:46,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 22:16:46,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 22:16:46,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid 768cd4ba-c7dc-426b-a8c8-483fcdf2227f) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 22:16:46,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid 768cd4ba-c7dc-426b-a8c8-483fcdf2227f) service to master/172.18.0.2:54310
2024-01-20 22:16:46,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x566dedde234,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 22:16:46,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:20:35,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x59c524a4cea,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 22:20:35,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:38:55,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 22:38:55,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 22:38:56,200 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 22:38:56,284 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 22:38:56,284 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 22:38:56,288 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 22:38:56,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-20 22:38:56,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 22:38:56,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 22:38:56,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 22:38:56,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 22:38:56,507 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 22:38:56,524 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 22:38:56,529 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 22:38:56,534 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 22:38:56,535 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 22:38:56,536 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 22:38:56,545 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 22:38:56,567 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34743
2024-01-20 22:38:56,567 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 22:38:56,780 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34743
2024-01-20 22:38:56,988 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 22:38:57,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 22:38:57,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 22:38:57,394 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 22:38:57,425 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 22:38:57,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 22:38:57,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 22:38:57,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 22:38:57,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 22:38:57,566 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 22:38:57,567 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 22:38:58,170 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-20 22:38:58,171 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,171 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:38:58,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,303 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,304 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-290709276-172.18.0.2-1705790328183 is not formatted for BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,304 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:38:58,304 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-290709276-172.18.0.2-1705790328183 directory /tmp/hadoop/dfs/data/current/BP-290709276-172.18.0.2-1705790328183/current
2024-01-20 22:38:58,386 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 22:38:58,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=178358391;bpid=BP-290709276-172.18.0.2-1705790328183;lv=-56;nsInfo=lv=-63;cid=CID-2d22698e-c393-4ab9-adbe-72631a4165c4;nsid=178358391;c=0;bpid=BP-290709276-172.18.0.2-1705790328183;dnuuid=null
2024-01-20 22:38:58,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID f00c4886-b020-440c-b630-22b0e1c2b669
2024-01-20 22:38:58,540 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b3957d6d-9000-4d60-90af-f32289a7e40e
2024-01-20 22:38:58,540 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 22:38:58,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 22:38:58,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:38:58,554 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-290709276-172.18.0.2-1705790328183 on /tmp/hadoop/dfs/data/current: 8ms
2024-01-20 22:38:58,554 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-290709276-172.18.0.2-1705790328183: 10ms
2024-01-20 22:38:58,554 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:38:58,555 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 22:38:58,555 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-01-20 22:38:58,756 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data
2024-01-20 22:38:58,756 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b3957d6d-9000-4d60-90af-f32289a7e40e): finished scanning block pool BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,769 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705792866769 with interval 21600000
2024-01-20 22:38:58,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 22:38:58,852 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b3957d6d-9000-4d60-90af-f32289a7e40e): no suitable block pools found to scan.  Waiting 1814399904 ms.
2024-01-20 22:38:58,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 22:38:58,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 22:38:59,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid f00c4886-b020-440c-b630-22b0e1c2b669) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 22:38:59,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid f00c4886-b020-440c-b630-22b0e1c2b669) service to master/172.18.0.2:54310
2024-01-20 22:38:59,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x69d2b81a79b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 22:38:59,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-290709276-172.18.0.2-1705790328183
2024-01-21 16:57:02,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-21 16:57:02,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-21 16:57:03,268 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-21 16:57:03,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-21 16:57:03,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-21 16:57:03,357 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-21 16:57:03,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-21 16:57:03,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-21 16:57:03,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-21 16:57:03,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-21 16:57:03,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-21 16:57:03,528 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-21 16:57:03,535 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-21 16:57:03,539 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-21 16:57:03,543 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-21 16:57:03,554 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-21 16:57:03,554 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-21 16:57:03,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-21 16:57:03,567 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36901
2024-01-21 16:57:03,568 INFO org.mortbay.log: jetty-6.1.26
2024-01-21 16:57:03,815 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36901
2024-01-21 16:57:04,051 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-21 16:57:04,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-21 16:57:04,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-21 16:57:04,445 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-21 16:57:04,463 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-21 16:57:04,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-21 16:57:04,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-21 16:57:04,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-21 16:57:04,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-21 16:57:04,640 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-21 16:57:04,641 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-21 16:57:05,263 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-21 16:57:05,264 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,264 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-21 16:57:05,368 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,368 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,369 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1175791455-172.18.0.2-1705856215266 is not formatted for BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,369 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-21 16:57:05,369 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1175791455-172.18.0.2-1705856215266 directory /tmp/hadoop/dfs/data/current/BP-1175791455-172.18.0.2-1705856215266/current
2024-01-21 16:57:05,429 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-21 16:57:05,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=619814465;bpid=BP-1175791455-172.18.0.2-1705856215266;lv=-56;nsInfo=lv=-63;cid=CID-598f264a-2ba9-4c96-a8a5-cc4228cf780d;nsid=619814465;c=0;bpid=BP-1175791455-172.18.0.2-1705856215266;dnuuid=null
2024-01-21 16:57:05,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 9821ce81-11c2-4ae5-8744-9efc0dc4c617
2024-01-21 16:57:05,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-65ddb5b2-cd18-4b04-8bcf-895019f97223
2024-01-21 16:57:05,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-21 16:57:05,625 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-21 16:57:05,626 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,626 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data/current...
2024-01-21 16:57:05,638 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1175791455-172.18.0.2-1705856215266 on /tmp/hadoop/dfs/data/current: 12ms
2024-01-21 16:57:05,638 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1175791455-172.18.0.2-1705856215266: 12ms
2024-01-21 16:57:05,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data/current...
2024-01-21 16:57:05,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-21 16:57:05,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-21 16:57:05,827 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data
2024-01-21 16:57:05,828 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-65ddb5b2-cd18-4b04-8bcf-895019f97223): finished scanning block pool BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,845 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705866637845 with interval 21600000
2024-01-21 16:57:05,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-21 16:57:05,911 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-65ddb5b2-cd18-4b04-8bcf-895019f97223): no suitable block pools found to scan.  Waiting 1814399916 ms.
2024-01-21 16:57:05,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-21 16:57:05,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-21 16:57:06,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid 9821ce81-11c2-4ae5-8744-9efc0dc4c617) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-21 16:57:06,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid 9821ce81-11c2-4ae5-8744-9efc0dc4c617) service to master/172.18.0.2:54310
2024-01-21 16:57:06,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x96068d97a33,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-21 16:57:06,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1175791455-172.18.0.2-1705856215266
2024-01-22 12:21:22,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-22 12:21:22,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-22 12:21:23,425 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-22 12:21:23,519 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-22 12:21:23,519 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-22 12:21:23,523 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-22 12:21:23,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-22 12:21:23,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-22 12:21:23,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-22 12:21:23,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-22 12:21:23,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-22 12:21:23,710 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-22 12:21:23,716 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-22 12:21:23,730 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-22 12:21:23,735 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-22 12:21:23,737 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-22 12:21:23,737 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-22 12:21:23,750 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-22 12:21:23,760 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34507
2024-01-22 12:21:23,760 INFO org.mortbay.log: jetty-6.1.26
2024-01-22 12:21:24,034 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34507
2024-01-22 12:21:24,234 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-22 12:21:24,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-22 12:21:24,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-22 12:21:24,636 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-22 12:21:24,668 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-22 12:21:24,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-22 12:21:24,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-22 12:21:24,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-22 12:21:24,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-22 12:21:24,790 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-22 12:21:24,791 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-22 12:21:25,362 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-22 12:21:25,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,363 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-22 12:21:25,498 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,514 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-637491475-172.18.0.2-1705926075383 is not formatted for BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-22 12:21:25,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-637491475-172.18.0.2-1705926075383 directory /tmp/hadoop/dfs/data/current/BP-637491475-172.18.0.2-1705926075383/current
2024-01-22 12:21:25,665 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-22 12:21:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=134794854;bpid=BP-637491475-172.18.0.2-1705926075383;lv=-56;nsInfo=lv=-63;cid=CID-7b4d5891-c564-4515-8f64-e172cc0493f4;nsid=134794854;c=0;bpid=BP-637491475-172.18.0.2-1705926075383;dnuuid=null
2024-01-22 12:21:25,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID a2178d10-9914-4745-bdee-7ed9a4697c7e
2024-01-22 12:21:25,943 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-062b0fb6-6c02-4e98-b8dc-5fe4d3f550a5
2024-01-22 12:21:25,943 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-22 12:21:25,947 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-22 12:21:25,947 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data/current...
2024-01-22 12:21:25,984 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-637491475-172.18.0.2-1705926075383 on /tmp/hadoop/dfs/data/current: 29ms
2024-01-22 12:21:25,984 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-637491475-172.18.0.2-1705926075383: 37ms
2024-01-22 12:21:25,984 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data/current...
2024-01-22 12:21:25,985 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-22 12:21:25,985 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-22 12:21:26,178 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data
2024-01-22 12:21:26,178 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-062b0fb6-6c02-4e98-b8dc-5fe4d3f550a5): finished scanning block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:26,195 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705926881195 with interval 21600000
2024-01-22 12:21:26,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-22 12:21:26,274 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-062b0fb6-6c02-4e98-b8dc-5fe4d3f550a5): no suitable block pools found to scan.  Waiting 1814399903 ms.
2024-01-22 12:21:26,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-22 12:21:26,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-22 12:21:26,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid a2178d10-9914-4745-bdee-7ed9a4697c7e) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-22 12:21:26,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid a2178d10-9914-4745-bdee-7ed9a4697c7e) service to master/172.18.0.2:54310
2024-01-22 12:21:26,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6c4a71b6be,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-22 12:21:26,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:34:41,394 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-637491475-172.18.0.2-1705926075383 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-22 12:51:30,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x21060b97ce2,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 129 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-22 12:51:30,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 14:49:35,418 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3006ms
No GCs detected
2024-01-22 15:03:32,919 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1784ms
GC pool 'Copy' had collection(s): count=1 time=2243ms
2024-01-31 11:32:42,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 11:32:42,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 11:32:43,777 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 11:32:43,871 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 11:32:43,871 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 11:32:43,876 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 11:32:43,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-31 11:32:43,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 11:32:43,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 11:32:43,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 11:32:43,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 11:32:44,051 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 11:32:44,058 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 11:32:44,071 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 11:32:44,076 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 11:32:44,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 11:32:44,078 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 11:32:44,087 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 11:32:44,097 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41059
2024-01-31 11:32:44,098 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 11:32:44,330 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41059
2024-01-31 11:32:44,520 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 11:32:44,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 11:32:44,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 11:32:44,921 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 11:32:44,953 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 11:32:44,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 11:32:45,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 11:32:45,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 11:32:45,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.4:54310 starting to offer service
2024-01-31 11:32:45,101 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 11:32:45,102 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 11:32:45,670 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave1
2024-01-31 11:32:45,671 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,671 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 11:32:45,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1071215085-172.18.0.4-1706700755668 is not formatted for BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 11:32:45,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1071215085-172.18.0.4-1706700755668 directory /tmp/hadoop/dfs/data/current/BP-1071215085-172.18.0.4-1706700755668/current
2024-01-31 11:32:45,855 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 11:32:45,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=634398172;bpid=BP-1071215085-172.18.0.4-1706700755668;lv=-56;nsInfo=lv=-63;cid=CID-3e869996-b220-45f2-a5b6-cf4fc36d8ce8;nsid=634398172;c=0;bpid=BP-1071215085-172.18.0.4-1706700755668;dnuuid=null
2024-01-31 11:32:46,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 5bac4068-e7ff-4383-a039-fbdb27a7b8e8
2024-01-31 11:32:46,113 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ff617199-0dc8-49c5-9add-58563e911457
2024-01-31 11:32:46,113 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 11:32:46,117 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 11:32:46,117 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:46,118 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 11:32:46,129 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1071215085-172.18.0.4-1706700755668 on /tmp/hadoop/dfs/data/current: 10ms
2024-01-31 11:32:46,129 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1071215085-172.18.0.4-1706700755668: 13ms
2024-01-31 11:32:46,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 11:32:46,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-01-31 11:32:46,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 11:32:46,361 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data
2024-01-31 11:32:46,362 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ff617199-0dc8-49c5-9add-58563e911457): finished scanning block pool BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:46,376 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706709947376 with interval 21600000
2024-01-31 11:32:46,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid null) service to master/172.18.0.4:54310 beginning handshake with NN
2024-01-31 11:32:46,470 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ff617199-0dc8-49c5-9add-58563e911457): no suitable block pools found to scan.  Waiting 1814399891 ms.
2024-01-31 11:32:46,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid null) service to master/172.18.0.4:54310 successfully registered with NN
2024-01-31 11:32:46,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.4:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 11:32:46,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid 5bac4068-e7ff-4383-a039-fbdb27a7b8e8) service to master/172.18.0.4:54310 trying to claim ACTIVE state with txid=1
2024-01-31 11:32:46,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid 5bac4068-e7ff-4383-a039-fbdb27a7b8e8) service to master/172.18.0.4:54310
2024-01-31 11:32:46,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6f1f9d59385,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 79 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 11:32:46,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1071215085-172.18.0.4-1706700755668
2024-01-31 13:02:03,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 13:02:03,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 13:02:03,912 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 13:02:04,005 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 13:02:04,005 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 13:02:04,008 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 13:02:04,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-31 13:02:04,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 13:02:04,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 13:02:04,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 13:02:04,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 13:02:04,218 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 13:02:04,230 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 13:02:04,250 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 13:02:04,256 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 13:02:04,257 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 13:02:04,257 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 13:02:04,257 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 13:02:04,282 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45755
2024-01-31 13:02:04,283 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 13:02:04,560 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45755
2024-01-31 13:02:04,779 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 13:02:05,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 13:02:05,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 13:02:05,182 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 13:02:05,213 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 13:02:05,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 13:02:05,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 13:02:05,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 13:02:05,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-31 13:02:05,419 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 13:02:05,420 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 13:02:06,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave1
2024-01-31 13:02:06,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:02:06,181 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,181 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,182 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-304942432-172.18.0.2-1706706115706 is not formatted for BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,182 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:02:06,182 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-304942432-172.18.0.2-1706706115706 directory /tmp/hadoop/dfs/data/current/BP-304942432-172.18.0.2-1706706115706/current
2024-01-31 13:02:06,245 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 13:02:06,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=513807859;bpid=BP-304942432-172.18.0.2-1706706115706;lv=-56;nsInfo=lv=-63;cid=CID-8167d057-3746-45e6-bc43-1f73010e984f;nsid=513807859;c=0;bpid=BP-304942432-172.18.0.2-1706706115706;dnuuid=null
2024-01-31 13:02:06,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 8d27c7a4-cd1e-4c28-9d3d-13dffa4f52af
2024-01-31 13:02:06,412 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-6fab46e7-7307-4fb4-916a-0f18b26b7456
2024-01-31 13:02:06,412 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 13:02:06,416 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 13:02:06,417 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:02:06,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-304942432-172.18.0.2-1706706115706 on /tmp/hadoop/dfs/data/current: 11ms
2024-01-31 13:02:06,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-304942432-172.18.0.2-1706706115706: 13ms
2024-01-31 13:02:06,431 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:02:06,431 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-01-31 13:02:06,431 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 13:02:06,689 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data
2024-01-31 13:02:06,690 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-6fab46e7-7307-4fb4-916a-0f18b26b7456): finished scanning block pool BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,715 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706707565715 with interval 21600000
2024-01-31 13:02:06,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-31 13:02:06,813 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-6fab46e7-7307-4fb4-916a-0f18b26b7456): no suitable block pools found to scan.  Waiting 1814399876 ms.
2024-01-31 13:02:06,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-31 13:02:06,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 13:02:07,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid 8d27c7a4-cd1e-4c28-9d3d-13dffa4f52af) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-31 13:02:07,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid 8d27c7a4-cd1e-4c28-9d3d-13dffa4f52af) service to master/172.18.0.2:54310
2024-01-31 13:02:07,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xbd1ed6b621a,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 69 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 13:02:07,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:26:07,288 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-304942432-172.18.0.2-1706706115706 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-31 13:29:16,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 13:29:16,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 13:29:17,320 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 13:29:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 13:29:17,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 13:29:17,415 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 13:29:17,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-31 13:29:17,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 13:29:17,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 13:29:17,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 13:29:17,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 13:29:17,634 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 13:29:17,649 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 13:29:17,670 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 13:29:17,678 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 13:29:17,680 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 13:29:17,680 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 13:29:17,681 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 13:29:17,707 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40551
2024-01-31 13:29:17,707 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 13:29:17,959 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40551
2024-01-31 13:29:18,166 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 13:29:18,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 13:29:18,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 13:29:18,659 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 13:29:18,697 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 13:29:18,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 13:29:18,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 13:29:18,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 13:29:18,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-31 13:29:18,837 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 13:29:18,838 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 13:29:19,536 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave1
2024-01-31 13:29:19,537 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,537 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:29:19,723 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-583157701-172.18.0.2-1706707749215 is not formatted for BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,725 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:29:19,725 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-583157701-172.18.0.2-1706707749215 directory /tmp/hadoop/dfs/data/current/BP-583157701-172.18.0.2-1706707749215/current
2024-01-31 13:29:19,777 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 13:29:19,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=306995317;bpid=BP-583157701-172.18.0.2-1706707749215;lv=-56;nsInfo=lv=-63;cid=CID-058974d8-4383-4236-99ec-4ce43c431678;nsid=306995317;c=0;bpid=BP-583157701-172.18.0.2-1706707749215;dnuuid=null
2024-01-31 13:29:19,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 84663425-3158-4c90-a377-af0963b75596
2024-01-31 13:29:19,935 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ac4446d4-fbdb-4d18-a22d-7b34fdb16a87
2024-01-31 13:29:19,935 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 13:29:19,939 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 13:29:19,940 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,947 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:29:19,961 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-583157701-172.18.0.2-1706707749215 on /tmp/hadoop/dfs/data/current: 14ms
2024-01-31 13:29:19,962 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-583157701-172.18.0.2-1706707749215: 22ms
2024-01-31 13:29:19,962 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:29:19,962 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 13:29:19,962 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 13:29:20,184 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data
2024-01-31 13:29:20,186 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ac4446d4-fbdb-4d18-a22d-7b34fdb16a87): finished scanning block pool BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:20,205 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706725456205 with interval 21600000
2024-01-31 13:29:20,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-31 13:29:20,272 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ac4446d4-fbdb-4d18-a22d-7b34fdb16a87): no suitable block pools found to scan.  Waiting 1814399901 ms.
2024-01-31 13:29:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-31 13:29:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 13:29:20,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid 84663425-3158-4c90-a377-af0963b75596) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-31 13:29:20,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid 84663425-3158-4c90-a377-af0963b75596) service to master/172.18.0.2:54310
2024-01-31 13:29:20,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd4e3c5f187e,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 214 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 13:29:20,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-583157701-172.18.0.2-1706707749215
2024-01-31 14:57:02,519 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3498ms
No GCs detected
2024-01-31 15:17:20,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 15:17:20,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 15:17:21,804 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 15:17:21,924 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 15:17:21,924 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 15:17:21,928 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 15:17:21,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-31 15:17:21,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 15:17:21,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 15:17:21,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 15:17:21,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 15:17:22,125 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 15:17:22,131 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 15:17:22,146 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 15:17:22,151 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 15:17:22,153 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 15:17:22,153 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 15:17:22,163 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 15:17:22,185 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42873
2024-01-31 15:17:22,185 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 15:17:22,447 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42873
2024-01-31 15:17:22,650 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 15:17:22,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 15:17:22,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 15:17:23,057 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 15:17:23,089 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 15:17:23,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 15:17:23,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 15:17:23,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 15:17:23,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.4:54310 starting to offer service
2024-01-31 15:17:23,229 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 15:17:23,230 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 15:17:23,884 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave1
2024-01-31 15:17:23,885 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:23,885 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 15:17:24,271 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,277 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,278 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1431395744-172.18.0.4-1706714233822 is not formatted for BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,278 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 15:17:24,278 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1431395744-172.18.0.4-1706714233822 directory /tmp/hadoop/dfs/data/current/BP-1431395744-172.18.0.4-1706714233822/current
2024-01-31 15:17:24,356 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 15:17:24,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1371280364;bpid=BP-1431395744-172.18.0.4-1706714233822;lv=-56;nsInfo=lv=-63;cid=CID-cbc3682d-53ae-4915-b762-092f6d4a0db0;nsid=1371280364;c=0;bpid=BP-1431395744-172.18.0.4-1706714233822;dnuuid=null
2024-01-31 15:17:24,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 718ad682-d0fa-4b89-be7b-ec0edc48abb0
2024-01-31 15:17:24,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-8e79e14b-86e3-4ab8-9265-3eaa58267408
2024-01-31 15:17:24,543 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 15:17:24,549 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 15:17:24,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,559 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 15:17:24,609 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1431395744-172.18.0.4-1706714233822 on /tmp/hadoop/dfs/data/current: 49ms
2024-01-31 15:17:24,609 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1431395744-172.18.0.4-1706714233822: 52ms
2024-01-31 15:17:24,610 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 15:17:24,610 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 15:17:24,611 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2024-01-31 15:17:24,942 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data
2024-01-31 15:17:24,945 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8e79e14b-86e3-4ab8-9265-3eaa58267408): finished scanning block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,963 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706718492963 with interval 21600000
2024-01-31 15:17:24,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid null) service to master/172.18.0.4:54310 beginning handshake with NN
2024-01-31 15:17:25,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid null) service to master/172.18.0.4:54310 successfully registered with NN
2024-01-31 15:17:25,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.4:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 15:17:25,136 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8e79e14b-86e3-4ab8-9265-3eaa58267408): no suitable block pools found to scan.  Waiting 1814399797 ms.
2024-01-31 15:17:25,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid 718ad682-d0fa-4b89-be7b-ec0edc48abb0) service to master/172.18.0.4:54310 trying to claim ACTIVE state with txid=1
2024-01-31 15:17:25,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid 718ad682-d0fa-4b89-be7b-ec0edc48abb0) service to master/172.18.0.4:54310
2024-01-31 15:17:25,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xecd2f29b69,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 15:17:25,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 16:15:04,174 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4628ms
GC pool 'Copy' had collection(s): count=1 time=4742ms
2024-01-31 16:28:13,959 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1431395744-172.18.0.4-1706714233822 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-31 17:27:59,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x80cca3e5ac9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 26 msec to generate and 159 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 17:27:59,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 18:06:10,934 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1811ms
No GCs detected
2024-01-31 18:07:37,895 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1032ms
No GCs detected
2024-01-31 22:59:08,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 22:59:08,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 22:59:08,911 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 22:59:08,990 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 22:59:08,990 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 22:59:08,994 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 22:59:08,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-01-31 22:59:09,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 22:59:09,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 22:59:09,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 22:59:09,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 22:59:09,223 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 22:59:09,229 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 22:59:09,245 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 22:59:09,251 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 22:59:09,252 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 22:59:09,252 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 22:59:09,252 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 22:59:09,274 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33393
2024-01-31 22:59:09,274 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 22:59:09,505 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33393
2024-01-31 22:59:09,728 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 22:59:10,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 22:59:10,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 22:59:10,148 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 22:59:10,183 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 22:59:10,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 22:59:10,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 22:59:10,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 22:59:10,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.6:54310 starting to offer service
2024-01-31 22:59:10,300 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 22:59:10,301 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 22:59:10,935 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave1
2024-01-31 22:59:10,936 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:10,936 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 22:59:11,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-355379469-172.18.0.6-1706741940834 is not formatted for BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 22:59:11,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-355379469-172.18.0.6-1706741940834 directory /tmp/hadoop/dfs/data/current/BP-355379469-172.18.0.6-1706741940834/current
2024-01-31 22:59:11,127 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 22:59:11,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=321320448;bpid=BP-355379469-172.18.0.6-1706741940834;lv=-56;nsInfo=lv=-63;cid=CID-9f407693-9c9d-42b2-929b-9cb929a35059;nsid=321320448;c=0;bpid=BP-355379469-172.18.0.6-1706741940834;dnuuid=null
2024-01-31 22:59:11,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 6cd9f0df-0998-4203-a531-0a733b593d30
2024-01-31 22:59:11,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b922f016-bb6f-4a10-b9d4-9afcf346535d
2024-01-31 22:59:11,294 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 22:59:11,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 22:59:11,299 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,300 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 22:59:11,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-355379469-172.18.0.6-1706741940834 on /tmp/hadoop/dfs/data/current: 22ms
2024-01-31 22:59:11,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-355379469-172.18.0.6-1706741940834: 23ms
2024-01-31 22:59:11,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 22:59:11,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 22:59:11,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 22:59:11,598 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data
2024-01-31 22:59:11,599 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b922f016-bb6f-4a10-b9d4-9afcf346535d): finished scanning block pool BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,611 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706745690611 with interval 21600000
2024-01-31 22:59:11,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid null) service to master/172.18.0.6:54310 beginning handshake with NN
2024-01-31 22:59:11,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid null) service to master/172.18.0.6:54310 successfully registered with NN
2024-01-31 22:59:11,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.6:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 22:59:11,714 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b922f016-bb6f-4a10-b9d4-9afcf346535d): no suitable block pools found to scan.  Waiting 1814399884 ms.
2024-01-31 22:59:11,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid 6cd9f0df-0998-4203-a531-0a733b593d30) service to master/172.18.0.6:54310 trying to claim ACTIVE state with txid=1
2024-01-31 22:59:11,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid 6cd9f0df-0998-4203-a531-0a733b593d30) service to master/172.18.0.6:54310
2024-01-31 22:59:11,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa9efdde8e02,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 54 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 22:59:11,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-355379469-172.18.0.6-1706741940834
2024-02-03 17:10:22,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-02-03 17:10:22,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-02-03 17:10:23,656 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-02-03 17:10:23,762 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-02-03 17:10:23,762 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-02-03 17:10:23,766 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-02-03 17:10:23,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2024-02-03 17:10:23,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-02-03 17:10:23,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-02-03 17:10:23,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-02-03 17:10:23,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-02-03 17:10:24,014 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-02-03 17:10:24,021 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-02-03 17:10:24,036 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-02-03 17:10:24,041 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-02-03 17:10:24,042 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-02-03 17:10:24,042 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-02-03 17:10:24,054 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-02-03 17:10:24,075 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39169
2024-02-03 17:10:24,076 INFO org.mortbay.log: jetty-6.1.26
2024-02-03 17:10:24,300 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39169
2024-02-03 17:10:24,507 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-02-03 17:10:24,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-02-03 17:10:24,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-02-03 17:10:24,966 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-02-03 17:10:24,986 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-02-03 17:10:25,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-02-03 17:10:25,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-02-03 17:10:25,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-02-03 17:10:25,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.6:54310 starting to offer service
2024-02-03 17:10:25,128 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-02-03 17:10:25,129 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-02-03 17:10:25,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave1
2024-02-03 17:10:25,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-02-03 17:10:25,927 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,927 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,928 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1439553629-172.18.0.6-1706980215407 is not formatted for BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,928 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-02-03 17:10:25,928 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1439553629-172.18.0.6-1706980215407 directory /tmp/hadoop/dfs/data/current/BP-1439553629-172.18.0.6-1706980215407/current
2024-02-03 17:10:25,991 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-02-03 17:10:26,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1537516082;bpid=BP-1439553629-172.18.0.6-1706980215407;lv=-56;nsInfo=lv=-63;cid=CID-0dc58037-822b-4bcf-b296-f3e933fa8198;nsid=1537516082;c=0;bpid=BP-1439553629-172.18.0.6-1706980215407;dnuuid=null
2024-02-03 17:10:26,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 897fc491-f5c9-402a-bb98-b87f10150df7
2024-02-03 17:10:26,198 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ef88e758-430c-4707-a2f4-e68ddb6ef1d1
2024-02-03 17:10:26,198 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-02-03 17:10:26,202 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-02-03 17:10:26,202 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:26,210 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data/current...
2024-02-03 17:10:26,239 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1439553629-172.18.0.6-1706980215407 on /tmp/hadoop/dfs/data/current: 29ms
2024-02-03 17:10:26,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1439553629-172.18.0.6-1706980215407: 38ms
2024-02-03 17:10:26,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data/current...
2024-02-03 17:10:26,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-02-03 17:10:26,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-02-03 17:10:26,489 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data
2024-02-03 17:10:26,490 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ef88e758-430c-4707-a2f4-e68ddb6ef1d1): finished scanning block pool BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:26,505 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1707001293505 with interval 21600000
2024-02-03 17:10:26,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid null) service to master/172.18.0.6:54310 beginning handshake with NN
2024-02-03 17:10:26,595 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-ef88e758-430c-4707-a2f4-e68ddb6ef1d1): no suitable block pools found to scan.  Waiting 1814399887 ms.
2024-02-03 17:10:26,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid null) service to master/172.18.0.6:54310 successfully registered with NN
2024-02-03 17:10:26,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.6:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-02-03 17:10:26,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid 897fc491-f5c9-402a-bb98-b87f10150df7) service to master/172.18.0.6:54310 trying to claim ACTIVE state with txid=1
2024-02-03 17:10:26,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid 897fc491-f5c9-402a-bb98-b87f10150df7) service to master/172.18.0.6:54310
2024-02-03 17:10:26,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe2b02803e40,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 54 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-02-03 17:10:26,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1439553629-172.18.0.6-1706980215407
