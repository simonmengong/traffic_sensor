2020-11-26 14:26:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-11-26 14:26:21,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-11-26 14:26:22,307 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-11-26 14:26:22,416 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-11-26 14:26:22,416 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-11-26 14:26:22,420 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-11-26 14:26:22,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-11-26 14:26:22,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-11-26 14:26:22,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-11-26 14:26:22,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-11-26 14:26:22,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-11-26 14:26:22,570 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-11-26 14:26:22,577 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-11-26 14:26:22,590 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-11-26 14:26:22,594 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-11-26 14:26:22,595 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-11-26 14:26:22,595 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-11-26 14:26:22,595 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-11-26 14:26:22,609 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33541
2020-11-26 14:26:22,609 INFO org.mortbay.log: jetty-6.1.26
2020-11-26 14:26:22,781 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33541
2020-11-26 14:26:22,897 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-11-26 14:26:22,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-11-26 14:26:22,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-11-26 14:26:23,011 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-11-26 14:26:23,044 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-11-26 14:26:23,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-11-26 14:26:23,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-11-26 14:26:23,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-11-26 14:26:23,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-11-26 14:26:23,194 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-11-26 14:26:23,194 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-11-26 14:26:23,537 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 61@slave2
2020-11-26 14:26:23,538 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,538 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 14:26:23,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-33536009-172.18.0.2-1606371975169 is not formatted for BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 14:26:23,613 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-33536009-172.18.0.2-1606371975169 directory /tmp/hadoop/dfs/data/current/BP-33536009-172.18.0.2-1606371975169/current
2020-11-26 14:26:23,622 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-11-26 14:26:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1701568202;bpid=BP-33536009-172.18.0.2-1606371975169;lv=-56;nsInfo=lv=-63;cid=CID-a667e8b6-c7c4-443b-90cf-9eeda9af83fd;nsid=1701568202;c=0;bpid=BP-33536009-172.18.0.2-1606371975169;dnuuid=null
2020-11-26 14:26:23,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 26e5562b-24de-4c03-9aea-b92e4af86688
2020-11-26 14:26:23,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28
2020-11-26 14:26:23,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-11-26 14:26:23,669 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-11-26 14:26:23,669 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,670 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 14:26:23,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-33536009-172.18.0.2-1606371975169 on /tmp/hadoop/dfs/data/current: 6ms
2020-11-26 14:26:23,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-33536009-172.18.0.2-1606371975169: 7ms
2020-11-26 14:26:23,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 14:26:23,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-11-26 14:26:23,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-11-26 14:26:23,830 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-33536009-172.18.0.2-1606371975169 on volume /tmp/hadoop/dfs/data
2020-11-26 14:26:23,832 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): finished scanning block pool BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:26:23,854 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1606377311854 with interval 21600000
2020-11-26 14:26:23,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-11-26 14:26:23,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-11-26 14:26:23,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-11-26 14:26:23,917 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): no suitable block pools found to scan.  Waiting 1814399913 ms.
2020-11-26 14:26:23,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid 26e5562b-24de-4c03-9aea-b92e4af86688) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-11-26 14:26:23,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-33536009-172.18.0.2-1606371975169 (Datanode Uuid 26e5562b-24de-4c03-9aea-b92e4af86688) service to master/172.18.0.2:54310
2020-11-26 14:26:24,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1a36bbe4f76,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 29 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-11-26 14:26:24,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-33536009-172.18.0.2-1606371975169
2020-11-26 14:29:10,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741825_1001 src: /172.18.0.2:34038 dest: /172.18.0.4:50010
2020-11-26 14:29:10,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34038, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741825_1001, duration: 164418324
2020-11-26 14:29:10,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:10,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741827_1003 src: /172.18.0.2:34042 dest: /172.18.0.4:50010
2020-11-26 14:29:11,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34042, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741827_1003, duration: 79551110
2020-11-26 14:29:11,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741830_1006 src: /172.18.0.2:34048 dest: /172.18.0.4:50010
2020-11-26 14:29:11,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34048, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741830_1006, duration: 46248832
2020-11-26 14:29:11,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741833_1009 src: /172.18.0.2:34054 dest: /172.18.0.4:50010
2020-11-26 14:29:11,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34054, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741833_1009, duration: 48491075
2020-11-26 14:29:11,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741834_1010 src: /172.18.0.2:34056 dest: /172.18.0.4:50010
2020-11-26 14:29:11,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34056, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741834_1010, duration: 39720651
2020-11-26 14:29:11,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741835_1011 src: /172.18.0.2:34058 dest: /172.18.0.4:50010
2020-11-26 14:29:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34058, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741835_1011, duration: 51854810
2020-11-26 14:29:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:11,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741836_1012 src: /172.18.0.2:34060 dest: /172.18.0.4:50010
2020-11-26 14:29:11,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34060, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741836_1012, duration: 63727075
2020-11-26 14:29:11,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741842_1018 src: /172.18.0.2:34072 dest: /172.18.0.4:50010
2020-11-26 14:29:12,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34072, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741842_1018, duration: 44035470
2020-11-26 14:29:12,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741843_1019 src: /172.18.0.2:34074 dest: /172.18.0.4:50010
2020-11-26 14:29:12,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34074, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741843_1019, duration: 40659033
2020-11-26 14:29:12,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741849_1025 src: /172.18.0.2:34086 dest: /172.18.0.4:50010
2020-11-26 14:29:12,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34086, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741849_1025, duration: 42348200
2020-11-26 14:29:12,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741851_1027 src: /172.18.0.2:34090 dest: /172.18.0.4:50010
2020-11-26 14:29:12,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34090, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741851_1027, duration: 77961745
2020-11-26 14:29:12,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741852_1028 src: /172.18.0.2:34092 dest: /172.18.0.4:50010
2020-11-26 14:29:12,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34092, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741852_1028, duration: 54938493
2020-11-26 14:29:12,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:12,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741853_1029 src: /172.18.0.2:34094 dest: /172.18.0.4:50010
2020-11-26 14:29:13,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34094, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741853_1029, duration: 41332554
2020-11-26 14:29:13,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:13,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741854_1030 src: /172.18.0.2:34096 dest: /172.18.0.4:50010
2020-11-26 14:29:13,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34096, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741854_1030, duration: 36113766
2020-11-26 14:29:13,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:29:13,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741855_1031 src: /172.18.0.2:34098 dest: /172.18.0.4:50010
2020-11-26 14:29:13,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34098, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1332833478_1, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741855_1031, duration: 38722488
2020-11-26 14:29:13,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:30:40,652 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741827_1003 for rescanning.
2020-11-26 14:30:56,654 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): no suitable block pools found to scan.  Waiting 1814127176 ms.
2020-11-26 14:30:57,892 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741830_1006 for rescanning.
2020-11-26 14:31:06,908 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741833_1009 for rescanning.
2020-11-26 14:31:14,954 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741834_1010 for rescanning.
2020-11-26 14:31:15,615 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741835_1011 for rescanning.
2020-11-26 14:31:22,878 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741836_1012 for rescanning.
2020-11-26 14:31:47,303 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741842_1018 for rescanning.
2020-11-26 14:31:48,401 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741843_1019 for rescanning.
2020-11-26 14:32:13,035 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741849_1025 for rescanning.
2020-11-26 14:32:21,119 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741851_1027 for rescanning.
2020-11-26 14:32:27,660 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741852_1028 for rescanning.
2020-11-26 14:32:29,326 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741853_1029 for rescanning.
2020-11-26 14:32:35,592 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741854_1030 for rescanning.
2020-11-26 14:32:37,491 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): Scheduling suspect block BP-33536009-172.18.0.2-1606371975169:blk_1073741855_1031 for rescanning.
2020-11-26 14:32:49,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741857_1033 src: /172.18.0.4:39636 dest: /172.18.0.4:50010
2020-11-26 14:32:49,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741858_1034 src: /172.18.0.3:49098 dest: /172.18.0.4:50010
2020-11-26 14:32:49,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39636, dest: /172.18.0.4:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741857_1033, duration: 42057156
2020-11-26 14:32:49,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:49,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49098, dest: /172.18.0.4:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741858_1034, duration: 47395604
2020-11-26 14:32:49,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:49,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741860_1036 src: /172.18.0.4:39646 dest: /172.18.0.4:50010
2020-11-26 14:32:49,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741859_1035 src: /172.18.0.3:49104 dest: /172.18.0.4:50010
2020-11-26 14:32:49,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39646, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741860_1036, duration: 30764247
2020-11-26 14:32:49,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:49,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49104, dest: /172.18.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741859_1035, duration: 4239894
2020-11-26 14:32:49,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:49,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741861_1037 src: /172.18.0.4:39652 dest: /172.18.0.4:50010
2020-11-26 14:32:49,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39652, dest: /172.18.0.4:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741861_1037, duration: 4766249
2020-11-26 14:32:49,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:49,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741862_1038 src: /172.18.0.3:49114 dest: /172.18.0.4:50010
2020-11-26 14:32:49,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49114, dest: /172.18.0.4:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741862_1038, duration: 34693366
2020-11-26 14:32:49,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:49,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741863_1039 src: /172.18.0.4:39660 dest: /172.18.0.4:50010
2020-11-26 14:32:50,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741864_1040 src: /172.18.0.3:49122 dest: /172.18.0.4:50010
2020-11-26 14:32:50,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39660, dest: /172.18.0.4:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741863_1039, duration: 22401595
2020-11-26 14:32:50,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49122, dest: /172.18.0.4:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741864_1040, duration: 12710206
2020-11-26 14:32:50,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741865_1041 src: /172.18.0.4:39668 dest: /172.18.0.4:50010
2020-11-26 14:32:50,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39668, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741865_1041, duration: 28047989
2020-11-26 14:32:50,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741866_1042 src: /172.18.0.3:49130 dest: /172.18.0.4:50010
2020-11-26 14:32:50,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49130, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741866_1042, duration: 39749656
2020-11-26 14:32:50,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741867_1043 src: /172.18.0.4:39676 dest: /172.18.0.4:50010
2020-11-26 14:32:50,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39676, dest: /172.18.0.4:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741867_1043, duration: 13821463
2020-11-26 14:32:50,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741867_1043, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741868_1044 src: /172.18.0.3:49138 dest: /172.18.0.4:50010
2020-11-26 14:32:50,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49138, dest: /172.18.0.4:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741868_1044, duration: 4820139
2020-11-26 14:32:50,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741869_1045 src: /172.18.0.4:39684 dest: /172.18.0.4:50010
2020-11-26 14:32:50,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39684, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741869_1045, duration: 32401993
2020-11-26 14:32:50,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741869_1045, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741870_1046 src: /172.18.0.3:49146 dest: /172.18.0.4:50010
2020-11-26 14:32:50,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49146, dest: /172.18.0.4:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741870_1046, duration: 56977214
2020-11-26 14:32:50,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741871_1047 src: /172.18.0.4:39692 dest: /172.18.0.4:50010
2020-11-26 14:32:50,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39692, dest: /172.18.0.4:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741871_1047, duration: 11010497
2020-11-26 14:32:50,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741871_1047, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741872_1048 src: /172.18.0.3:49154 dest: /172.18.0.4:50010
2020-11-26 14:32:50,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49154, dest: /172.18.0.4:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741872_1048, duration: 42995917
2020-11-26 14:32:50,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:50,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741873_1049 src: /172.18.0.4:39700 dest: /172.18.0.4:50010
2020-11-26 14:32:50,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39700, dest: /172.18.0.4:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741873_1049, duration: 7425856
2020-11-26 14:32:50,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:50,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741874_1050 src: /172.18.0.3:49162 dest: /172.18.0.4:50010
2020-11-26 14:32:50,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49162, dest: /172.18.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741874_1050, duration: 6820463
2020-11-26 14:32:50,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741875_1051 src: /172.18.0.4:39708 dest: /172.18.0.4:50010
2020-11-26 14:32:51,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741876_1052 src: /172.18.0.3:49170 dest: /172.18.0.4:50010
2020-11-26 14:32:51,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39708, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741875_1051, duration: 30183652
2020-11-26 14:32:51,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49170, dest: /172.18.0.4:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741876_1052, duration: 2642106
2020-11-26 14:32:51,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741877_1053 src: /172.18.0.4:39716 dest: /172.18.0.4:50010
2020-11-26 14:32:51,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741878_1054 src: /172.18.0.3:49178 dest: /172.18.0.4:50010
2020-11-26 14:32:51,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39716, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741877_1053, duration: 9051057
2020-11-26 14:32:51,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49178, dest: /172.18.0.4:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741878_1054, duration: 44992470
2020-11-26 14:32:51,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741879_1055 src: /172.18.0.4:39724 dest: /172.18.0.4:50010
2020-11-26 14:32:51,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741880_1056 src: /172.18.0.3:49186 dest: /172.18.0.4:50010
2020-11-26 14:32:51,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39724, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741879_1055, duration: 47209128
2020-11-26 14:32:51,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49186, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741880_1056, duration: 58675986
2020-11-26 14:32:51,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741881_1057 src: /172.18.0.4:39732 dest: /172.18.0.4:50010
2020-11-26 14:32:51,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741882_1058 src: /172.18.0.3:49194 dest: /172.18.0.4:50010
2020-11-26 14:32:51,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39732, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741881_1057, duration: 9889858
2020-11-26 14:32:51,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49194, dest: /172.18.0.4:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741882_1058, duration: 11814832
2020-11-26 14:32:51,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741883_1059 src: /172.18.0.4:39740 dest: /172.18.0.4:50010
2020-11-26 14:32:51,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39740, dest: /172.18.0.4:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741883_1059, duration: 1321160
2020-11-26 14:32:51,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741884_1060 src: /172.18.0.3:49202 dest: /172.18.0.4:50010
2020-11-26 14:32:51,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49202, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741884_1060, duration: 11392831
2020-11-26 14:32:51,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741885_1061 src: /172.18.0.4:39748 dest: /172.18.0.4:50010
2020-11-26 14:32:51,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39748, dest: /172.18.0.4:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741885_1061, duration: 4292172
2020-11-26 14:32:51,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741885_1061, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:32:51,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741886_1062 src: /172.18.0.3:49210 dest: /172.18.0.4:50010
2020-11-26 14:32:51,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:49210, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000001_0_-1877766486_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741886_1062, duration: 2999611
2020-11-26 14:32:51,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 14:32:51,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-33536009-172.18.0.2-1606371975169:blk_1073741887_1063 src: /172.18.0.4:39756 dest: /172.18.0.4:50010
2020-11-26 14:32:51,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:39756, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126143031_0000_m_000000_0_-1550450420_26, offset: 0, srvID: 26e5562b-24de-4c03-9aea-b92e4af86688, blockid: BP-33536009-172.18.0.2-1606371975169:blk_1073741887_1063, duration: 31177577
2020-11-26 14:32:51,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-33536009-172.18.0.2-1606371975169:blk_1073741887_1063, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 14:34:26,157 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c0d48516-3632-4fd5-8212-b4d6ebae7e28): no suitable block pools found to scan.  Waiting 1813917673 ms.
2020-11-26 22:49:10,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-11-26 22:49:10,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-11-26 22:49:11,412 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-11-26 22:49:11,552 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-11-26 22:49:11,553 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-11-26 22:49:11,558 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-11-26 22:49:11,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-11-26 22:49:11,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-11-26 22:49:11,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-11-26 22:49:11,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-11-26 22:49:11,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-11-26 22:49:11,777 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-11-26 22:49:11,785 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-11-26 22:49:11,800 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-11-26 22:49:11,806 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-11-26 22:49:11,818 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-11-26 22:49:11,818 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-11-26 22:49:11,819 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-11-26 22:49:11,846 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38391
2020-11-26 22:49:11,846 INFO org.mortbay.log: jetty-6.1.26
2020-11-26 22:49:12,106 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38391
2020-11-26 22:49:12,291 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-11-26 22:49:12,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-11-26 22:49:12,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-11-26 22:49:12,469 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-11-26 22:49:12,512 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-11-26 22:49:12,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-11-26 22:49:12,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-11-26 22:49:12,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-11-26 22:49:12,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-11-26 22:49:12,715 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-11-26 22:49:12,716 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-11-26 22:49:13,271 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 66@slave2
2020-11-26 22:49:13,272 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,272 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 22:49:13,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,388 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-826070094-172.18.0.2-1606402143158 is not formatted for BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,388 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-11-26 22:49:13,388 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-826070094-172.18.0.2-1606402143158 directory /tmp/hadoop/dfs/data/current/BP-826070094-172.18.0.2-1606402143158/current
2020-11-26 22:49:13,390 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-11-26 22:49:13,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=644343777;bpid=BP-826070094-172.18.0.2-1606402143158;lv=-56;nsInfo=lv=-63;cid=CID-fb04172a-742b-4aef-b727-76c3b62004ab;nsid=644343777;c=0;bpid=BP-826070094-172.18.0.2-1606402143158;dnuuid=null
2020-11-26 22:49:13,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 50792693-13e8-43d2-9e61-c8917afef742
2020-11-26 22:49:13,462 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9
2020-11-26 22:49:13,462 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-11-26 22:49:13,466 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-11-26 22:49:13,467 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,468 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 22:49:13,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-826070094-172.18.0.2-1606402143158 on /tmp/hadoop/dfs/data/current: 8ms
2020-11-26 22:49:13,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-826070094-172.18.0.2-1606402143158: 9ms
2020-11-26 22:49:13,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data/current...
2020-11-26 22:49:13,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-11-26 22:49:13,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-11-26 22:49:13,696 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-826070094-172.18.0.2-1606402143158 on volume /tmp/hadoop/dfs/data
2020-11-26 22:49:13,699 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): finished scanning block pool BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:49:13,714 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1606403561714 with interval 21600000
2020-11-26 22:49:13,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-11-26 22:49:13,803 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): no suitable block pools found to scan.  Waiting 1814399889 ms.
2020-11-26 22:49:13,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-11-26 22:49:13,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-11-26 22:49:13,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid 50792693-13e8-43d2-9e61-c8917afef742) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-11-26 22:49:13,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-826070094-172.18.0.2-1606402143158 (Datanode Uuid 50792693-13e8-43d2-9e61-c8917afef742) service to master/172.18.0.2:54310
2020-11-26 22:49:14,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1a6b9a26a488,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 62 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-11-26 22:49:14,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-826070094-172.18.0.2-1606402143158
2020-11-26 22:52:23,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741826_1002 src: /172.18.0.2:38990 dest: /172.18.0.4:50010
2020-11-26 22:52:23,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38990, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741826_1002, duration: 274194396
2020-11-26 22:52:23,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:23,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741827_1003 src: /172.18.0.2:38992 dest: /172.18.0.4:50010
2020-11-26 22:52:23,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38992, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741827_1003, duration: 149396920
2020-11-26 22:52:23,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:23,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741829_1005 src: /172.18.0.2:38996 dest: /172.18.0.4:50010
2020-11-26 22:52:23,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38996, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741829_1005, duration: 83551890
2020-11-26 22:52:23,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:23,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741830_1006 src: /172.18.0.2:38998 dest: /172.18.0.4:50010
2020-11-26 22:52:23,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:38998, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741830_1006, duration: 64646611
2020-11-26 22:52:23,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741833_1009 src: /172.18.0.2:39004 dest: /172.18.0.4:50010
2020-11-26 22:52:24,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39004, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741833_1009, duration: 85411231
2020-11-26 22:52:24,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741834_1010 src: /172.18.0.2:39006 dest: /172.18.0.4:50010
2020-11-26 22:52:24,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39006, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741834_1010, duration: 93518294
2020-11-26 22:52:24,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741837_1013 src: /172.18.0.2:39012 dest: /172.18.0.4:50010
2020-11-26 22:52:24,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39012, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741837_1013, duration: 71165871
2020-11-26 22:52:24,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:24,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741838_1014 src: /172.18.0.2:39014 dest: /172.18.0.4:50010
2020-11-26 22:52:24,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39014, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741838_1014, duration: 97148795
2020-11-26 22:52:24,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741843_1019 src: /172.18.0.2:39024 dest: /172.18.0.4:50010
2020-11-26 22:52:25,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39024, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741843_1019, duration: 88440492
2020-11-26 22:52:25,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741845_1021 src: /172.18.0.2:39028 dest: /172.18.0.4:50010
2020-11-26 22:52:25,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39028, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741845_1021, duration: 70607888
2020-11-26 22:52:25,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741846_1022 src: /172.18.0.2:39030 dest: /172.18.0.4:50010
2020-11-26 22:52:25,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39030, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741846_1022, duration: 81287761
2020-11-26 22:52:25,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:25,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741848_1024 src: /172.18.0.2:39034 dest: /172.18.0.4:50010
2020-11-26 22:52:25,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39034, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741848_1024, duration: 86999132
2020-11-26 22:52:25,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741851_1027 src: /172.18.0.2:39040 dest: /172.18.0.4:50010
2020-11-26 22:52:26,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39040, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741851_1027, duration: 94096910
2020-11-26 22:52:26,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741854_1030 src: /172.18.0.2:39046 dest: /172.18.0.4:50010
2020-11-26 22:52:26,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39046, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741854_1030, duration: 76729892
2020-11-26 22:52:26,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741856_1032 src: /172.18.0.2:39050 dest: /172.18.0.4:50010
2020-11-26 22:52:26,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39050, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741856_1032, duration: 59000712
2020-11-26 22:52:26,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741857_1033 src: /172.18.0.2:39052 dest: /172.18.0.4:50010
2020-11-26 22:52:26,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39052, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741857_1033, duration: 74044839
2020-11-26 22:52:26,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741859_1035 src: /172.18.0.2:39056 dest: /172.18.0.4:50010
2020-11-26 22:52:26,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39056, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741859_1035, duration: 48643036
2020-11-26 22:52:26,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741860_1036 src: /172.18.0.2:39058 dest: /172.18.0.4:50010
2020-11-26 22:52:26,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39058, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741860_1036, duration: 48948595
2020-11-26 22:52:26,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:26,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741862_1038 src: /172.18.0.2:39062 dest: /172.18.0.4:50010
2020-11-26 22:52:26,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39062, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741862_1038, duration: 58169639
2020-11-26 22:52:26,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741863_1039 src: /172.18.0.2:39064 dest: /172.18.0.4:50010
2020-11-26 22:52:27,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39064, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741863_1039, duration: 60600921
2020-11-26 22:52:27,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741864_1040 src: /172.18.0.2:39066 dest: /172.18.0.4:50010
2020-11-26 22:52:27,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39066, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741864_1040, duration: 52835021
2020-11-26 22:52:27,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:27,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741869_1045 src: /172.18.0.2:39076 dest: /172.18.0.4:50010
2020-11-26 22:52:27,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39076, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741869_1045, duration: 93131103
2020-11-26 22:52:27,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741875_1051 src: /172.18.0.2:39088 dest: /172.18.0.4:50010
2020-11-26 22:52:28,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39088, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741875_1051, duration: 56129942
2020-11-26 22:52:28,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741876_1052 src: /172.18.0.2:39090 dest: /172.18.0.4:50010
2020-11-26 22:52:28,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39090, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741876_1052, duration: 47729015
2020-11-26 22:52:28,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741877_1053 src: /172.18.0.2:39092 dest: /172.18.0.4:50010
2020-11-26 22:52:28,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39092, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741877_1053, duration: 99774975
2020-11-26 22:52:28,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741880_1056 src: /172.18.0.2:39098 dest: /172.18.0.4:50010
2020-11-26 22:52:28,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39098, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741880_1056, duration: 54254524
2020-11-26 22:52:28,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741881_1057 src: /172.18.0.2:39100 dest: /172.18.0.4:50010
2020-11-26 22:52:28,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39100, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741881_1057, duration: 53340084
2020-11-26 22:52:28,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741883_1059 src: /172.18.0.2:39104 dest: /172.18.0.4:50010
2020-11-26 22:52:28,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39104, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741883_1059, duration: 42433769
2020-11-26 22:52:28,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:28,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741885_1061 src: /172.18.0.2:39108 dest: /172.18.0.4:50010
2020-11-26 22:52:28,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39108, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741885_1061, duration: 98082941
2020-11-26 22:52:28,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:52:29,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741888_1064 src: /172.18.0.2:39114 dest: /172.18.0.4:50010
2020-11-26 22:52:29,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39114, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1519637404_1, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741888_1064, duration: 43754872
2020-11-26 22:52:29,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741888_1064, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 22:54:08,494 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741827_1003 for rescanning.
2020-11-26 22:54:09,793 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741826_1002 for rescanning.
2020-11-26 22:54:21,738 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741829_1005 for rescanning.
2020-11-26 22:54:32,738 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741830_1006 for rescanning.
2020-11-26 22:54:45,303 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741833_1009 for rescanning.
2020-11-26 22:54:55,876 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741834_1010 for rescanning.
2020-11-26 22:55:09,260 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741837_1013 for rescanning.
2020-11-26 22:55:18,356 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741838_1014 for rescanning.
2020-11-26 22:55:43,753 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741843_1019 for rescanning.
2020-11-26 22:55:55,713 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741845_1021 for rescanning.
2020-11-26 22:56:03,978 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741846_1022 for rescanning.
2020-11-26 22:56:15,626 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741848_1024 for rescanning.
2020-11-26 22:56:31,821 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741851_1027 for rescanning.
2020-11-26 22:56:48,694 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741854_1030 for rescanning.
2020-11-26 22:56:59,806 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741856_1032 for rescanning.
2020-11-26 22:57:07,247 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741857_1033 for rescanning.
2020-11-26 22:57:18,955 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741859_1035 for rescanning.
2020-11-26 22:57:21,911 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741860_1036 for rescanning.
2020-11-26 22:57:32,864 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741862_1038 for rescanning.
2020-11-26 22:57:41,869 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741863_1039 for rescanning.
2020-11-26 22:57:43,893 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741864_1040 for rescanning.
2020-11-26 22:58:16,443 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741869_1045 for rescanning.
2020-11-26 22:58:49,610 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741875_1051 for rescanning.
2020-11-26 22:58:51,306 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741876_1052 for rescanning.
2020-11-26 22:59:00,583 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741877_1053 for rescanning.
2020-11-26 22:59:14,355 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741880_1056 for rescanning.
2020-11-26 22:59:22,953 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741881_1057 for rescanning.
2020-11-26 22:59:33,668 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741883_1059 for rescanning.
2020-11-26 22:59:44,737 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741885_1061 for rescanning.
2020-11-26 23:00:00,292 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): Scheduling suspect block BP-826070094-172.18.0.2-1606402143158:blk_1073741888_1064 for rescanning.
2020-11-26 23:00:10,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741889_1065 src: /172.18.0.4:44926 dest: /172.18.0.4:50010
2020-11-26 23:00:10,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741890_1066 src: /172.18.0.3:54388 dest: /172.18.0.4:50010
2020-11-26 23:00:11,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44926, dest: /172.18.0.4:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741889_1065, duration: 64383237
2020-11-26 23:00:11,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54388, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741890_1066, duration: 99790984
2020-11-26 23:00:11,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741890_1066, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741891_1067 src: /172.18.0.4:44934 dest: /172.18.0.4:50010
2020-11-26 23:00:11,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44934, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741891_1067, duration: 19895018
2020-11-26 23:00:11,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741891_1067, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741892_1068 src: /172.18.0.3:54396 dest: /172.18.0.4:50010
2020-11-26 23:00:11,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54396, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741892_1068, duration: 5983205
2020-11-26 23:00:11,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741892_1068, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741893_1069 src: /172.18.0.4:44942 dest: /172.18.0.4:50010
2020-11-26 23:00:11,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44942, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741893_1069, duration: 17389085
2020-11-26 23:00:11,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741893_1069, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741894_1070 src: /172.18.0.3:54404 dest: /172.18.0.4:50010
2020-11-26 23:00:11,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54404, dest: /172.18.0.4:50010, bytes: 98, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741894_1070, duration: 1774264
2020-11-26 23:00:11,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741894_1070, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:11,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741895_1071 src: /172.18.0.4:44950 dest: /172.18.0.4:50010
2020-11-26 23:00:11,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44950, dest: /172.18.0.4:50010, bytes: 81, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741895_1071, duration: 4950544
2020-11-26 23:00:11,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741895_1071, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:11,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741896_1072 src: /172.18.0.3:54412 dest: /172.18.0.4:50010
2020-11-26 23:00:12,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54412, dest: /172.18.0.4:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741896_1072, duration: 11728118
2020-11-26 23:00:12,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741896_1072, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741897_1073 src: /172.18.0.4:44958 dest: /172.18.0.4:50010
2020-11-26 23:00:12,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44958, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741897_1073, duration: 19373486
2020-11-26 23:00:12,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741897_1073, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741898_1074 src: /172.18.0.3:54420 dest: /172.18.0.4:50010
2020-11-26 23:00:12,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54420, dest: /172.18.0.4:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741898_1074, duration: 14525629
2020-11-26 23:00:12,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741898_1074, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741899_1075 src: /172.18.0.4:44966 dest: /172.18.0.4:50010
2020-11-26 23:00:12,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741900_1076 src: /172.18.0.3:54428 dest: /172.18.0.4:50010
2020-11-26 23:00:12,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44966, dest: /172.18.0.4:50010, bytes: 60, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741899_1075, duration: 26664802
2020-11-26 23:00:12,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741899_1075, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54428, dest: /172.18.0.4:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741900_1076, duration: 17314737
2020-11-26 23:00:12,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741900_1076, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741901_1077 src: /172.18.0.4:44974 dest: /172.18.0.4:50010
2020-11-26 23:00:12,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44974, dest: /172.18.0.4:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741901_1077, duration: 4424273
2020-11-26 23:00:12,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741901_1077, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741902_1078 src: /172.18.0.3:54436 dest: /172.18.0.4:50010
2020-11-26 23:00:12,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54436, dest: /172.18.0.4:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741902_1078, duration: 59266465
2020-11-26 23:00:12,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741902_1078, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:12,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741903_1079 src: /172.18.0.4:44982 dest: /172.18.0.4:50010
2020-11-26 23:00:12,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741904_1080 src: /172.18.0.3:54444 dest: /172.18.0.4:50010
2020-11-26 23:00:12,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44982, dest: /172.18.0.4:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741903_1079, duration: 35726685
2020-11-26 23:00:12,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741903_1079, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:12,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54444, dest: /172.18.0.4:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741904_1080, duration: 36916564
2020-11-26 23:00:12,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741904_1080, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741905_1081 src: /172.18.0.4:44990 dest: /172.18.0.4:50010
2020-11-26 23:00:13,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44990, dest: /172.18.0.4:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741905_1081, duration: 20116295
2020-11-26 23:00:13,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741905_1081, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741906_1082 src: /172.18.0.3:54452 dest: /172.18.0.4:50010
2020-11-26 23:00:13,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54452, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741906_1082, duration: 1133136
2020-11-26 23:00:13,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741906_1082, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741907_1083 src: /172.18.0.4:44998 dest: /172.18.0.4:50010
2020-11-26 23:00:13,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:44998, dest: /172.18.0.4:50010, bytes: 55, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741907_1083, duration: 6294465
2020-11-26 23:00:13,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741907_1083, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741908_1084 src: /172.18.0.3:54460 dest: /172.18.0.4:50010
2020-11-26 23:00:13,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54460, dest: /172.18.0.4:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741908_1084, duration: 6687770
2020-11-26 23:00:13,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741908_1084, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741909_1085 src: /172.18.0.4:45006 dest: /172.18.0.4:50010
2020-11-26 23:00:13,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45006, dest: /172.18.0.4:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741909_1085, duration: 18357283
2020-11-26 23:00:13,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741909_1085, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:13,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741910_1086 src: /172.18.0.3:54468 dest: /172.18.0.4:50010
2020-11-26 23:00:13,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54468, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741910_1086, duration: 16379140
2020-11-26 23:00:13,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741910_1086, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:13,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741911_1087 src: /172.18.0.4:45014 dest: /172.18.0.4:50010
2020-11-26 23:00:13,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45014, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741911_1087, duration: 50424131
2020-11-26 23:00:13,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741911_1087, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741912_1088 src: /172.18.0.3:54476 dest: /172.18.0.4:50010
2020-11-26 23:00:14,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54476, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741912_1088, duration: 4023461
2020-11-26 23:00:14,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741912_1088, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741913_1089 src: /172.18.0.4:45022 dest: /172.18.0.4:50010
2020-11-26 23:00:14,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45022, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741913_1089, duration: 8501145
2020-11-26 23:00:14,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741913_1089, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741914_1090 src: /172.18.0.3:54484 dest: /172.18.0.4:50010
2020-11-26 23:00:14,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741915_1091 src: /172.18.0.4:45030 dest: /172.18.0.4:50010
2020-11-26 23:00:14,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54484, dest: /172.18.0.4:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741914_1090, duration: 23764736
2020-11-26 23:00:14,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741914_1090, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45030, dest: /172.18.0.4:50010, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741915_1091, duration: 31882128
2020-11-26 23:00:14,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741915_1091, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741917_1093 src: /172.18.0.4:45036 dest: /172.18.0.4:50010
2020-11-26 23:00:14,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741916_1092 src: /172.18.0.3:54494 dest: /172.18.0.4:50010
2020-11-26 23:00:14,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54494, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741916_1092, duration: 22315995
2020-11-26 23:00:14,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741916_1092, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45036, dest: /172.18.0.4:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741917_1093, duration: 10923886
2020-11-26 23:00:14,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741917_1093, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741918_1094 src: /172.18.0.4:45044 dest: /172.18.0.4:50010
2020-11-26 23:00:14,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741919_1095 src: /172.18.0.3:54504 dest: /172.18.0.4:50010
2020-11-26 23:00:14,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54504, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741919_1095, duration: 22695401
2020-11-26 23:00:14,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741919_1095, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:14,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45044, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741918_1094, duration: 24525500
2020-11-26 23:00:14,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741918_1094, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:14,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741920_1096 src: /172.18.0.3:54508 dest: /172.18.0.4:50010
2020-11-26 23:00:14,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54508, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741920_1096, duration: 30280840
2020-11-26 23:00:14,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741920_1096, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741921_1097 src: /172.18.0.3:54512 dest: /172.18.0.4:50010
2020-11-26 23:00:15,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54512, dest: /172.18.0.4:50010, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741921_1097, duration: 27625845
2020-11-26 23:00:15,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741921_1097, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741922_1098 src: /172.18.0.3:54516 dest: /172.18.0.4:50010
2020-11-26 23:00:15,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741923_1099 src: /172.18.0.4:45062 dest: /172.18.0.4:50010
2020-11-26 23:00:15,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54516, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741922_1098, duration: 35586143
2020-11-26 23:00:15,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741922_1098, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45062, dest: /172.18.0.4:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741923_1099, duration: 31178590
2020-11-26 23:00:15,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741923_1099, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741924_1100 src: /172.18.0.3:54524 dest: /172.18.0.4:50010
2020-11-26 23:00:15,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741925_1101 src: /172.18.0.4:45070 dest: /172.18.0.4:50010
2020-11-26 23:00:15,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54524, dest: /172.18.0.4:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741924_1100, duration: 31940008
2020-11-26 23:00:15,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741924_1100, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45070, dest: /172.18.0.4:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741925_1101, duration: 40549441
2020-11-26 23:00:15,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741925_1101, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741926_1102 src: /172.18.0.3:54532 dest: /172.18.0.4:50010
2020-11-26 23:00:15,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54532, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741926_1102, duration: 17539863
2020-11-26 23:00:15,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741926_1102, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:15,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741927_1103 src: /172.18.0.4:45078 dest: /172.18.0.4:50010
2020-11-26 23:00:15,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45078, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741927_1103, duration: 10869780
2020-11-26 23:00:15,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741927_1103, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:15,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741928_1104 src: /172.18.0.3:54540 dest: /172.18.0.4:50010
2020-11-26 23:00:15,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741929_1105 src: /172.18.0.4:45086 dest: /172.18.0.4:50010
2020-11-26 23:00:15,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54540, dest: /172.18.0.4:50010, bytes: 75, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741928_1104, duration: 9593226
2020-11-26 23:00:15,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741928_1104, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45086, dest: /172.18.0.4:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741929_1105, duration: 16174272
2020-11-26 23:00:16,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741929_1105, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741930_1106 src: /172.18.0.3:54548 dest: /172.18.0.4:50010
2020-11-26 23:00:16,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741931_1107 src: /172.18.0.4:45094 dest: /172.18.0.4:50010
2020-11-26 23:00:16,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54548, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741930_1106, duration: 20830077
2020-11-26 23:00:16,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741930_1106, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45094, dest: /172.18.0.4:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741931_1107, duration: 31938492
2020-11-26 23:00:16,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741931_1107, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741932_1108 src: /172.18.0.3:54556 dest: /172.18.0.4:50010
2020-11-26 23:00:16,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54556, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741932_1108, duration: 5049596
2020-11-26 23:00:16,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741932_1108, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741933_1109 src: /172.18.0.4:45102 dest: /172.18.0.4:50010
2020-11-26 23:00:16,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45102, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741933_1109, duration: 29054556
2020-11-26 23:00:16,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741933_1109, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741934_1110 src: /172.18.0.3:54564 dest: /172.18.0.4:50010
2020-11-26 23:00:16,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54564, dest: /172.18.0.4:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741934_1110, duration: 763227
2020-11-26 23:00:16,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741934_1110, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741935_1111 src: /172.18.0.4:45110 dest: /172.18.0.4:50010
2020-11-26 23:00:16,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45110, dest: /172.18.0.4:50010, bytes: 59, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741935_1111, duration: 2078831
2020-11-26 23:00:16,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741935_1111, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741936_1112 src: /172.18.0.3:54572 dest: /172.18.0.4:50010
2020-11-26 23:00:16,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741937_1113 src: /172.18.0.4:45118 dest: /172.18.0.4:50010
2020-11-26 23:00:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54572, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741936_1112, duration: 671167
2020-11-26 23:00:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741936_1112, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45118, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741937_1113, duration: 32839004
2020-11-26 23:00:16,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741937_1113, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741938_1114 src: /172.18.0.3:54580 dest: /172.18.0.4:50010
2020-11-26 23:00:16,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54580, dest: /172.18.0.4:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741938_1114, duration: 6281363
2020-11-26 23:00:16,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741938_1114, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:00:16,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741939_1115 src: /172.18.0.4:45126 dest: /172.18.0.4:50010
2020-11-26 23:00:16,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:45126, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000001_0_1890012201_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741939_1115, duration: 24869953
2020-11-26 23:00:16,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741939_1115, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-11-26 23:00:16,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-826070094-172.18.0.2-1606402143158:blk_1073741940_1116 src: /172.18.0.3:54588 dest: /172.18.0.4:50010
2020-11-26 23:00:17,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:54588, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201126225355_0000_m_000000_0_-1233334146_26, offset: 0, srvID: 50792693-13e8-43d2-9e61-c8917afef742, blockid: BP-826070094-172.18.0.2-1606402143158:blk_1073741940_1116, duration: 4006961
2020-11-26 23:00:17,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-826070094-172.18.0.2-1606402143158:blk_1073741940_1116, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-11-26 23:02:12,496 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0da1e86d-64b2-4598-833a-10c27a2d3ad9): no suitable block pools found to scan.  Waiting 1813621196 ms.
2020-11-26 23:02:48,634 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave2/172.18.0.4"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2020-11-26 23:02:51,349 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-11-26 23:02:51,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave2/172.18.0.4
************************************************************/
2020-12-01 21:47:43,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-12-01 21:47:43,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-01 21:47:44,626 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-01 21:47:44,777 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-01 21:47:44,777 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-01 21:47:44,782 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-01 21:47:44,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-12-01 21:47:44,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-01 21:47:44,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-01 21:47:44,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-01 21:47:44,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-01 21:47:45,010 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-01 21:47:45,028 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-01 21:47:45,035 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-01 21:47:45,042 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-01 21:47:45,044 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-01 21:47:45,044 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-01 21:47:45,044 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-01 21:47:45,061 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34401
2020-12-01 21:47:45,061 INFO org.mortbay.log: jetty-6.1.26
2020-12-01 21:47:45,324 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34401
2020-12-01 21:47:45,524 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-01 21:47:45,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-12-01 21:47:45,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-01 21:47:45,696 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-01 21:47:45,737 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-01 21:47:45,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-01 21:47:45,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-01 21:47:45,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-01 21:47:45,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-12-01 21:47:45,909 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-01 21:47:45,909 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-01 21:47:46,530 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 72@slave2
2020-12-01 21:47:46,531 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,531 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-01 21:47:46,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1191596377-172.18.0.2-1606830456145 is not formatted for BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-01 21:47:46,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1191596377-172.18.0.2-1606830456145 directory /tmp/hadoop/dfs/data/current/BP-1191596377-172.18.0.2-1606830456145/current
2020-12-01 21:47:46,688 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-12-01 21:47:46,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=299825135;bpid=BP-1191596377-172.18.0.2-1606830456145;lv=-56;nsInfo=lv=-63;cid=CID-36f672ce-16be-4137-95d3-b261fc7fbade;nsid=299825135;c=0;bpid=BP-1191596377-172.18.0.2-1606830456145;dnuuid=null
2020-12-01 21:47:46,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 5d39ab94-1530-4574-b897-635a3fee0a4f
2020-12-01 21:47:46,759 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-fb7c657c-f8f3-451b-b844-ad1a619f702b
2020-12-01 21:47:46,759 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-12-01 21:47:46,763 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-01 21:47:46,764 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:46,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data/current...
2020-12-01 21:47:46,793 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1191596377-172.18.0.2-1606830456145 on /tmp/hadoop/dfs/data/current: 17ms
2020-12-01 21:47:46,793 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1191596377-172.18.0.2-1606830456145: 29ms
2020-12-01 21:47:46,793 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data/current...
2020-12-01 21:47:46,793 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-12-01 21:47:46,794 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-12-01 21:47:47,011 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1191596377-172.18.0.2-1606830456145 on volume /tmp/hadoop/dfs/data
2020-12-01 21:47:47,014 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): finished scanning block pool BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:47:47,031 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1606844651031 with interval 21600000
2020-12-01 21:47:47,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-12-01 21:47:47,118 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): no suitable block pools found to scan.  Waiting 1814399893 ms.
2020-12-01 21:47:47,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-12-01 21:47:47,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-01 21:47:47,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid 5d39ab94-1530-4574-b897-635a3fee0a4f) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-12-01 21:47:47,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1191596377-172.18.0.2-1606830456145 (Datanode Uuid 5d39ab94-1530-4574-b897-635a3fee0a4f) service to master/172.18.0.2:54310
2020-12-01 21:47:47,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6ffe165b5d33,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 65 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-01 21:47:47,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1191596377-172.18.0.2-1606830456145
2020-12-01 21:49:14,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741827_1003 src: /172.18.0.2:35268 dest: /172.18.0.4:50010
2020-12-01 21:49:15,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35268, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741827_1003, duration: 261444855
2020-12-01 21:49:15,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741828_1004 src: /172.18.0.2:35270 dest: /172.18.0.4:50010
2020-12-01 21:49:15,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35270, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741828_1004, duration: 122149156
2020-12-01 21:49:15,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741831_1007 src: /172.18.0.2:35276 dest: /172.18.0.4:50010
2020-12-01 21:49:15,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35276, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741831_1007, duration: 58857489
2020-12-01 21:49:15,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741832_1008 src: /172.18.0.2:35278 dest: /172.18.0.4:50010
2020-12-01 21:49:15,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35278, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741832_1008, duration: 78533488
2020-12-01 21:49:15,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:15,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741835_1011 src: /172.18.0.2:35284 dest: /172.18.0.4:50010
2020-12-01 21:49:16,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35284, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741835_1011, duration: 76351407
2020-12-01 21:49:16,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741838_1014 src: /172.18.0.2:35290 dest: /172.18.0.4:50010
2020-12-01 21:49:16,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35290, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741838_1014, duration: 67007964
2020-12-01 21:49:16,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741840_1016 src: /172.18.0.2:35294 dest: /172.18.0.4:50010
2020-12-01 21:49:16,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35294, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741840_1016, duration: 108743715
2020-12-01 21:49:16,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741841_1017 src: /172.18.0.2:35296 dest: /172.18.0.4:50010
2020-12-01 21:49:16,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35296, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741841_1017, duration: 66055672
2020-12-01 21:49:16,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741842_1018 src: /172.18.0.2:35298 dest: /172.18.0.4:50010
2020-12-01 21:49:16,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35298, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741842_1018, duration: 61823051
2020-12-01 21:49:16,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:16,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741843_1019 src: /172.18.0.2:35300 dest: /172.18.0.4:50010
2020-12-01 21:49:16,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35300, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741843_1019, duration: 60033983
2020-12-01 21:49:16,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741846_1022 src: /172.18.0.2:35306 dest: /172.18.0.4:50010
2020-12-01 21:49:17,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35306, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741846_1022, duration: 73619653
2020-12-01 21:49:17,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741850_1026 src: /172.18.0.2:35314 dest: /172.18.0.4:50010
2020-12-01 21:49:17,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35314, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741850_1026, duration: 61972603
2020-12-01 21:49:17,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741854_1030 src: /172.18.0.2:35322 dest: /172.18.0.4:50010
2020-12-01 21:49:17,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35322, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741854_1030, duration: 72611415
2020-12-01 21:49:17,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741855_1031 src: /172.18.0.2:35324 dest: /172.18.0.4:50010
2020-12-01 21:49:17,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35324, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741855_1031, duration: 75381973
2020-12-01 21:49:17,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:17,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741856_1032 src: /172.18.0.2:35326 dest: /172.18.0.4:50010
2020-12-01 21:49:18,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35326, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741856_1032, duration: 77416066
2020-12-01 21:49:18,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741859_1035 src: /172.18.0.2:35332 dest: /172.18.0.4:50010
2020-12-01 21:49:18,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35332, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741859_1035, duration: 71649027
2020-12-01 21:49:18,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741861_1037 src: /172.18.0.2:35336 dest: /172.18.0.4:50010
2020-12-01 21:49:18,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35336, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741861_1037, duration: 71133186
2020-12-01 21:49:18,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741862_1038 src: /172.18.0.2:35338 dest: /172.18.0.4:50010
2020-12-01 21:49:18,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35338, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741862_1038, duration: 59529510
2020-12-01 21:49:18,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741862_1038, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741864_1040 src: /172.18.0.2:35346 dest: /172.18.0.4:50010
2020-12-01 21:49:18,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35346, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741864_1040, duration: 88914130
2020-12-01 21:49:18,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741864_1040, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741865_1041 src: /172.18.0.2:35368 dest: /172.18.0.4:50010
2020-12-01 21:49:18,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35368, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741865_1041, duration: 74303976
2020-12-01 21:49:18,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:18,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741866_1042 src: /172.18.0.2:35370 dest: /172.18.0.4:50010
2020-12-01 21:49:18,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35370, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741866_1042, duration: 85507930
2020-12-01 21:49:18,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741866_1042, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741867_1043 src: /172.18.0.2:35372 dest: /172.18.0.4:50010
2020-12-01 21:49:19,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35372, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741867_1043, duration: 106109830
2020-12-01 21:49:19,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741868_1044 src: /172.18.0.2:35374 dest: /172.18.0.4:50010
2020-12-01 21:49:19,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35374, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741868_1044, duration: 46540946
2020-12-01 21:49:19,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741868_1044, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741869_1045 src: /172.18.0.2:35376 dest: /172.18.0.4:50010
2020-12-01 21:49:19,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35376, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741869_1045, duration: 69146679
2020-12-01 21:49:19,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741870_1046 src: /172.18.0.2:35378 dest: /172.18.0.4:50010
2020-12-01 21:49:19,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35378, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741870_1046, duration: 126869879
2020-12-01 21:49:19,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741870_1046, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741871_1047 src: /172.18.0.2:35380 dest: /172.18.0.4:50010
2020-12-01 21:49:19,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35380, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741871_1047, duration: 96824221
2020-12-01 21:49:19,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741872_1048 src: /172.18.0.2:35382 dest: /172.18.0.4:50010
2020-12-01 21:49:19,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35382, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741872_1048, duration: 81203088
2020-12-01 21:49:19,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741872_1048, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741874_1050 src: /172.18.0.2:35386 dest: /172.18.0.4:50010
2020-12-01 21:49:19,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35386, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741874_1050, duration: 52760837
2020-12-01 21:49:19,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741875_1051 src: /172.18.0.2:35388 dest: /172.18.0.4:50010
2020-12-01 21:49:19,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35388, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741875_1051, duration: 70287516
2020-12-01 21:49:19,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:19,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741876_1052 src: /172.18.0.2:35390 dest: /172.18.0.4:50010
2020-12-01 21:49:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35390, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741876_1052, duration: 83349837
2020-12-01 21:49:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741877_1053 src: /172.18.0.2:35392 dest: /172.18.0.4:50010
2020-12-01 21:49:20,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35392, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741877_1053, duration: 79648493
2020-12-01 21:49:20,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741879_1055 src: /172.18.0.2:35396 dest: /172.18.0.4:50010
2020-12-01 21:49:20,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35396, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741879_1055, duration: 76736179
2020-12-01 21:49:20,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741880_1056 src: /172.18.0.2:35398 dest: /172.18.0.4:50010
2020-12-01 21:49:20,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35398, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741880_1056, duration: 60997860
2020-12-01 21:49:20,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:49:20,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741883_1059 src: /172.18.0.2:35404 dest: /172.18.0.4:50010
2020-12-01 21:49:20,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35404, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_483950169_1, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741883_1059, duration: 49169840
2020-12-01 21:49:20,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:50:38,962 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741827_1003 for rescanning.
2020-12-01 21:50:50,004 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741828_1004 for rescanning.
2020-12-01 21:51:01,015 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741831_1007 for rescanning.
2020-12-01 21:51:10,814 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741832_1008 for rescanning.
2020-12-01 21:51:24,310 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741835_1011 for rescanning.
2020-12-01 21:51:44,851 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741838_1014 for rescanning.
2020-12-01 21:51:56,068 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741840_1016 for rescanning.
2020-12-01 21:51:59,102 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741841_1017 for rescanning.
2020-12-01 21:52:07,616 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741842_1018 for rescanning.
2020-12-01 21:52:11,067 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741843_1019 for rescanning.
2020-12-01 21:52:29,530 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741846_1022 for rescanning.
2020-12-01 21:52:50,320 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741850_1026 for rescanning.
2020-12-01 21:53:10,908 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741854_1030 for rescanning.
2020-12-01 21:53:15,238 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741855_1031 for rescanning.
2020-12-01 21:53:21,485 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741856_1032 for rescanning.
2020-12-01 21:53:36,167 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741859_1035 for rescanning.
2020-12-01 21:53:46,916 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741861_1037 for rescanning.
2020-12-01 21:53:52,530 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741862_1038 for rescanning.
2020-12-01 21:54:03,186 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741864_1040 for rescanning.
2020-12-01 21:54:07,662 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741865_1041 for rescanning.
2020-12-01 21:54:13,627 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741866_1042 for rescanning.
2020-12-01 21:54:18,138 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741867_1043 for rescanning.
2020-12-01 21:54:23,929 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741868_1044 for rescanning.
2020-12-01 21:54:29,043 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741869_1045 for rescanning.
2020-12-01 21:54:34,306 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741870_1046 for rescanning.
2020-12-01 21:54:39,258 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741871_1047 for rescanning.
2020-12-01 21:54:44,847 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741872_1048 for rescanning.
2020-12-01 21:54:55,101 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741874_1050 for rescanning.
2020-12-01 21:54:59,953 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741875_1051 for rescanning.
2020-12-01 21:55:05,511 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741876_1052 for rescanning.
2020-12-01 21:55:10,381 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741877_1053 for rescanning.
2020-12-01 21:55:20,846 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741879_1055 for rescanning.
2020-12-01 21:55:26,045 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741880_1056 for rescanning.
2020-12-01 21:55:42,086 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): Scheduling suspect block BP-1191596377-172.18.0.2-1606830456145:blk_1073741883_1059 for rescanning.
2020-12-01 21:56:18,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741889_1065 src: /172.18.0.4:54574 dest: /172.18.0.4:50010
2020-12-01 21:56:18,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741890_1066 src: /172.18.0.3:44018 dest: /172.18.0.4:50010
2020-12-01 21:56:18,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54574, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741889_1065, duration: 67704753
2020-12-01 21:56:18,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:18,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44018, dest: /172.18.0.4:50010, bytes: 37, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741890_1066, duration: 104726885
2020-12-01 21:56:18,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741890_1066, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:18,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741891_1067 src: /172.18.0.4:54582 dest: /172.18.0.4:50010
2020-12-01 21:56:18,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54582, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741891_1067, duration: 12825091
2020-12-01 21:56:18,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741891_1067, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:18,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741892_1068 src: /172.18.0.3:44026 dest: /172.18.0.4:50010
2020-12-01 21:56:18,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44026, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741892_1068, duration: 5351554
2020-12-01 21:56:18,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741892_1068, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:18,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741893_1069 src: /172.18.0.4:54590 dest: /172.18.0.4:50010
2020-12-01 21:56:19,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54590, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741893_1069, duration: 21867990
2020-12-01 21:56:19,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741893_1069, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741894_1070 src: /172.18.0.3:44034 dest: /172.18.0.4:50010
2020-12-01 21:56:19,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741895_1071 src: /172.18.0.4:54598 dest: /172.18.0.4:50010
2020-12-01 21:56:19,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44034, dest: /172.18.0.4:50010, bytes: 98, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741894_1070, duration: 9188281
2020-12-01 21:56:19,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741894_1070, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54598, dest: /172.18.0.4:50010, bytes: 81, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741895_1071, duration: 64553519
2020-12-01 21:56:19,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741895_1071, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741896_1072 src: /172.18.0.3:44042 dest: /172.18.0.4:50010
2020-12-01 21:56:19,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44042, dest: /172.18.0.4:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741896_1072, duration: 1588027
2020-12-01 21:56:19,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741896_1072, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741897_1073 src: /172.18.0.4:54606 dest: /172.18.0.4:50010
2020-12-01 21:56:19,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54606, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741897_1073, duration: 11657612
2020-12-01 21:56:19,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741897_1073, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741898_1074 src: /172.18.0.3:44050 dest: /172.18.0.4:50010
2020-12-01 21:56:19,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44050, dest: /172.18.0.4:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741898_1074, duration: 1833765
2020-12-01 21:56:19,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741898_1074, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:19,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741899_1075 src: /172.18.0.4:54614 dest: /172.18.0.4:50010
2020-12-01 21:56:19,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54614, dest: /172.18.0.4:50010, bytes: 60, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741899_1075, duration: 6877704
2020-12-01 21:56:19,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741899_1075, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:19,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741900_1076 src: /172.18.0.3:44058 dest: /172.18.0.4:50010
2020-12-01 21:56:19,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44058, dest: /172.18.0.4:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741900_1076, duration: 7261068
2020-12-01 21:56:19,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741900_1076, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741901_1077 src: /172.18.0.4:54622 dest: /172.18.0.4:50010
2020-12-01 21:56:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54622, dest: /172.18.0.4:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741901_1077, duration: 13518225
2020-12-01 21:56:20,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741901_1077, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741902_1078 src: /172.18.0.3:44066 dest: /172.18.0.4:50010
2020-12-01 21:56:20,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44066, dest: /172.18.0.4:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741902_1078, duration: 1872387
2020-12-01 21:56:20,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741902_1078, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741903_1079 src: /172.18.0.4:54630 dest: /172.18.0.4:50010
2020-12-01 21:56:20,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54630, dest: /172.18.0.4:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741903_1079, duration: 20523538
2020-12-01 21:56:20,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741903_1079, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741904_1080 src: /172.18.0.3:44074 dest: /172.18.0.4:50010
2020-12-01 21:56:20,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44074, dest: /172.18.0.4:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741904_1080, duration: 24820348
2020-12-01 21:56:20,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741904_1080, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741905_1081 src: /172.18.0.4:54638 dest: /172.18.0.4:50010
2020-12-01 21:56:20,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54638, dest: /172.18.0.4:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741905_1081, duration: 13412944
2020-12-01 21:56:20,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741905_1081, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741906_1082 src: /172.18.0.3:44082 dest: /172.18.0.4:50010
2020-12-01 21:56:20,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44082, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741906_1082, duration: 7817847
2020-12-01 21:56:20,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741906_1082, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741907_1083 src: /172.18.0.4:54646 dest: /172.18.0.4:50010
2020-12-01 21:56:20,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741908_1084 src: /172.18.0.3:44088 dest: /172.18.0.4:50010
2020-12-01 21:56:20,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44088, dest: /172.18.0.4:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741908_1084, duration: 4846259
2020-12-01 21:56:20,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741908_1084, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:20,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54646, dest: /172.18.0.4:50010, bytes: 55, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741907_1083, duration: 22842632
2020-12-01 21:56:20,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741907_1083, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:20,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741909_1085 src: /172.18.0.4:54654 dest: /172.18.0.4:50010
2020-12-01 21:56:20,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54654, dest: /172.18.0.4:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741909_1085, duration: 32345655
2020-12-01 21:56:20,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741909_1085, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741910_1086 src: /172.18.0.3:44098 dest: /172.18.0.4:50010
2020-12-01 21:56:21,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44098, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741910_1086, duration: 30120946
2020-12-01 21:56:21,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741910_1086, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741911_1087 src: /172.18.0.4:54662 dest: /172.18.0.4:50010
2020-12-01 21:56:21,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54662, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741911_1087, duration: 6503287
2020-12-01 21:56:21,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741911_1087, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741912_1088 src: /172.18.0.3:44106 dest: /172.18.0.4:50010
2020-12-01 21:56:21,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44106, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741912_1088, duration: 4944698
2020-12-01 21:56:21,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741912_1088, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741913_1089 src: /172.18.0.4:54670 dest: /172.18.0.4:50010
2020-12-01 21:56:21,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54670, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741913_1089, duration: 5048163
2020-12-01 21:56:21,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741913_1089, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741914_1090 src: /172.18.0.3:44114 dest: /172.18.0.4:50010
2020-12-01 21:56:21,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44114, dest: /172.18.0.4:50010, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741914_1090, duration: 18110281
2020-12-01 21:56:21,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741914_1090, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741915_1091 src: /172.18.0.4:54678 dest: /172.18.0.4:50010
2020-12-01 21:56:21,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54678, dest: /172.18.0.4:50010, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741915_1091, duration: 8967267
2020-12-01 21:56:21,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741915_1091, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741916_1092 src: /172.18.0.3:44122 dest: /172.18.0.4:50010
2020-12-01 21:56:21,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44122, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741916_1092, duration: 1747160
2020-12-01 21:56:21,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741916_1092, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:21,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741917_1093 src: /172.18.0.4:54686 dest: /172.18.0.4:50010
2020-12-01 21:56:21,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54686, dest: /172.18.0.4:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741917_1093, duration: 11468988
2020-12-01 21:56:21,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741917_1093, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:21,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741918_1094 src: /172.18.0.3:44130 dest: /172.18.0.4:50010
2020-12-01 21:56:22,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44130, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741918_1094, duration: 2954120
2020-12-01 21:56:22,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741918_1094, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741919_1095 src: /172.18.0.4:54694 dest: /172.18.0.4:50010
2020-12-01 21:56:22,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54694, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741919_1095, duration: 39145414
2020-12-01 21:56:22,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741919_1095, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741920_1096 src: /172.18.0.3:44138 dest: /172.18.0.4:50010
2020-12-01 21:56:22,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44138, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741920_1096, duration: 1270605
2020-12-01 21:56:22,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741920_1096, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741921_1097 src: /172.18.0.4:54702 dest: /172.18.0.4:50010
2020-12-01 21:56:22,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54702, dest: /172.18.0.4:50010, bytes: 18, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741921_1097, duration: 9495081
2020-12-01 21:56:22,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741921_1097, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741922_1098 src: /172.18.0.3:44146 dest: /172.18.0.4:50010
2020-12-01 21:56:22,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44146, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741922_1098, duration: 13720515
2020-12-01 21:56:22,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741922_1098, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741923_1099 src: /172.18.0.4:54710 dest: /172.18.0.4:50010
2020-12-01 21:56:22,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54710, dest: /172.18.0.4:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741923_1099, duration: 7906769
2020-12-01 21:56:22,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741923_1099, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741924_1100 src: /172.18.0.3:44154 dest: /172.18.0.4:50010
2020-12-01 21:56:22,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44154, dest: /172.18.0.4:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741924_1100, duration: 1146264
2020-12-01 21:56:22,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741924_1100, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741925_1101 src: /172.18.0.4:54718 dest: /172.18.0.4:50010
2020-12-01 21:56:22,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54718, dest: /172.18.0.4:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741925_1101, duration: 13545087
2020-12-01 21:56:22,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741925_1101, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:22,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741926_1102 src: /172.18.0.3:44162 dest: /172.18.0.4:50010
2020-12-01 21:56:22,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44162, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741926_1102, duration: 2814626
2020-12-01 21:56:22,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741926_1102, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:22,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741927_1103 src: /172.18.0.4:54726 dest: /172.18.0.4:50010
2020-12-01 21:56:23,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54726, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741927_1103, duration: 28340159
2020-12-01 21:56:23,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741927_1103, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741928_1104 src: /172.18.0.3:44170 dest: /172.18.0.4:50010
2020-12-01 21:56:23,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44170, dest: /172.18.0.4:50010, bytes: 75, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741928_1104, duration: 2014328
2020-12-01 21:56:23,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741928_1104, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741929_1105 src: /172.18.0.4:54734 dest: /172.18.0.4:50010
2020-12-01 21:56:23,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54734, dest: /172.18.0.4:50010, bytes: 57, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741929_1105, duration: 9001206
2020-12-01 21:56:23,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741929_1105, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741930_1106 src: /172.18.0.3:44178 dest: /172.18.0.4:50010
2020-12-01 21:56:23,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44178, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741930_1106, duration: 8863279
2020-12-01 21:56:23,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741930_1106, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741931_1107 src: /172.18.0.4:54742 dest: /172.18.0.4:50010
2020-12-01 21:56:23,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54742, dest: /172.18.0.4:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741931_1107, duration: 20357940
2020-12-01 21:56:23,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741931_1107, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741932_1108 src: /172.18.0.3:44186 dest: /172.18.0.4:50010
2020-12-01 21:56:23,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44186, dest: /172.18.0.4:50010, bytes: 43, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741932_1108, duration: 2018407
2020-12-01 21:56:23,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741932_1108, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741933_1109 src: /172.18.0.4:54750 dest: /172.18.0.4:50010
2020-12-01 21:56:23,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54750, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741933_1109, duration: 4782925
2020-12-01 21:56:23,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741933_1109, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741934_1110 src: /172.18.0.3:44194 dest: /172.18.0.4:50010
2020-12-01 21:56:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44194, dest: /172.18.0.4:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741934_1110, duration: 784473
2020-12-01 21:56:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741934_1110, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741935_1111 src: /172.18.0.4:54758 dest: /172.18.0.4:50010
2020-12-01 21:56:23,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54758, dest: /172.18.0.4:50010, bytes: 59, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741935_1111, duration: 16385701
2020-12-01 21:56:23,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741935_1111, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:23,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741936_1112 src: /172.18.0.3:44202 dest: /172.18.0.4:50010
2020-12-01 21:56:24,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44202, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741936_1112, duration: 11815819
2020-12-01 21:56:24,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741936_1112, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:24,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741937_1113 src: /172.18.0.4:54766 dest: /172.18.0.4:50010
2020-12-01 21:56:24,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54766, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741937_1113, duration: 27278026
2020-12-01 21:56:24,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741937_1113, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:24,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741938_1114 src: /172.18.0.3:44210 dest: /172.18.0.4:50010
2020-12-01 21:56:24,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741939_1115 src: /172.18.0.4:54774 dest: /172.18.0.4:50010
2020-12-01 21:56:24,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44210, dest: /172.18.0.4:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741938_1114, duration: 2326351
2020-12-01 21:56:24,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741938_1114, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:56:24,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:54774, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000000_0_-1962780208_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741939_1115, duration: 47589243
2020-12-01 21:56:24,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741939_1115, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-01 21:56:24,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1191596377-172.18.0.2-1606830456145:blk_1073741940_1116 src: /172.18.0.3:44218 dest: /172.18.0.4:50010
2020-12-01 21:56:24,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:44218, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20201201215025_0000_m_000001_0_1731366401_26, offset: 0, srvID: 5d39ab94-1530-4574-b897-635a3fee0a4f, blockid: BP-1191596377-172.18.0.2-1606830456145:blk_1073741940_1116, duration: 1733546
2020-12-01 21:56:24,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1191596377-172.18.0.2-1606830456145:blk_1073741940_1116, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-01 21:59:47,476 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fb7c657c-f8f3-451b-b844-ad1a619f702b): no suitable block pools found to scan.  Waiting 1813679535 ms.
2020-12-07 21:30:41,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2020-12-07 21:30:41,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-07 21:30:42,816 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-07 21:30:42,952 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-07 21:30:42,952 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-07 21:30:42,959 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-07 21:30:42,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2020-12-07 21:30:42,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-07 21:30:43,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-07 21:30:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-07 21:30:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-07 21:30:43,171 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-07 21:30:43,184 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-07 21:30:43,202 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-07 21:30:43,208 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-07 21:30:43,212 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-07 21:30:43,213 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-07 21:30:43,213 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-07 21:30:43,238 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 32871
2020-12-07 21:30:43,240 INFO org.mortbay.log: jetty-6.1.26
2020-12-07 21:30:43,473 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:32871
2020-12-07 21:30:43,661 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-07 21:30:43,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2020-12-07 21:30:43,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-07 21:30:43,815 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-07 21:30:43,854 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-07 21:30:43,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-07 21:30:43,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-07 21:30:43,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-07 21:30:43,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2020-12-07 21:30:44,028 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-07 21:30:44,029 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-07 21:30:44,597 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 68@slave2
2020-12-07 21:30:44,598 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,598 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-07 21:30:44,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,715 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1798038798-172.18.0.2-1607347834556 is not formatted for BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2020-12-07 21:30:44,716 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1798038798-172.18.0.2-1607347834556 directory /tmp/hadoop/dfs/data/current/BP-1798038798-172.18.0.2-1607347834556/current
2020-12-07 21:30:44,721 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2020-12-07 21:30:44,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=828757604;bpid=BP-1798038798-172.18.0.2-1607347834556;lv=-56;nsInfo=lv=-63;cid=CID-cc84c8e7-2264-425c-ba9f-37caf69f3ba8;nsid=828757604;c=0;bpid=BP-1798038798-172.18.0.2-1607347834556;dnuuid=null
2020-12-07 21:30:44,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8
2020-12-07 21:30:44,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2
2020-12-07 21:30:44,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2020-12-07 21:30:44,789 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-07 21:30:44,789 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:44,791 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data/current...
2020-12-07 21:30:44,799 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1798038798-172.18.0.2-1607347834556 on /tmp/hadoop/dfs/data/current: 8ms
2020-12-07 21:30:44,799 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1798038798-172.18.0.2-1607347834556: 10ms
2020-12-07 21:30:44,800 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data/current...
2020-12-07 21:30:44,800 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data/current: 0ms
2020-12-07 21:30:44,800 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-12-07 21:30:45,015 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1798038798-172.18.0.2-1607347834556 on volume /tmp/hadoop/dfs/data
2020-12-07 21:30:45,018 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): finished scanning block pool BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:30:45,032 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607351443032 with interval 21600000
2020-12-07 21:30:45,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2020-12-07 21:30:45,130 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): no suitable block pools found to scan.  Waiting 1814399878 ms.
2020-12-07 21:30:45,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2020-12-07 21:30:45,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-07 21:30:45,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2020-12-07 21:30:45,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1798038798-172.18.0.2-1607347834556 (Datanode Uuid 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8) service to master/172.18.0.2:54310
2020-12-07 21:30:45,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2421d380cb51,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 86 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-07 21:30:45,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1798038798-172.18.0.2-1607347834556
2020-12-07 21:34:09,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741827_1003 src: /172.18.0.2:58060 dest: /172.18.0.4:50010
2020-12-07 21:34:09,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58060, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741827_1003, duration: 229855126
2020-12-07 21:34:09,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741829_1005 src: /172.18.0.2:58064 dest: /172.18.0.4:50010
2020-12-07 21:34:09,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58064, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741829_1005, duration: 92007735
2020-12-07 21:34:09,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741831_1007 src: /172.18.0.2:58068 dest: /172.18.0.4:50010
2020-12-07 21:34:09,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58068, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741831_1007, duration: 62929618
2020-12-07 21:34:09,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741832_1008 src: /172.18.0.2:58070 dest: /172.18.0.4:50010
2020-12-07 21:34:09,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58070, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741832_1008, duration: 76540060
2020-12-07 21:34:09,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:09,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741833_1009 src: /172.18.0.2:58072 dest: /172.18.0.4:50010
2020-12-07 21:34:09,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58072, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741833_1009, duration: 71153791
2020-12-07 21:34:09,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:10,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741837_1013 src: /172.18.0.2:58080 dest: /172.18.0.4:50010
2020-12-07 21:34:10,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58080, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741837_1013, duration: 46034168
2020-12-07 21:34:10,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:10,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741838_1014 src: /172.18.0.2:58082 dest: /172.18.0.4:50010
2020-12-07 21:34:10,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58082, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741838_1014, duration: 61112767
2020-12-07 21:34:10,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:34:10,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741839_1015 src: /172.18.0.2:58084 dest: /172.18.0.4:50010
2020-12-07 21:34:10,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:58084, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1434275153_1, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741839_1015, duration: 57319222
2020-12-07 21:34:10,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:36:42,106 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741827_1003 for rescanning.
2020-12-07 21:36:53,987 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741829_1005 for rescanning.
2020-12-07 21:37:06,244 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741831_1007 for rescanning.
2020-12-07 21:37:15,846 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741832_1008 for rescanning.
2020-12-07 21:37:17,300 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741833_1009 for rescanning.
2020-12-07 21:37:40,394 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741837_1013 for rescanning.
2020-12-07 21:37:49,167 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741838_1014 for rescanning.
2020-12-07 21:37:51,936 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): Scheduling suspect block BP-1798038798-172.18.0.2-1607347834556:blk_1073741839_1015 for rescanning.
2020-12-07 21:38:07,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741841_1017 src: /172.18.0.3:34922 dest: /172.18.0.4:50010
2020-12-07 21:38:07,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741842_1018 src: /172.18.0.4:56280 dest: /172.18.0.4:50010
2020-12-07 21:38:08,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34922, dest: /172.18.0.4:50010, bytes: 233, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741841_1017, duration: 69164728
2020-12-07 21:38:08,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56280, dest: /172.18.0.4:50010, bytes: 207, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741842_1018, duration: 42834000
2020-12-07 21:38:08,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741843_1019 src: /172.18.0.3:34928 dest: /172.18.0.4:50010
2020-12-07 21:38:08,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741844_1020 src: /172.18.0.4:56290 dest: /172.18.0.4:50010
2020-12-07 21:38:08,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34928, dest: /172.18.0.4:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741843_1019, duration: 25113266
2020-12-07 21:38:08,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56290, dest: /172.18.0.4:50010, bytes: 210, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741844_1020, duration: 64172810
2020-12-07 21:38:08,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741845_1021 src: /172.18.0.3:34936 dest: /172.18.0.4:50010
2020-12-07 21:38:08,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34936, dest: /172.18.0.4:50010, bytes: 119, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741845_1021, duration: 11646657
2020-12-07 21:38:08,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741846_1022 src: /172.18.0.4:56298 dest: /172.18.0.4:50010
2020-12-07 21:38:08,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56298, dest: /172.18.0.4:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741846_1022, duration: 3486944
2020-12-07 21:38:08,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741847_1023 src: /172.18.0.3:34944 dest: /172.18.0.4:50010
2020-12-07 21:38:08,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34944, dest: /172.18.0.4:50010, bytes: 129, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741847_1023, duration: 18722339
2020-12-07 21:38:08,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:08,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741848_1024 src: /172.18.0.4:56306 dest: /172.18.0.4:50010
2020-12-07 21:38:08,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56306, dest: /172.18.0.4:50010, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741848_1024, duration: 24332861
2020-12-07 21:38:08,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:08,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741849_1025 src: /172.18.0.3:34952 dest: /172.18.0.4:50010
2020-12-07 21:38:08,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34952, dest: /172.18.0.4:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741849_1025, duration: 14234894
2020-12-07 21:38:09,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741850_1026 src: /172.18.0.4:56314 dest: /172.18.0.4:50010
2020-12-07 21:38:09,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56314, dest: /172.18.0.4:50010, bytes: 88, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741850_1026, duration: 27717862
2020-12-07 21:38:09,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741851_1027 src: /172.18.0.3:34960 dest: /172.18.0.4:50010
2020-12-07 21:38:09,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34960, dest: /172.18.0.4:50010, bytes: 144, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741851_1027, duration: 7994634
2020-12-07 21:38:09,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741852_1028 src: /172.18.0.4:56322 dest: /172.18.0.4:50010
2020-12-07 21:38:09,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56322, dest: /172.18.0.4:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741852_1028, duration: 5183159
2020-12-07 21:38:09,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741853_1029 src: /172.18.0.3:34968 dest: /172.18.0.4:50010
2020-12-07 21:38:09,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34968, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741853_1029, duration: 26084515
2020-12-07 21:38:09,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741854_1030 src: /172.18.0.4:56330 dest: /172.18.0.4:50010
2020-12-07 21:38:09,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56330, dest: /172.18.0.4:50010, bytes: 193, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741854_1030, duration: 8075625
2020-12-07 21:38:09,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:09,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741855_1031 src: /172.18.0.3:34976 dest: /172.18.0.4:50010
2020-12-07 21:38:09,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:34976, dest: /172.18.0.4:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000001_0_-380636597_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741855_1031, duration: 5423476
2020-12-07 21:38:09,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-07 21:38:09,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1798038798-172.18.0.2-1607347834556:blk_1073741856_1032 src: /172.18.0.4:56338 dest: /172.18.0.4:50010
2020-12-07 21:38:09,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56338, dest: /172.18.0.4:50010, bytes: 87, op: HDFS_WRITE, cliID: DFSClient_attempt_20201207213628_0000_m_000000_0_2085206987_26, offset: 0, srvID: 9fba6524-b8c9-4ee9-a0db-f3f21e06a9e8, blockid: BP-1798038798-172.18.0.2-1607347834556:blk_1073741856_1032, duration: 3565470
2020-12-07 21:38:09,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1798038798-172.18.0.2-1607347834556:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2020-12-07 21:38:51,117 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9c1a3ab8-c0a4-4250-95e8-e0e32ee2edd2): no suitable block pools found to scan.  Waiting 1813913892 ms.
2020-12-07 22:30:43,067 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1798038798-172.18.0.2-1607347834556 Total blocks: 24, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-12-07 22:48:37,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2861c594c37f,  containing 1 storage report(s), of which we sent 1. The reports had 24 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-07 22:48:37,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1798038798-172.18.0.2-1607347834556
2021-01-23 18:13:16,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:13:16,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:13:17,851 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:13:17,968 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:13:17,968 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:13:17,971 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:13:17,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:13:17,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:13:18,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:13:18,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:13:18,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:13:18,205 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:13:18,214 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:13:18,219 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:13:18,223 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:13:18,225 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:13:18,226 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:13:18,226 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:13:18,239 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43155
2021-01-23 18:13:18,239 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:13:18,465 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43155
2021-01-23 18:13:18,650 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:13:19,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:13:19,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:13:19,083 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:13:19,112 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:13:19,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:13:19,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:13:19,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:13:19,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:13:19,233 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:13:19,235 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:13:19,637 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 121@slave2
2021-01-23 18:13:19,638 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,638 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:13:19,690 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,690 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,691 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-661382008-172.18.0.2-1611425590339 is not formatted for BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,691 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:13:19,691 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-661382008-172.18.0.2-1611425590339 directory /tmp/hadoop/dfs/data/current/BP-661382008-172.18.0.2-1611425590339/current
2021-01-23 18:13:19,703 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:13:19,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=941365349;bpid=BP-661382008-172.18.0.2-1611425590339;lv=-56;nsInfo=lv=-63;cid=CID-fe118d50-7a06-4140-920f-c73a086893b7;nsid=941365349;c=0;bpid=BP-661382008-172.18.0.2-1611425590339;dnuuid=null
2021-01-23 18:13:19,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 6c18fb42-c287-4048-a167-a2dd4f97e431
2021-01-23 18:13:19,755 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-7ee1ab27-3dfe-43a2-8f9b-7ee3a6c72d37
2021-01-23 18:13:19,755 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:13:19,758 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:13:19,759 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,760 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:13:19,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-661382008-172.18.0.2-1611425590339 on /tmp/hadoop/dfs/data/current: 6ms
2021-01-23 18:13:19,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-661382008-172.18.0.2-1611425590339: 7ms
2021-01-23 18:13:19,766 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:13:19,767 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:13:19,767 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-01-23 18:13:19,913 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-661382008-172.18.0.2-1611425590339 on volume /tmp/hadoop/dfs/data
2021-01-23 18:13:19,914 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7ee1ab27-3dfe-43a2-8f9b-7ee3a6c72d37): finished scanning block pool BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:13:19,932 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611447116932 with interval 21600000
2021-01-23 18:13:19,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:13:19,975 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7ee1ab27-3dfe-43a2-8f9b-7ee3a6c72d37): no suitable block pools found to scan.  Waiting 1814399937 ms.
2021-01-23 18:13:19,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:13:19,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:13:20,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid 6c18fb42-c287-4048-a167-a2dd4f97e431) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:13:20,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-661382008-172.18.0.2-1611425590339 (Datanode Uuid 6c18fb42-c287-4048-a167-a2dd4f97e431) service to master/172.18.0.2:54310
2021-01-23 18:13:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e164694be5b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 36 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:13:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-661382008-172.18.0.2-1611425590339
2021-01-23 18:14:13,220 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave2/172.18.0.4"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2021-01-23 18:14:16,968 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-01-23 18:14:16,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave2/172.18.0.4
************************************************************/
2021-01-23 18:15:06,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:15:06,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:15:07,080 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:15:07,166 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:15:07,166 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:15:07,170 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:15:07,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:15:07,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:15:07,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:15:07,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:15:07,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:15:07,336 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:15:07,342 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:15:07,362 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:15:07,366 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:15:07,367 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:15:07,367 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:15:07,368 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:15:07,394 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46799
2021-01-23 18:15:07,394 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:15:07,599 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46799
2021-01-23 18:15:07,709 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:15:08,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:15:08,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:15:08,132 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:15:08,156 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:15:08,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:15:08,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:15:08,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:15:08,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:15:08,319 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:15:08,327 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:15:08,729 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 288@slave2
2021-01-23 18:15:08,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:15:08,779 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,779 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,779 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-466924295-172.18.0.2-1611425699514 is not formatted for BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,780 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:15:08,780 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-466924295-172.18.0.2-1611425699514 directory /tmp/hadoop/dfs/data/current/BP-466924295-172.18.0.2-1611425699514/current
2021-01-23 18:15:08,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:15:08,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=767045300;bpid=BP-466924295-172.18.0.2-1611425699514;lv=-56;nsInfo=lv=-63;cid=CID-07353671-4518-42c4-b437-17e5e4081e03;nsid=767045300;c=0;bpid=BP-466924295-172.18.0.2-1611425699514;dnuuid=null
2021-01-23 18:15:08,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 49bc166e-c32a-47f2-834e-02b9a920af15
2021-01-23 18:15:08,850 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-fc88d270-c1a3-4b32-8b5d-eb168fc31072
2021-01-23 18:15:08,850 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:15:08,854 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:15:08,854 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:08,871 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:15:08,896 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-466924295-172.18.0.2-1611425699514 on /tmp/hadoop/dfs/data/current: 25ms
2021-01-23 18:15:08,896 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-466924295-172.18.0.2-1611425699514: 42ms
2021-01-23 18:15:08,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:15:08,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:15:08,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-01-23 18:15:09,080 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-466924295-172.18.0.2-1611425699514 on volume /tmp/hadoop/dfs/data
2021-01-23 18:15:09,081 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fc88d270-c1a3-4b32-8b5d-eb168fc31072): finished scanning block pool BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:15:09,096 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611436347096 with interval 21600000
2021-01-23 18:15:09,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:15:09,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:15:09,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:15:09,165 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fc88d270-c1a3-4b32-8b5d-eb168fc31072): no suitable block pools found to scan.  Waiting 1814399915 ms.
2021-01-23 18:15:09,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid 49bc166e-c32a-47f2-834e-02b9a920af15) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:15:09,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-466924295-172.18.0.2-1611425699514 (Datanode Uuid 49bc166e-c32a-47f2-834e-02b9a920af15) service to master/172.18.0.2:54310
2021-01-23 18:15:09,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e2fb15f7877,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 21 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:15:09,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-466924295-172.18.0.2-1611425699514
2021-01-23 18:16:33,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741825_1001 src: /172.18.0.2:34250 dest: /172.18.0.4:50010
2021-01-23 18:16:33,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34250, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741825_1001, duration: 316408496
2021-01-23 18:16:33,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741827_1003 src: /172.18.0.2:34254 dest: /172.18.0.4:50010
2021-01-23 18:16:34,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34254, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741827_1003, duration: 144897925
2021-01-23 18:16:34,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741828_1004 src: /172.18.0.2:34256 dest: /172.18.0.4:50010
2021-01-23 18:16:34,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34256, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741828_1004, duration: 88417448
2021-01-23 18:16:34,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741829_1005 src: /172.18.0.2:34258 dest: /172.18.0.4:50010
2021-01-23 18:16:34,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34258, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741829_1005, duration: 53757644
2021-01-23 18:16:34,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741831_1007 src: /172.18.0.2:34262 dest: /172.18.0.4:50010
2021-01-23 18:16:34,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34262, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741831_1007, duration: 117743953
2021-01-23 18:16:34,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741832_1008 src: /172.18.0.2:34264 dest: /172.18.0.4:50010
2021-01-23 18:16:34,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34264, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741832_1008, duration: 70157901
2021-01-23 18:16:34,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:34,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741833_1009 src: /172.18.0.2:34266 dest: /172.18.0.4:50010
2021-01-23 18:16:34,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34266, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741833_1009, duration: 65686415
2021-01-23 18:16:34,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:35,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741835_1011 src: /172.18.0.2:34270 dest: /172.18.0.4:50010
2021-01-23 18:16:35,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34270, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741835_1011, duration: 56694004
2021-01-23 18:16:35,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:35,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741839_1015 src: /172.18.0.2:34278 dest: /172.18.0.4:50010
2021-01-23 18:16:35,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34278, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741839_1015, duration: 76351845
2021-01-23 18:16:35,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:16:35,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-466924295-172.18.0.2-1611425699514:blk_1073741840_1016 src: /172.18.0.2:34280 dest: /172.18.0.4:50010
2021-01-23 18:16:35,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34280, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36361330_1, offset: 0, srvID: 49bc166e-c32a-47f2-834e-02b9a920af15, blockid: BP-466924295-172.18.0.2-1611425699514:blk_1073741840_1016, duration: 64074648
2021-01-23 18:16:35,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-466924295-172.18.0.2-1611425699514:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:19:05,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:19:05,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:19:06,151 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:19:06,255 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:19:06,255 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:19:06,260 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:19:06,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:19:06,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:19:06,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2021-01-23 18:19:06,340 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:721)
	at org.apache.hadoop.ipc.Server.bind(Server.java:425)
	at org.apache.hadoop.ipc.Server.bind(Server.java:397)
	at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:111)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:893)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1107)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:428)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2373)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2260)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2307)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2484)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2508)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.apache.hadoop.ipc.Server.bind(Server.java:408)
	... 10 more
2021-01-23 18:19:06,345 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2021-01-23 18:19:06,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave2/172.18.0.4
************************************************************/
2021-01-23 18:19:50,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave2/172.18.0.4"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2021-01-23 18:19:54,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:55,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:56,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:57,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:58,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:19:59,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:00,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:01,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:02,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:03,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:03,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From slave2/172.18.0.4 to master:54310 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2021-01-23 18:20:04,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:05,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:06,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:07,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:08,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:09,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:10,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:11,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:12,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:13,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:13,319 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From slave2/172.18.0.4 to master:54310 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 8 more
2021-01-23 18:20:14,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:15,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:16,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:33,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:20:33,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:20:34,854 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:20:34,946 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:20:34,947 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:20:34,950 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:20:34,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:20:34,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:20:35,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:20:35,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:20:35,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:20:35,116 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:20:35,121 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:20:35,127 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:20:35,132 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:20:35,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:20:35,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:20:35,145 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:20:35,155 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42209
2021-01-23 18:20:35,155 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:20:35,333 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42209
2021-01-23 18:20:35,432 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:20:35,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:20:35,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:20:35,840 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:20:35,911 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:20:35,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:20:35,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:20:35,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:20:35,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:20:36,000 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:20:36,032 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:20:37,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:38,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:39,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:40,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:41,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:42,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:43,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:44,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:45,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:46,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:46,174 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:20:52,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:53,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:54,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:55,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:56,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:57,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:58,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:20:59,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:00,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:01,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:01,196 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:07,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:08,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:09,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:10,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:11,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:12,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:13,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:14,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:15,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:16,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:16,222 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:22,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:23,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:24,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:25,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:26,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:27,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:28,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:29,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:30,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:31,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:31,240 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:37,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:38,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:39,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:40,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:41,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:42,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:43,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:44,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:45,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:46,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:46,272 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:21:52,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:53,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:54,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:55,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:56,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:57,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:58,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:21:59,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:00,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:01,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:01,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:22:07,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:08,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:09,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:10,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:11,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:12,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:13,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:14,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:15,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:16,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-01-23 18:22:16,310 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/172.18.0.2:54310
2021-01-23 18:22:19,271 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-01-23 18:22:19,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave2/172.18.0.4
************************************************************/
2021-01-23 18:22:53,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:22:53,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:22:54,922 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:22:55,004 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:22:55,005 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:22:55,008 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:22:55,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:22:55,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:22:55,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:22:55,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:22:55,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:22:55,175 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:22:55,180 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:22:55,185 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:22:55,189 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:22:55,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:22:55,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:22:55,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:22:55,211 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37109
2021-01-23 18:22:55,211 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:22:55,387 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37109
2021-01-23 18:22:55,513 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:22:55,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:22:55,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:22:55,947 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:22:55,970 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:22:56,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:22:56,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:22:56,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:22:56,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:22:56,113 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:22:56,129 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:22:56,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 769@slave2
2021-01-23 18:22:56,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:22:56,618 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,618 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,618 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-876748488-172.18.0.2-1611426167385 is not formatted for BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,618 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:22:56,618 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-876748488-172.18.0.2-1611426167385 directory /tmp/hadoop/dfs/data/current/BP-876748488-172.18.0.2-1611426167385/current
2021-01-23 18:22:56,625 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:22:56,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=460839116;bpid=BP-876748488-172.18.0.2-1611426167385;lv=-56;nsInfo=lv=-63;cid=CID-83b1748a-0185-426e-8406-b2e797cd3ba0;nsid=460839116;c=0;bpid=BP-876748488-172.18.0.2-1611426167385;dnuuid=null
2021-01-23 18:22:56,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 02c7cbc0-07a5-4c67-bff3-bec318438237
2021-01-23 18:22:56,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-fc628a7a-36c3-4185-a972-dd4e323584f3
2021-01-23 18:22:56,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:22:56,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:22:56,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:22:56,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-876748488-172.18.0.2-1611426167385 on /tmp/hadoop/dfs/data/current: 6ms
2021-01-23 18:22:56,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-876748488-172.18.0.2-1611426167385: 23ms
2021-01-23 18:22:56,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:22:56,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:22:56,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-01-23 18:22:56,829 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-876748488-172.18.0.2-1611426167385 on volume /tmp/hadoop/dfs/data
2021-01-23 18:22:56,830 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fc628a7a-36c3-4185-a972-dd4e323584f3): finished scanning block pool BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:22:56,853 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611441878853 with interval 21600000
2021-01-23 18:22:56,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:22:56,876 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-fc628a7a-36c3-4185-a972-dd4e323584f3): no suitable block pools found to scan.  Waiting 1814399953 ms.
2021-01-23 18:22:56,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:22:56,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:22:56,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid 02c7cbc0-07a5-4c67-bff3-bec318438237) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:22:56,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-876748488-172.18.0.2-1611426167385 (Datanode Uuid 02c7cbc0-07a5-4c67-bff3-bec318438237) service to master/172.18.0.2:54310
2021-01-23 18:22:57,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2e9c99df03cf,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:22:57,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-876748488-172.18.0.2-1611426167385
2021-01-23 18:32:56,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:32:56,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:32:57,111 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:32:57,200 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:32:57,200 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:32:57,203 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:32:57,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:32:57,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:32:57,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:32:57,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:32:57,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:32:57,385 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:32:57,426 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:32:57,443 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:32:57,448 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:32:57,449 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:32:57,449 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:32:57,449 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:32:57,459 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46049
2021-01-23 18:32:57,459 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:32:57,677 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46049
2021-01-23 18:32:57,795 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:32:58,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:32:58,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:32:58,258 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:32:58,296 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:32:58,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:32:58,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:32:58,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:32:58,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:32:58,456 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:32:58,476 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:32:58,996 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2021-01-23 18:32:58,997 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:58,997 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:32:59,053 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,053 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1299640566-172.18.0.2-1611426769503 is not formatted for BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:32:59,054 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1299640566-172.18.0.2-1611426769503 directory /tmp/hadoop/dfs/data/current/BP-1299640566-172.18.0.2-1611426769503/current
2021-01-23 18:32:59,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:32:59,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=629590770;bpid=BP-1299640566-172.18.0.2-1611426769503;lv=-56;nsInfo=lv=-63;cid=CID-f5bdc4db-1e67-4bfa-b5be-12664398e087;nsid=629590770;c=0;bpid=BP-1299640566-172.18.0.2-1611426769503;dnuuid=null
2021-01-23 18:32:59,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 00e544a8-ec68-4c16-8406-8ca804a688ca
2021-01-23 18:32:59,143 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-f50185f4-129a-410a-be1e-92852ebcebd3
2021-01-23 18:32:59,144 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:32:59,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:32:59,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,149 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:32:59,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1299640566-172.18.0.2-1611426769503 on /tmp/hadoop/dfs/data/current: 25ms
2021-01-23 18:32:59,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1299640566-172.18.0.2-1611426769503: 25ms
2021-01-23 18:32:59,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:32:59,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:32:59,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-01-23 18:32:59,312 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1299640566-172.18.0.2-1611426769503 on volume /tmp/hadoop/dfs/data
2021-01-23 18:32:59,313 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): finished scanning block pool BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:32:59,338 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611443918338 with interval 21600000
2021-01-23 18:32:59,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:32:59,373 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): no suitable block pools found to scan.  Waiting 1814399939 ms.
2021-01-23 18:32:59,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:32:59,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:32:59,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid 00e544a8-ec68-4c16-8406-8ca804a688ca) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:32:59,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1299640566-172.18.0.2-1611426769503 (Datanode Uuid 00e544a8-ec68-4c16-8406-8ca804a688ca) service to master/172.18.0.2:54310
2021-01-23 18:32:59,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2f28e0c6c2df,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:32:59,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1299640566-172.18.0.2-1611426769503
2021-01-23 18:35:19,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741826_1002 src: /172.18.0.2:35044 dest: /172.18.0.4:50010
2021-01-23 18:35:19,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35044, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741826_1002, duration: 148412913
2021-01-23 18:35:19,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741829_1005 src: /172.18.0.2:35050 dest: /172.18.0.4:50010
2021-01-23 18:35:20,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35050, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741829_1005, duration: 69832497
2021-01-23 18:35:20,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741835_1011 src: /172.18.0.2:35062 dest: /172.18.0.4:50010
2021-01-23 18:35:20,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35062, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741835_1011, duration: 67299873
2021-01-23 18:35:20,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741838_1014 src: /172.18.0.2:35068 dest: /172.18.0.4:50010
2021-01-23 18:35:20,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35068, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741838_1014, duration: 42721991
2021-01-23 18:35:20,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:20,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741839_1015 src: /172.18.0.2:35070 dest: /172.18.0.4:50010
2021-01-23 18:35:21,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35070, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741839_1015, duration: 81731187
2021-01-23 18:35:21,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:21,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741840_1016 src: /172.18.0.2:35072 dest: /172.18.0.4:50010
2021-01-23 18:35:21,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35072, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-105051857_1, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741840_1016, duration: 58983355
2021-01-23 18:35:21,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:35:48,484 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741826_1002 for rescanning.
2021-01-23 18:35:55,649 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741829_1005 for rescanning.
2021-01-23 18:36:14,989 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741835_1011 for rescanning.
2021-01-23 18:36:25,354 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741838_1014 for rescanning.
2021-01-23 18:36:27,241 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741839_1015 for rescanning.
2021-01-23 18:36:31,157 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): Scheduling suspect block BP-1299640566-172.18.0.2-1611426769503:blk_1073741840_1016 for rescanning.
2021-01-23 18:36:35,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741841_1017 src: /172.18.0.4:42940 dest: /172.18.0.4:50010
2021-01-23 18:36:35,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741842_1018 src: /172.18.0.3:35514 dest: /172.18.0.4:50010
2021-01-23 18:36:35,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42940, dest: /172.18.0.4:50010, bytes: 233, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741841_1017, duration: 65804515
2021-01-23 18:36:35,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:35,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35514, dest: /172.18.0.4:50010, bytes: 207, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741842_1018, duration: 38641072
2021-01-23 18:36:35,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741844_1020 src: /172.18.0.4:42950 dest: /172.18.0.4:50010
2021-01-23 18:36:36,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741843_1019 src: /172.18.0.3:35520 dest: /172.18.0.4:50010
2021-01-23 18:36:36,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35520, dest: /172.18.0.4:50010, bytes: 210, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741843_1019, duration: 64050933
2021-01-23 18:36:36,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42950, dest: /172.18.0.4:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741844_1020, duration: 8867347
2021-01-23 18:36:36,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741845_1021 src: /172.18.0.3:35526 dest: /172.18.0.4:50010
2021-01-23 18:36:36,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741846_1022 src: /172.18.0.4:42960 dest: /172.18.0.4:50010
2021-01-23 18:36:36,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35526, dest: /172.18.0.4:50010, bytes: 119, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741845_1021, duration: 10449826
2021-01-23 18:36:36,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42960, dest: /172.18.0.4:50010, bytes: 95, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741846_1022, duration: 50079209
2021-01-23 18:36:36,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741847_1023 src: /172.18.0.3:35534 dest: /172.18.0.4:50010
2021-01-23 18:36:36,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35534, dest: /172.18.0.4:50010, bytes: 129, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741847_1023, duration: 6979927
2021-01-23 18:36:36,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741848_1024 src: /172.18.0.4:42968 dest: /172.18.0.4:50010
2021-01-23 18:36:36,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42968, dest: /172.18.0.4:50010, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741848_1024, duration: 20300417
2021-01-23 18:36:36,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741849_1025 src: /172.18.0.3:35542 dest: /172.18.0.4:50010
2021-01-23 18:36:36,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35542, dest: /172.18.0.4:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741849_1025, duration: 11070924
2021-01-23 18:36:36,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741850_1026 src: /172.18.0.4:42976 dest: /172.18.0.4:50010
2021-01-23 18:36:36,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42976, dest: /172.18.0.4:50010, bytes: 88, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741850_1026, duration: 25598561
2021-01-23 18:36:36,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741851_1027 src: /172.18.0.3:35550 dest: /172.18.0.4:50010
2021-01-23 18:36:36,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35550, dest: /172.18.0.4:50010, bytes: 144, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741851_1027, duration: 2680449
2021-01-23 18:36:36,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:36,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741852_1028 src: /172.18.0.4:42984 dest: /172.18.0.4:50010
2021-01-23 18:36:36,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42984, dest: /172.18.0.4:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741852_1028, duration: 18635493
2021-01-23 18:36:36,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:36,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741853_1029 src: /172.18.0.3:35558 dest: /172.18.0.4:50010
2021-01-23 18:36:36,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35558, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741853_1029, duration: 8123349
2021-01-23 18:36:36,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:37,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741854_1030 src: /172.18.0.4:42992 dest: /172.18.0.4:50010
2021-01-23 18:36:37,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:42992, dest: /172.18.0.4:50010, bytes: 193, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741854_1030, duration: 15478473
2021-01-23 18:36:37,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:36:37,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741855_1031 src: /172.18.0.3:35566 dest: /172.18.0.4:50010
2021-01-23 18:36:37,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:35566, dest: /172.18.0.4:50010, bytes: 124, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000001_0_907132721_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741855_1031, duration: 16555857
2021-01-23 18:36:37,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:36:37,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1299640566-172.18.0.2-1611426769503:blk_1073741856_1032 src: /172.18.0.4:43000 dest: /172.18.0.4:50010
2021-01-23 18:36:37,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:43000, dest: /172.18.0.4:50010, bytes: 87, op: HDFS_WRITE, cliID: DFSClient_attempt_20210123183538_0000_m_000000_0_-1063595375_26, offset: 0, srvID: 00e544a8-ec68-4c16-8406-8ca804a688ca, blockid: BP-1299640566-172.18.0.2-1611426769503:blk_1073741856_1032, duration: 13916740
2021-01-23 18:36:37,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1299640566-172.18.0.2-1611426769503:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2021-01-23 18:37:24,989 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f50185f4-129a-410a-be1e-92852ebcebd3): no suitable block pools found to scan.  Waiting 1814134323 ms.
2021-01-23 18:43:23,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-23 18:43:23,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-23 18:43:24,253 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-23 18:43:24,343 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-23 18:43:24,343 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-23 18:43:24,347 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-23 18:43:24,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-23 18:43:24,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-23 18:43:24,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-23 18:43:24,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-23 18:43:24,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-23 18:43:24,523 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-23 18:43:24,530 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-23 18:43:24,546 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-23 18:43:24,550 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-23 18:43:24,551 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-23 18:43:24,552 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-23 18:43:24,552 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-23 18:43:24,573 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40531
2021-01-23 18:43:24,573 INFO org.mortbay.log: jetty-6.1.26
2021-01-23 18:43:24,754 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40531
2021-01-23 18:43:24,874 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-23 18:43:25,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-23 18:43:25,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-23 18:43:25,309 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-23 18:43:25,330 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-23 18:43:25,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-23 18:43:25,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-23 18:43:25,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-23 18:43:25,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-23 18:43:25,469 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-23 18:43:25,490 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-23 18:43:25,920 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2021-01-23 18:43:25,921 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:25,921 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:43:25,997 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:25,998 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:25,998 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1520537408-172.18.0.2-1611427396672 is not formatted for BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:25,998 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-23 18:43:25,998 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1520537408-172.18.0.2-1611427396672 directory /tmp/hadoop/dfs/data/current/BP-1520537408-172.18.0.2-1611427396672/current
2021-01-23 18:43:26,003 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-23 18:43:26,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1020823805;bpid=BP-1520537408-172.18.0.2-1611427396672;lv=-56;nsInfo=lv=-63;cid=CID-1b155ced-ce84-468a-b3c8-042c1a2a88cf;nsid=1020823805;c=0;bpid=BP-1520537408-172.18.0.2-1611427396672;dnuuid=null
2021-01-23 18:43:26,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 16806596-a856-45a5-b831-2d88df5b61ae
2021-01-23 18:43:26,070 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-7aa6d585-f370-4f22-95be-ead35b244012
2021-01-23 18:43:26,070 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-23 18:43:26,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-23 18:43:26,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,095 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:43:26,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1520537408-172.18.0.2-1611427396672 on /tmp/hadoop/dfs/data/current: 28ms
2021-01-23 18:43:26,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1520537408-172.18.0.2-1611427396672: 47ms
2021-01-23 18:43:26,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data/current...
2021-01-23 18:43:26,125 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-23 18:43:26,125 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2021-01-23 18:43:26,280 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1520537408-172.18.0.2-1611427396672 on volume /tmp/hadoop/dfs/data
2021-01-23 18:43:26,281 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7aa6d585-f370-4f22-95be-ead35b244012): finished scanning block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:43:26,296 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611447266296 with interval 21600000
2021-01-23 18:43:26,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-23 18:43:26,345 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7aa6d585-f370-4f22-95be-ead35b244012): no suitable block pools found to scan.  Waiting 1814399935 ms.
2021-01-23 18:43:26,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-23 18:43:26,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-23 18:43:26,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid 16806596-a856-45a5-b831-2d88df5b61ae) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-23 18:43:26,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1520537408-172.18.0.2-1611427396672 (Datanode Uuid 16806596-a856-45a5-b831-2d88df5b61ae) service to master/172.18.0.2:54310
2021-01-23 18:43:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2fbadd4d344d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-23 18:43:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1520537408-172.18.0.2-1611427396672
2021-01-23 18:44:08,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741827_1003 src: /172.18.0.2:35382 dest: /172.18.0.4:50010
2021-01-23 18:44:08,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35382, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741827_1003, duration: 137455859
2021-01-23 18:44:08,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741829_1005 src: /172.18.0.2:35386 dest: /172.18.0.4:50010
2021-01-23 18:44:08,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35386, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741829_1005, duration: 86378197
2021-01-23 18:44:08,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741831_1007 src: /172.18.0.2:35390 dest: /172.18.0.4:50010
2021-01-23 18:44:08,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35390, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741831_1007, duration: 60161075
2021-01-23 18:44:08,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741833_1009 src: /172.18.0.2:35394 dest: /172.18.0.4:50010
2021-01-23 18:44:08,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35394, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741833_1009, duration: 57078614
2021-01-23 18:44:08,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:08,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741834_1010 src: /172.18.0.2:35396 dest: /172.18.0.4:50010
2021-01-23 18:44:09,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35396, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741834_1010, duration: 37055014
2021-01-23 18:44:09,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:09,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741835_1011 src: /172.18.0.2:35398 dest: /172.18.0.4:50010
2021-01-23 18:44:09,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35398, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741835_1011, duration: 57213248
2021-01-23 18:44:09,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:09,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741836_1012 src: /172.18.0.2:35400 dest: /172.18.0.4:50010
2021-01-23 18:44:09,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35400, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741836_1012, duration: 63762124
2021-01-23 18:44:09,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:09,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1520537408-172.18.0.2-1611427396672:blk_1073741840_1016 src: /172.18.0.2:35408 dest: /172.18.0.4:50010
2021-01-23 18:44:09,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:35408, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1698404395_1, offset: 0, srvID: 16806596-a856-45a5-b831-2d88df5b61ae, blockid: BP-1520537408-172.18.0.2-1611427396672:blk_1073741840_1016, duration: 34059764
2021-01-23 18:44:09,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1520537408-172.18.0.2-1611427396672:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2021-01-23 18:44:40,222 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7aa6d585-f370-4f22-95be-ead35b244012): Scheduling suspect block BP-1520537408-172.18.0.2-1611427396672:blk_1073741827_1003 for rescanning.
2021-01-23 18:44:56,230 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-7aa6d585-f370-4f22-95be-ead35b244012): no suitable block pools found to scan.  Waiting 1814310050 ms.
2021-01-27 08:53:33,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2021-01-27 08:53:33,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-01-27 08:53:34,385 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2021-01-27 08:53:34,477 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2021-01-27 08:53:34,477 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-01-27 08:53:34,480 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-01-27 08:53:34,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2021-01-27 08:53:34,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-01-27 08:53:34,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2021-01-27 08:53:34,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2021-01-27 08:53:34,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2021-01-27 08:53:34,614 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2021-01-27 08:53:34,619 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-01-27 08:53:34,632 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-01-27 08:53:34,636 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-01-27 08:53:34,637 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-01-27 08:53:34,637 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-01-27 08:53:34,637 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-01-27 08:53:34,656 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42485
2021-01-27 08:53:34,656 INFO org.mortbay.log: jetty-6.1.26
2021-01-27 08:53:34,816 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42485
2021-01-27 08:53:34,945 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2021-01-27 08:53:35,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-01-27 08:53:35,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-01-27 08:53:35,332 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2021-01-27 08:53:35,366 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2021-01-27 08:53:35,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2021-01-27 08:53:35,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-01-27 08:53:35,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-01-27 08:53:35,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2021-01-27 08:53:35,519 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-01-27 08:53:35,529 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2021-01-27 08:53:35,909 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2021-01-27 08:53:35,910 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:35,910 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-27 08:53:35,963 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:35,963 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:35,963 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-798846186-172.18.0.2-1611737607458 is not formatted for BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:35,963 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2021-01-27 08:53:35,963 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-798846186-172.18.0.2-1611737607458 directory /tmp/hadoop/dfs/data/current/BP-798846186-172.18.0.2-1611737607458/current
2021-01-27 08:53:35,974 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2021-01-27 08:53:35,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1826582023;bpid=BP-798846186-172.18.0.2-1611737607458;lv=-56;nsInfo=lv=-63;cid=CID-ae6077e4-015e-44b3-8712-a06ddf744854;nsid=1826582023;c=0;bpid=BP-798846186-172.18.0.2-1611737607458;dnuuid=null
2021-01-27 08:53:35,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 578a59e8-6a62-4cc7-a963-6cc838dbf538
2021-01-27 08:53:36,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-8f8bd674-b64f-4110-b61b-27eb02eea00a
2021-01-27 08:53:36,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2021-01-27 08:53:36,033 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-01-27 08:53:36,033 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data/current...
2021-01-27 08:53:36,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-798846186-172.18.0.2-1611737607458 on /tmp/hadoop/dfs/data/current: 14ms
2021-01-27 08:53:36,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-798846186-172.18.0.2-1611737607458: 31ms
2021-01-27 08:53:36,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data/current...
2021-01-27 08:53:36,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data/current: 0ms
2021-01-27 08:53:36,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2021-01-27 08:53:36,229 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-798846186-172.18.0.2-1611737607458 on volume /tmp/hadoop/dfs/data
2021-01-27 08:53:36,230 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f8bd674-b64f-4110-b61b-27eb02eea00a): finished scanning block pool BP-798846186-172.18.0.2-1611737607458
2021-01-27 08:53:36,246 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1611756923246 with interval 21600000
2021-01-27 08:53:36,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2021-01-27 08:53:36,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2021-01-27 08:53:36,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-01-27 08:53:36,326 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-8f8bd674-b64f-4110-b61b-27eb02eea00a): no suitable block pools found to scan.  Waiting 1814399889 ms.
2021-01-27 08:53:36,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid 578a59e8-6a62-4cc7-a963-6cc838dbf538) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2021-01-27 08:53:36,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-798846186-172.18.0.2-1611737607458 (Datanode Uuid 578a59e8-6a62-4cc7-a963-6cc838dbf538) service to master/172.18.0.2:54310
2021-01-27 08:53:36,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4d7f72e63ac5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-01-27 08:53:36,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-798846186-172.18.0.2-1611737607458
2022-12-18 08:03:53,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2022-12-18 08:03:53,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-18 08:03:53,878 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-18 08:03:53,968 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2022-12-18 08:03:53,968 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-18 08:03:53,990 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-18 08:03:53,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2022-12-18 08:03:53,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-18 08:03:54,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-18 08:03:54,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2022-12-18 08:03:54,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2022-12-18 08:03:54,119 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-18 08:03:54,124 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-18 08:03:54,140 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-18 08:03:54,144 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-18 08:03:54,145 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-18 08:03:54,146 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-18 08:03:54,146 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-18 08:03:54,170 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41767
2022-12-18 08:03:54,170 INFO org.mortbay.log: jetty-6.1.26
2022-12-18 08:03:54,346 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41767
2022-12-18 08:03:54,468 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-18 08:03:54,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-12-18 08:03:54,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-18 08:03:54,794 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2022-12-18 08:03:54,841 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-18 08:03:54,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-18 08:03:54,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-18 08:03:54,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-18 08:03:54,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2022-12-18 08:03:54,952 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-18 08:03:54,963 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-18 08:03:55,320 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2022-12-18 08:03:55,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:03:55,374 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,374 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,375 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1689137157-172.18.0.2-1671350626907 is not formatted for BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,375 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:03:55,375 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1689137157-172.18.0.2-1671350626907 directory /tmp/hadoop/dfs/data/current/BP-1689137157-172.18.0.2-1671350626907/current
2022-12-18 08:03:55,377 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2022-12-18 08:03:55,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=986042096;bpid=BP-1689137157-172.18.0.2-1671350626907;lv=-56;nsInfo=lv=-63;cid=CID-52e7924c-17d4-4d95-8d84-341aece6ea1a;nsid=986042096;c=0;bpid=BP-1689137157-172.18.0.2-1671350626907;dnuuid=null
2022-12-18 08:03:55,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID cfed8242-3ad1-42ca-9d23-40dc018f7953
2022-12-18 08:03:55,418 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313
2022-12-18 08:03:55,418 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2022-12-18 08:03:55,435 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-18 08:03:55,435 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,436 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:03:55,468 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1689137157-172.18.0.2-1671350626907 on /tmp/hadoop/dfs/data/current: 33ms
2022-12-18 08:03:55,468 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1689137157-172.18.0.2-1671350626907: 33ms
2022-12-18 08:03:55,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:03:55,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data/current: 0ms
2022-12-18 08:03:55,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 14ms
2022-12-18 08:03:55,627 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1689137157-172.18.0.2-1671350626907 on volume /tmp/hadoop/dfs/data
2022-12-18 08:03:55,628 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): finished scanning block pool BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:03:55,651 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1671369366651 with interval 21600000
2022-12-18 08:03:55,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2022-12-18 08:03:55,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2022-12-18 08:03:55,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-18 08:03:55,690 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): no suitable block pools found to scan.  Waiting 1814399937 ms.
2022-12-18 08:03:55,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid cfed8242-3ad1-42ca-9d23-40dc018f7953) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2022-12-18 08:03:55,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1689137157-172.18.0.2-1671350626907 (Datanode Uuid cfed8242-3ad1-42ca-9d23-40dc018f7953) service to master/172.18.0.2:54310
2022-12-18 08:03:55,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3c848796a84d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 36 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-18 08:03:55,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1689137157-172.18.0.2-1671350626907
2022-12-18 08:06:05,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741825_1001 src: /172.18.0.2:47842 dest: /172.18.0.4:50010
2022-12-18 08:06:05,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:47842, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741825_1001, duration: 187076183
2022-12-18 08:06:05,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:06:05,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003 src: /172.18.0.2:47846 dest: /172.18.0.4:50010
2022-12-18 08:06:05,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:47846, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003, duration: 68157439
2022-12-18 08:06:05,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:06:05,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004 src: /172.18.0.2:47860 dest: /172.18.0.4:50010
2022-12-18 08:06:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:47860, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004, duration: 38460263
2022-12-18 08:06:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:06:05,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741830_1006 src: /172.18.0.2:47868 dest: /172.18.0.4:50010
2022-12-18 08:06:05,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:47868, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741830_1006, duration: 57175814
2022-12-18 08:06:05,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:06:05,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741831_1007 src: /172.18.0.2:47870 dest: /172.18.0.4:50010
2022-12-18 08:06:05,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:47870, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1420242843_1, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741831_1007, duration: 49366000
2022-12-18 08:06:05,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:11:47,896 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003 for rescanning.
2022-12-18 08:11:47,990 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004 for rescanning.
2022-12-18 08:11:48,083 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003 for rescanning, because we rescanned it recently.
2022-12-18 08:11:48,105 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004 for rescanning, because we rescanned it recently.
2022-12-18 08:11:48,154 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003 for rescanning, because we rescanned it recently.
2022-12-18 08:11:48,221 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004 for rescanning, because we rescanned it recently.
2022-12-18 08:11:48,255 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003 for rescanning, because we rescanned it recently.
2022-12-18 08:12:19,930 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): no suitable block pools found to scan.  Waiting 1813895697 ms.
2022-12-18 08:14:20,784 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741827_1003 for rescanning, because we rescanned it recently.
2022-12-18 08:14:24,968 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Not scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741828_1004 for rescanning, because we rescanned it recently.
2022-12-18 08:14:28,607 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741830_1006 for rescanning.
2022-12-18 08:14:28,775 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): Scheduling suspect block BP-1689137157-172.18.0.2-1671350626907:blk_1073741831_1007 for rescanning.
2022-12-18 08:14:33,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741833_1009 src: /172.18.0.4:47610 dest: /172.18.0.4:50010
2022-12-18 08:14:34,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47610, dest: /172.18.0.4:50010, bytes: 319, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741833_1009, duration: 55225334
2022-12-18 08:14:34,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741834_1010 src: /172.18.0.3:48090 dest: /172.18.0.4:50010
2022-12-18 08:14:34,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:48090, dest: /172.18.0.4:50010, bytes: 274, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741834_1010, duration: 47705766
2022-12-18 08:14:34,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741835_1011 src: /172.18.0.4:47626 dest: /172.18.0.4:50010
2022-12-18 08:14:34,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47626, dest: /172.18.0.4:50010, bytes: 247, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741835_1011, duration: 3262124
2022-12-18 08:14:34,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741836_1012 src: /172.18.0.3:48100 dest: /172.18.0.4:50010
2022-12-18 08:14:34,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:48100, dest: /172.18.0.4:50010, bytes: 313, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741836_1012, duration: 14335133
2022-12-18 08:14:34,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741837_1013 src: /172.18.0.4:47638 dest: /172.18.0.4:50010
2022-12-18 08:14:34,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47638, dest: /172.18.0.4:50010, bytes: 195, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741837_1013, duration: 32982422
2022-12-18 08:14:34,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741838_1014 src: /172.18.0.3:48116 dest: /172.18.0.4:50010
2022-12-18 08:14:34,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:48116, dest: /172.18.0.4:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741838_1014, duration: 5870328
2022-12-18 08:14:34,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:14:34,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741839_1015 src: /172.18.0.4:47644 dest: /172.18.0.4:50010
2022-12-18 08:14:34,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:47644, dest: /172.18.0.4:50010, bytes: 252, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000001_0_1091487769_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741839_1015, duration: 28975875
2022-12-18 08:14:34,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:14:34,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1689137157-172.18.0.2-1671350626907:blk_1073741840_1016 src: /172.18.0.3:48130 dest: /172.18.0.4:50010
2022-12-18 08:14:34,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:48130, dest: /172.18.0.4:50010, bytes: 214, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218081412_0000_m_000000_0_1320954571_26, offset: 0, srvID: cfed8242-3ad1-42ca-9d23-40dc018f7953, blockid: BP-1689137157-172.18.0.2-1671350626907:blk_1073741840_1016, duration: 9939991
2022-12-18 08:14:34,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1689137157-172.18.0.2-1671350626907:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:15:00,608 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-5e501a2d-e149-4fb1-91c6-a1c3ff973313): no suitable block pools found to scan.  Waiting 1813735019 ms.
2022-12-18 08:20:16,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2022-12-18 08:20:16,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-18 08:20:17,725 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-18 08:20:17,814 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2022-12-18 08:20:17,814 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-18 08:20:17,836 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-18 08:20:17,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2022-12-18 08:20:17,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-18 08:20:17,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-18 08:20:17,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2022-12-18 08:20:17,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2022-12-18 08:20:17,971 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-18 08:20:17,977 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-18 08:20:17,992 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-18 08:20:17,996 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-18 08:20:17,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-18 08:20:17,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-18 08:20:17,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-18 08:20:18,005 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46625
2022-12-18 08:20:18,005 INFO org.mortbay.log: jetty-6.1.26
2022-12-18 08:20:18,178 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46625
2022-12-18 08:20:18,304 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-18 08:20:18,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-12-18 08:20:18,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-18 08:20:18,672 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2022-12-18 08:20:18,713 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-18 08:20:18,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-18 08:20:18,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-18 08:20:18,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-18 08:20:18,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2022-12-18 08:20:18,810 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-18 08:20:18,839 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-18 08:20:19,222 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2022-12-18 08:20:19,223 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,223 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:20:19,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1055401500-172.18.0.2-1671351610662 is not formatted for BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 08:20:19,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1055401500-172.18.0.2-1671351610662 directory /tmp/hadoop/dfs/data/current/BP-1055401500-172.18.0.2-1671351610662/current
2022-12-18 08:20:19,262 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2022-12-18 08:20:19,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1512424922;bpid=BP-1055401500-172.18.0.2-1671351610662;lv=-56;nsInfo=lv=-63;cid=CID-cc203620-c2ce-413b-96a0-d04a3dcbf0af;nsid=1512424922;c=0;bpid=BP-1055401500-172.18.0.2-1671351610662;dnuuid=null
2022-12-18 08:20:19,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 59480029-17b4-485b-acda-f3df4f249fa5
2022-12-18 08:20:19,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-387ee28d-ec17-4821-87cc-48946e9b8984
2022-12-18 08:20:19,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2022-12-18 08:20:19,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-18 08:20:19,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,309 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:20:19,315 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1055401500-172.18.0.2-1671351610662 on /tmp/hadoop/dfs/data/current: 6ms
2022-12-18 08:20:19,315 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1055401500-172.18.0.2-1671351610662: 7ms
2022-12-18 08:20:19,315 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 08:20:19,315 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data/current: 0ms
2022-12-18 08:20:19,315 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2022-12-18 08:20:19,418 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1055401500-172.18.0.2-1671351610662 on volume /tmp/hadoop/dfs/data
2022-12-18 08:20:19,419 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): finished scanning block pool BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:20:19,466 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1671360276466 with interval 21600000
2022-12-18 08:20:19,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2022-12-18 08:20:19,485 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): no suitable block pools found to scan.  Waiting 1814399933 ms.
2022-12-18 08:20:19,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2022-12-18 08:20:19,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-18 08:20:19,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid 59480029-17b4-485b-acda-f3df4f249fa5) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2022-12-18 08:20:19,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1055401500-172.18.0.2-1671351610662 (Datanode Uuid 59480029-17b4-485b-acda-f3df4f249fa5) service to master/172.18.0.2:54310
2022-12-18 08:20:19,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3d69980cf1ba,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-18 08:20:19,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1055401500-172.18.0.2-1671351610662
2022-12-18 08:21:12,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741826_1002 src: /172.18.0.2:44868 dest: /172.18.0.4:50010
2022-12-18 08:21:12,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44868, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741826_1002, duration: 183297343
2022-12-18 08:21:12,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:12,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741827_1003 src: /172.18.0.2:44870 dest: /172.18.0.4:50010
2022-12-18 08:21:12,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44870, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741827_1003, duration: 102105639
2022-12-18 08:21:12,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:12,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741829_1005 src: /172.18.0.2:44874 dest: /172.18.0.4:50010
2022-12-18 08:21:12,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44874, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741829_1005, duration: 48923627
2022-12-18 08:21:12,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:12,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741832_1008 src: /172.18.0.2:44884 dest: /172.18.0.4:50010
2022-12-18 08:21:12,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:44884, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_805203440_1, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741832_1008, duration: 48643173
2022-12-18 08:21:12,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:21:47,467 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741826_1002 for rescanning.
2022-12-18 08:21:48,332 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741827_1003 for rescanning.
2022-12-18 08:21:52,397 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741829_1005 for rescanning.
2022-12-18 08:21:58,713 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): Scheduling suspect block BP-1055401500-172.18.0.2-1671351610662:blk_1073741832_1008 for rescanning.
2022-12-18 08:22:01,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741834_1010 src: /172.18.0.4:58862 dest: /172.18.0.4:50010
2022-12-18 08:22:01,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741833_1009 src: /172.18.0.3:40432 dest: /172.18.0.4:50010
2022-12-18 08:22:01,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:40432, dest: /172.18.0.4:50010, bytes: 274, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741833_1009, duration: 14803783
2022-12-18 08:22:01,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:01,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:58862, dest: /172.18.0.4:50010, bytes: 319, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741834_1010, duration: 26520831
2022-12-18 08:22:01,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:01,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741835_1011 src: /172.18.0.4:58870 dest: /172.18.0.4:50010
2022-12-18 08:22:01,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741836_1012 src: /172.18.0.3:40438 dest: /172.18.0.4:50010
2022-12-18 08:22:01,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:58870, dest: /172.18.0.4:50010, bytes: 247, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741835_1011, duration: 3223392
2022-12-18 08:22:01,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:01,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:40438, dest: /172.18.0.4:50010, bytes: 313, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741836_1012, duration: 15536025
2022-12-18 08:22:01,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:01,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741837_1013 src: /172.18.0.4:58884 dest: /172.18.0.4:50010
2022-12-18 08:22:01,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:58884, dest: /172.18.0.4:50010, bytes: 195, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741837_1013, duration: 2653302
2022-12-18 08:22:01,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:01,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741838_1014 src: /172.18.0.3:40454 dest: /172.18.0.4:50010
2022-12-18 08:22:01,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:40454, dest: /172.18.0.4:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741838_1014, duration: 2849151
2022-12-18 08:22:01,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:01,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741839_1015 src: /172.18.0.4:58890 dest: /172.18.0.4:50010
2022-12-18 08:22:01,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:58890, dest: /172.18.0.4:50010, bytes: 252, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000001_0_-1125157306_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741839_1015, duration: 33628089
2022-12-18 08:22:01,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 08:22:02,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1055401500-172.18.0.2-1671351610662:blk_1073741840_1016 src: /172.18.0.3:40466 dest: /172.18.0.4:50010
2022-12-18 08:22:02,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:40466, dest: /172.18.0.4:50010, bytes: 214, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218082140_0000_m_000000_0_1281960914_26, offset: 0, srvID: 59480029-17b4-485b-acda-f3df4f249fa5, blockid: BP-1055401500-172.18.0.2-1671351610662:blk_1073741840_1016, duration: 10882401
2022-12-18 08:22:02,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1055401500-172.18.0.2-1671351610662:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 08:22:51,969 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-387ee28d-ec17-4821-87cc-48946e9b8984): no suitable block pools found to scan.  Waiting 1814247449 ms.
2022-12-18 09:46:36,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2022-12-18 09:46:36,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-18 09:46:36,971 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-18 09:46:37,060 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2022-12-18 09:46:37,060 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-18 09:46:37,083 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-18 09:46:37,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2022-12-18 09:46:37,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-18 09:46:37,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-18 09:46:37,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2022-12-18 09:46:37,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2022-12-18 09:46:37,214 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-18 09:46:37,219 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-18 09:46:37,223 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-18 09:46:37,227 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-18 09:46:37,228 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-18 09:46:37,228 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-18 09:46:37,228 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-18 09:46:37,247 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34311
2022-12-18 09:46:37,247 INFO org.mortbay.log: jetty-6.1.26
2022-12-18 09:46:37,401 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34311
2022-12-18 09:46:37,492 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-18 09:46:37,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-12-18 09:46:37,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-18 09:46:37,838 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2022-12-18 09:46:37,882 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-18 09:46:37,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-18 09:46:37,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-18 09:46:37,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-18 09:46:37,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2022-12-18 09:46:37,980 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-18 09:46:38,020 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-18 09:46:38,350 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2022-12-18 09:46:38,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 09:46:38,391 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,391 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-558954561-172.18.0.2-1671356790058 is not formatted for BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2022-12-18 09:46:38,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-558954561-172.18.0.2-1671356790058 directory /tmp/hadoop/dfs/data/current/BP-558954561-172.18.0.2-1671356790058/current
2022-12-18 09:46:38,395 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2022-12-18 09:46:38,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=755013202;bpid=BP-558954561-172.18.0.2-1671356790058;lv=-56;nsInfo=lv=-63;cid=CID-fd2d1757-d3ec-4c41-bc3b-9a90a68f1dcf;nsid=755013202;c=0;bpid=BP-558954561-172.18.0.2-1671356790058;dnuuid=null
2022-12-18 09:46:38,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 73983929-9749-47a1-a77e-929f67e590ca
2022-12-18 09:46:38,447 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9cfb2444-ddb2-4fc5-be61-b911530de8e8
2022-12-18 09:46:38,447 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2022-12-18 09:46:38,450 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-18 09:46:38,451 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,452 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 09:46:38,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-558954561-172.18.0.2-1671356790058 on /tmp/hadoop/dfs/data/current: 6ms
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-558954561-172.18.0.2-1671356790058: 7ms
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data/current...
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data/current: 0ms
2022-12-18 09:46:38,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2022-12-18 09:46:38,589 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-558954561-172.18.0.2-1671356790058 on volume /tmp/hadoop/dfs/data
2022-12-18 09:46:38,590 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9cfb2444-ddb2-4fc5-be61-b911530de8e8): finished scanning block pool BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:46:38,608 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1671372773608 with interval 21600000
2022-12-18 09:46:38,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2022-12-18 09:46:38,640 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9cfb2444-ddb2-4fc5-be61-b911530de8e8): no suitable block pools found to scan.  Waiting 1814399949 ms.
2022-12-18 09:46:38,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2022-12-18 09:46:38,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-18 09:46:38,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid 73983929-9749-47a1-a77e-929f67e590ca) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2022-12-18 09:46:38,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-558954561-172.18.0.2-1671356790058 (Datanode Uuid 73983929-9749-47a1-a77e-929f67e590ca) service to master/172.18.0.2:54310
2022-12-18 09:46:38,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3eeba3f28871,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-18 09:46:38,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-558954561-172.18.0.2-1671356790058
2022-12-18 09:49:31,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741825_1001 src: /172.18.0.2:34012 dest: /172.18.0.4:50010
2022-12-18 09:49:31,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34012, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741825_1001, duration: 141348799
2022-12-18 09:49:31,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:49:31,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741831_1007 src: /172.18.0.2:34024 dest: /172.18.0.4:50010
2022-12-18 09:49:31,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:34024, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1313163031_1, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741831_1007, duration: 67904923
2022-12-18 09:49:31,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:32,472 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9cfb2444-ddb2-4fc5-be61-b911530de8e8): Scheduling suspect block BP-558954561-172.18.0.2-1671356790058:blk_1073741831_1007 for rescanning.
2022-12-18 09:50:37,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741833_1009 src: /172.18.0.4:56626 dest: /172.18.0.4:50010
2022-12-18 09:50:37,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741834_1010 src: /172.18.0.3:57840 dest: /172.18.0.4:50010
2022-12-18 09:50:37,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56626, dest: /172.18.0.4:50010, bytes: 274, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741833_1009, duration: 53206399
2022-12-18 09:50:37,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:37,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:57840, dest: /172.18.0.4:50010, bytes: 319, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741834_1010, duration: 26602261
2022-12-18 09:50:37,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:37,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741835_1011 src: /172.18.0.4:56634 dest: /172.18.0.4:50010
2022-12-18 09:50:37,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:56634, dest: /172.18.0.4:50010, bytes: 247, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741835_1011, duration: 12558400
2022-12-18 09:50:37,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:38,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741836_1012 src: /172.18.0.3:43302 dest: /172.18.0.4:50010
2022-12-18 09:50:38,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43302, dest: /172.18.0.4:50010, bytes: 313, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741836_1012, duration: 1470382
2022-12-18 09:50:38,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:38,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741837_1013 src: /172.18.0.4:55670 dest: /172.18.0.4:50010
2022-12-18 09:50:38,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:55670, dest: /172.18.0.4:50010, bytes: 195, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741837_1013, duration: 35903995
2022-12-18 09:50:38,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:38,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741838_1014 src: /172.18.0.3:43314 dest: /172.18.0.4:50010
2022-12-18 09:50:38,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43314, dest: /172.18.0.4:50010, bytes: 287, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741838_1014, duration: 1170261
2022-12-18 09:50:38,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:38,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741839_1015 src: /172.18.0.4:55684 dest: /172.18.0.4:50010
2022-12-18 09:50:38,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:55684, dest: /172.18.0.4:50010, bytes: 252, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000000_0_-559007600_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741839_1015, duration: 24971613
2022-12-18 09:50:38,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2022-12-18 09:50:38,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-558954561-172.18.0.2-1671356790058:blk_1073741840_1016 src: /172.18.0.3:43326 dest: /172.18.0.4:50010
2022-12-18 09:50:38,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:43326, dest: /172.18.0.4:50010, bytes: 214, op: HDFS_WRITE, cliID: DFSClient_attempt_20221218095016_0000_m_000001_0_230538026_26, offset: 0, srvID: 73983929-9749-47a1-a77e-929f67e590ca, blockid: BP-558954561-172.18.0.2-1671356790058:blk_1073741840_1016, duration: 11127533
2022-12-18 09:50:38,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-558954561-172.18.0.2-1671356790058:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2022-12-18 09:50:48,474 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9cfb2444-ddb2-4fc5-be61-b911530de8e8): no suitable block pools found to scan.  Waiting 1814150115 ms.
2023-12-10 22:12:10,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2023-12-10 22:12:10,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-10 22:12:11,984 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-12-10 22:12:12,131 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2023-12-10 22:12:12,131 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-12-10 22:12:12,135 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-12-10 22:12:12,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2023-12-10 22:12:12,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-12-10 22:12:12,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-12-10 22:12:12,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2023-12-10 22:12:12,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2023-12-10 22:12:12,338 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-12-10 22:12:12,346 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-12-10 22:12:12,356 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-12-10 22:12:12,362 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-12-10 22:12:12,363 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-12-10 22:12:12,363 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-12-10 22:12:12,364 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-12-10 22:12:12,376 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42619
2023-12-10 22:12:12,376 INFO org.mortbay.log: jetty-6.1.26
2023-12-10 22:12:12,584 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42619
2023-12-10 22:12:12,741 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-12-10 22:12:13,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-12-10 22:12:13,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-12-10 22:12:13,258 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2023-12-10 22:12:13,286 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-12-10 22:12:13,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-12-10 22:12:13,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-12-10 22:12:13,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-12-10 22:12:13,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2023-12-10 22:12:13,446 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-12-10 22:12:13,448 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-12-10 22:12:13,895 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 43@slave2
2023-12-10 22:12:13,896 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,896 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-10 22:12:13,939 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,939 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,939 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-97103087-172.18.0.2-1702246324889 is not formatted for BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:13,939 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-10 22:12:13,940 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-97103087-172.18.0.2-1702246324889 directory /tmp/hadoop/dfs/data/current/BP-97103087-172.18.0.2-1702246324889/current
2023-12-10 22:12:13,944 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2023-12-10 22:12:13,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1807287671;bpid=BP-97103087-172.18.0.2-1702246324889;lv=-56;nsInfo=lv=-63;cid=CID-dfb45879-218e-4e95-b6d1-4970483b32da;nsid=1807287671;c=0;bpid=BP-97103087-172.18.0.2-1702246324889;dnuuid=null
2023-12-10 22:12:13,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 056fafb3-97ac-4a52-a99e-7c26613ba8dc
2023-12-10 22:12:14,024 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-90625483-fa96-46ce-869c-0cfaa55714f0
2023-12-10 22:12:14,025 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2023-12-10 22:12:14,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-12-10 22:12:14,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:14,030 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data/current...
2023-12-10 22:12:14,040 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-97103087-172.18.0.2-1702246324889 on /tmp/hadoop/dfs/data/current: 9ms
2023-12-10 22:12:14,040 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-97103087-172.18.0.2-1702246324889: 11ms
2023-12-10 22:12:14,040 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data/current...
2023-12-10 22:12:14,041 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data/current: 0ms
2023-12-10 22:12:14,041 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2023-12-10 22:12:14,237 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-97103087-172.18.0.2-1702246324889 on volume /tmp/hadoop/dfs/data
2023-12-10 22:12:14,238 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): finished scanning block pool BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:12:14,251 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1702248293251 with interval 21600000
2023-12-10 22:12:14,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2023-12-10 22:12:14,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2023-12-10 22:12:14,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-12-10 22:12:14,345 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): no suitable block pools found to scan.  Waiting 1814399877 ms.
2023-12-10 22:12:14,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid 056fafb3-97ac-4a52-a99e-7c26613ba8dc) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2023-12-10 22:12:14,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-97103087-172.18.0.2-1702246324889 (Datanode Uuid 056fafb3-97ac-4a52-a99e-7c26613ba8dc) service to master/172.18.0.2:54310
2023-12-10 22:12:14,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7d5db79881,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-10 22:12:14,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-97103087-172.18.0.2-1702246324889
2023-12-10 22:23:32,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741825_1001 src: /172.18.0.2:39668 dest: /172.18.0.4:50010
2023-12-10 22:23:32,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39668, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741825_1001, duration: 200453707
2023-12-10 22:23:32,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741832_1008 src: /172.18.0.2:39670 dest: /172.18.0.4:50010
2023-12-10 22:23:33,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39670, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741832_1008, duration: 98304523
2023-12-10 22:23:33,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741833_1009 src: /172.18.0.2:39686 dest: /172.18.0.4:50010
2023-12-10 22:23:33,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39686, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741833_1009, duration: 68861962
2023-12-10 22:23:33,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741835_1011 src: /172.18.0.2:39688 dest: /172.18.0.4:50010
2023-12-10 22:23:33,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39688, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741835_1011, duration: 61376108
2023-12-10 22:23:33,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741837_1013 src: /172.18.0.2:39692 dest: /172.18.0.4:50010
2023-12-10 22:23:33,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39692, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741837_1013, duration: 97764889
2023-12-10 22:23:33,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:33,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741838_1014 src: /172.18.0.2:39708 dest: /172.18.0.4:50010
2023-12-10 22:23:34,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39708, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741838_1014, duration: 77128948
2023-12-10 22:23:34,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741840_1016 src: /172.18.0.2:39714 dest: /172.18.0.4:50010
2023-12-10 22:23:34,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39714, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741840_1016, duration: 47730130
2023-12-10 22:23:34,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741841_1017 src: /172.18.0.2:39726 dest: /172.18.0.4:50010
2023-12-10 22:23:34,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39726, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741841_1017, duration: 43648631
2023-12-10 22:23:34,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741842_1018 src: /172.18.0.2:39738 dest: /172.18.0.4:50010
2023-12-10 22:23:34,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39738, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741842_1018, duration: 65088951
2023-12-10 22:23:34,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741843_1019 src: /172.18.0.2:39754 dest: /172.18.0.4:50010
2023-12-10 22:23:34,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39754, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741843_1019, duration: 63594874
2023-12-10 22:23:34,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741844_1020 src: /172.18.0.2:39758 dest: /172.18.0.4:50010
2023-12-10 22:23:34,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39758, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741844_1020, duration: 80924617
2023-12-10 22:23:34,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741847_1023 src: /172.18.0.2:39768 dest: /172.18.0.4:50010
2023-12-10 22:23:34,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39768, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741847_1023, duration: 50278662
2023-12-10 22:23:34,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:34,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741849_1025 src: /172.18.0.2:39778 dest: /172.18.0.4:50010
2023-12-10 22:23:35,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39778, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741849_1025, duration: 48184293
2023-12-10 22:23:35,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741850_1026 src: /172.18.0.2:39790 dest: /172.18.0.4:50010
2023-12-10 22:23:35,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39790, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741850_1026, duration: 36319852
2023-12-10 22:23:35,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741852_1028 src: /172.18.0.2:39802 dest: /172.18.0.4:50010
2023-12-10 22:23:35,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39802, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741852_1028, duration: 42820912
2023-12-10 22:23:35,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741853_1029 src: /172.18.0.2:39810 dest: /172.18.0.4:50010
2023-12-10 22:23:35,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39810, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741853_1029, duration: 31506685
2023-12-10 22:23:35,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:23:35,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741855_1031 src: /172.18.0.2:39818 dest: /172.18.0.4:50010
2023-12-10 22:23:35,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:39818, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1234285672_1, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741855_1031, duration: 41625226
2023-12-10 22:23:35,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:24:16,814 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741832_1008 for rescanning.
2023-12-10 22:24:17,040 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741833_1009 for rescanning.
2023-12-10 22:24:20,671 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741835_1011 for rescanning.
2023-12-10 22:24:24,248 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741837_1013 for rescanning.
2023-12-10 22:24:27,518 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741838_1014 for rescanning.
2023-12-10 22:24:31,150 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741840_1016 for rescanning.
2023-12-10 22:24:31,161 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741841_1017 for rescanning.
2023-12-10 22:24:34,442 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741843_1019 for rescanning.
2023-12-10 22:24:34,527 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741842_1018 for rescanning.
2023-12-10 22:24:38,528 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741844_1020 for rescanning.
2023-12-10 22:24:41,868 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741847_1023 for rescanning.
2023-12-10 22:24:45,185 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741849_1025 for rescanning.
2023-12-10 22:24:48,625 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741850_1026 for rescanning.
2023-12-10 22:24:52,006 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741852_1028 for rescanning.
2023-12-10 22:24:52,094 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741853_1029 for rescanning.
2023-12-10 22:24:55,939 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-90625483-fa96-46ce-869c-0cfaa55714f0): Scheduling suspect block BP-97103087-172.18.0.2-1702246324889:blk_1073741855_1031 for rescanning.
2023-12-10 22:25:01,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741857_1033 src: /172.18.0.4:37872 dest: /172.18.0.4:50010
2023-12-10 22:25:01,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741858_1034 src: /172.18.0.3:50342 dest: /172.18.0.4:50010
2023-12-10 22:25:01,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37872, dest: /172.18.0.4:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741857_1033, duration: 30484228
2023-12-10 22:25:01,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:01,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50342, dest: /172.18.0.4:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741858_1034, duration: 72276157
2023-12-10 22:25:01,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:01,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741859_1035 src: /172.18.0.4:37882 dest: /172.18.0.4:50010
2023-12-10 22:25:01,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741860_1036 src: /172.18.0.3:50346 dest: /172.18.0.4:50010
2023-12-10 22:25:01,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37882, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741859_1035, duration: 9181995
2023-12-10 22:25:01,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:01,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50346, dest: /172.18.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741860_1036, duration: 5972209
2023-12-10 22:25:01,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:01,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741862_1038 src: /172.18.0.4:37886 dest: /172.18.0.4:50010
2023-12-10 22:25:01,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741861_1037 src: /172.18.0.3:50352 dest: /172.18.0.4:50010
2023-12-10 22:25:01,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50352, dest: /172.18.0.4:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741861_1037, duration: 20945651
2023-12-10 22:25:01,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:01,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37886, dest: /172.18.0.4:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741862_1038, duration: 28583299
2023-12-10 22:25:01,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741864_1040 src: /172.18.0.4:37898 dest: /172.18.0.4:50010
2023-12-10 22:25:02,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741863_1039 src: /172.18.0.3:50368 dest: /172.18.0.4:50010
2023-12-10 22:25:02,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50368, dest: /172.18.0.4:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741863_1039, duration: 24971092
2023-12-10 22:25:02,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37898, dest: /172.18.0.4:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741864_1040, duration: 5279821
2023-12-10 22:25:02,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741866_1042 src: /172.18.0.4:37914 dest: /172.18.0.4:50010
2023-12-10 22:25:02,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741865_1041 src: /172.18.0.3:50372 dest: /172.18.0.4:50010
2023-12-10 22:25:02,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37914, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741866_1042, duration: 20853412
2023-12-10 22:25:02,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50372, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741865_1041, duration: 8093153
2023-12-10 22:25:02,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741867_1043 src: /172.18.0.3:50376 dest: /172.18.0.4:50010
2023-12-10 22:25:02,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50376, dest: /172.18.0.4:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741867_1043, duration: 9667117
2023-12-10 22:25:02,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741868_1044 src: /172.18.0.4:37918 dest: /172.18.0.4:50010
2023-12-10 22:25:02,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37918, dest: /172.18.0.4:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741868_1044, duration: 42593619
2023-12-10 22:25:02,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:02,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741869_1045 src: /172.18.0.3:50384 dest: /172.18.0.4:50010
2023-12-10 22:25:02,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50384, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741869_1045, duration: 5463617
2023-12-10 22:25:02,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:02,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741870_1046 src: /172.18.0.4:37928 dest: /172.18.0.4:50010
2023-12-10 22:25:02,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37928, dest: /172.18.0.4:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741870_1046, duration: 2794855
2023-12-10 22:25:02,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741871_1047 src: /172.18.0.3:50386 dest: /172.18.0.4:50010
2023-12-10 22:25:03,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50386, dest: /172.18.0.4:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741871_1047, duration: 16942364
2023-12-10 22:25:03,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741872_1048 src: /172.18.0.4:37934 dest: /172.18.0.4:50010
2023-12-10 22:25:03,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37934, dest: /172.18.0.4:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741872_1048, duration: 42634999
2023-12-10 22:25:03,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741873_1049 src: /172.18.0.3:50396 dest: /172.18.0.4:50010
2023-12-10 22:25:03,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50396, dest: /172.18.0.4:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741873_1049, duration: 6451451
2023-12-10 22:25:03,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741874_1050 src: /172.18.0.4:37944 dest: /172.18.0.4:50010
2023-12-10 22:25:03,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37944, dest: /172.18.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741874_1050, duration: 5270743
2023-12-10 22:25:03,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741875_1051 src: /172.18.0.3:50412 dest: /172.18.0.4:50010
2023-12-10 22:25:03,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50412, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741875_1051, duration: 1535916
2023-12-10 22:25:03,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:03,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741876_1052 src: /172.18.0.4:37960 dest: /172.18.0.4:50010
2023-12-10 22:25:03,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37960, dest: /172.18.0.4:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741876_1052, duration: 43668046
2023-12-10 22:25:03,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:03,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741877_1053 src: /172.18.0.3:50418 dest: /172.18.0.4:50010
2023-12-10 22:25:03,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50418, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741877_1053, duration: 1257186
2023-12-10 22:25:03,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741878_1054 src: /172.18.0.4:37968 dest: /172.18.0.4:50010
2023-12-10 22:25:04,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37968, dest: /172.18.0.4:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741878_1054, duration: 5217052
2023-12-10 22:25:04,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741879_1055 src: /172.18.0.3:50432 dest: /172.18.0.4:50010
2023-12-10 22:25:04,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50432, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741879_1055, duration: 9366157
2023-12-10 22:25:04,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741880_1056 src: /172.18.0.4:37984 dest: /172.18.0.4:50010
2023-12-10 22:25:04,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741881_1057 src: /172.18.0.3:50434 dest: /172.18.0.4:50010
2023-12-10 22:25:04,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50434, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741881_1057, duration: 20677688
2023-12-10 22:25:04,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37984, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741880_1056, duration: 22134382
2023-12-10 22:25:04,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741882_1058 src: /172.18.0.4:37996 dest: /172.18.0.4:50010
2023-12-10 22:25:04,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741883_1059 src: /172.18.0.3:50438 dest: /172.18.0.4:50010
2023-12-10 22:25:04,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:37996, dest: /172.18.0.4:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741882_1058, duration: 10184193
2023-12-10 22:25:04,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50438, dest: /172.18.0.4:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741883_1059, duration: 13245362
2023-12-10 22:25:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:04,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741884_1060 src: /172.18.0.4:38010 dest: /172.18.0.4:50010
2023-12-10 22:25:04,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741885_1061 src: /172.18.0.3:50448 dest: /172.18.0.4:50010
2023-12-10 22:25:04,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:38010, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741884_1060, duration: 2590513
2023-12-10 22:25:04,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741884_1060, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:04,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50448, dest: /172.18.0.4:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741885_1061, duration: 3105325
2023-12-10 22:25:04,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:05,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741887_1063 src: /172.18.0.4:38014 dest: /172.18.0.4:50010
2023-12-10 22:25:05,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-97103087-172.18.0.2-1702246324889:blk_1073741886_1062 src: /172.18.0.3:50460 dest: /172.18.0.4:50010
2023-12-10 22:25:05,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:38014, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000000_0_1245083975_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741887_1063, duration: 10382104
2023-12-10 22:25:05,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741887_1063, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-10 22:25:05,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:50460, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231210222354_0000_m_000001_0_-281111758_26, offset: 0, srvID: 056fafb3-97ac-4a52-a99e-7c26613ba8dc, blockid: BP-97103087-172.18.0.2-1702246324889:blk_1073741886_1062, duration: 12835623
2023-12-10 22:25:05,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-97103087-172.18.0.2-1702246324889:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-10 22:25:40,549 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "slave2/172.18.0.4"; destination host is: "master":54310; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2023-12-10 22:25:44,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/172.18.0.2:54310. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-12-10 22:25:45,382 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-12-10 22:25:45,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave2/172.18.0.4
************************************************************/
2023-12-16 08:09:55,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.19.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2023-12-16 08:09:55,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-16 08:09:56,550 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-12-16 08:09:56,614 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2023-12-16 08:09:56,614 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-12-16 08:09:56,617 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-12-16 08:09:56,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2023-12-16 08:09:56,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-12-16 08:09:56,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-12-16 08:09:56,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2023-12-16 08:09:56,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2023-12-16 08:09:56,713 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-12-16 08:09:56,717 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-12-16 08:09:56,719 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-12-16 08:09:56,722 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-12-16 08:09:56,723 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-12-16 08:09:56,723 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-12-16 08:09:56,723 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-12-16 08:09:56,748 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36567
2023-12-16 08:09:56,748 INFO org.mortbay.log: jetty-6.1.26
2023-12-16 08:09:56,894 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36567
2023-12-16 08:09:57,009 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-12-16 08:09:57,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-12-16 08:09:57,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-12-16 08:09:57,312 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2023-12-16 08:09:57,324 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-12-16 08:09:57,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-12-16 08:09:57,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-12-16 08:09:57,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-12-16 08:09:57,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.19.0.2:54310 starting to offer service
2023-12-16 08:09:57,430 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-12-16 08:09:57,433 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-12-16 08:09:58,635 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2023-12-16 08:09:58,638 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,638 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-16 08:09:58,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,770 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,787 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-855300685-172.19.0.2-1702714189155 is not formatted for BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:58,787 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-16 08:09:58,788 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-855300685-172.19.0.2-1702714189155 directory /tmp/hadoop/dfs/data/current/BP-855300685-172.19.0.2-1702714189155/current
2023-12-16 08:09:58,795 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2023-12-16 08:09:58,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1110687171;bpid=BP-855300685-172.19.0.2-1702714189155;lv=-56;nsInfo=lv=-63;cid=CID-2bbcc24e-5268-42cb-b63f-a0eb25f33987;nsid=1110687171;c=0;bpid=BP-855300685-172.19.0.2-1702714189155;dnuuid=null
2023-12-16 08:09:58,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 2ee9eb69-157f-4706-8ce3-1936700eec6f
2023-12-16 08:09:58,971 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-57010e22-184f-408c-b309-4eee3be6bffc
2023-12-16 08:09:58,972 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2023-12-16 08:09:58,999 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-12-16 08:09:59,000 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:59,003 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data/current...
2023-12-16 08:09:59,062 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-855300685-172.19.0.2-1702714189155 on /tmp/hadoop/dfs/data/current: 60ms
2023-12-16 08:09:59,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-855300685-172.19.0.2-1702714189155: 62ms
2023-12-16 08:09:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data/current...
2023-12-16 08:09:59,065 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data/current: 1ms
2023-12-16 08:09:59,067 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2023-12-16 08:09:59,448 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-855300685-172.19.0.2-1702714189155 on volume /tmp/hadoop/dfs/data
2023-12-16 08:09:59,450 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-57010e22-184f-408c-b309-4eee3be6bffc): finished scanning block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:09:59,471 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1702718824471 with interval 21600000
2023-12-16 08:09:59,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid null) service to master/172.19.0.2:54310 beginning handshake with NN
2023-12-16 08:09:59,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid null) service to master/172.19.0.2:54310 successfully registered with NN
2023-12-16 08:09:59,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.19.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-12-16 08:09:59,762 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-57010e22-184f-408c-b309-4eee3be6bffc): no suitable block pools found to scan.  Waiting 1814399681 ms.
2023-12-16 08:09:59,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid 2ee9eb69-157f-4706-8ce3-1936700eec6f) service to master/172.19.0.2:54310 trying to claim ACTIVE state with txid=1
2023-12-16 08:09:59,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-855300685-172.19.0.2-1702714189155 (Datanode Uuid 2ee9eb69-157f-4706-8ce3-1936700eec6f) service to master/172.19.0.2:54310
2023-12-16 08:10:00,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2c371bc510b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 175 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-16 08:10:00,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:11:11,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741827_1003 src: /172.19.0.2:60080 dest: /172.19.0.4:50010
2023-12-16 08:11:11,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:60080, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_853522575_1, offset: 0, srvID: 2ee9eb69-157f-4706-8ce3-1936700eec6f, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741827_1003, duration: 127802809
2023-12-16 08:11:11,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:12:23,617 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-57010e22-184f-408c-b309-4eee3be6bffc): Scheduling suspect block BP-855300685-172.19.0.2-1702714189155:blk_1073741827_1003 for rescanning.
2023-12-16 08:12:36,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741830_1006 src: /172.19.0.4:49416 dest: /172.19.0.4:50010
2023-12-16 08:12:36,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741829_1005 src: /172.19.0.3:36126 dest: /172.19.0.4:50010
2023-12-16 08:12:36,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:36126, dest: /172.19.0.4:50010, bytes: 448, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000001_0_497024143_26, offset: 0, srvID: 2ee9eb69-157f-4706-8ce3-1936700eec6f, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741829_1005, duration: 75656370
2023-12-16 08:12:36,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:12:36,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:49416, dest: /172.19.0.4:50010, bytes: 580, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000000_0_1389196456_26, offset: 0, srvID: 2ee9eb69-157f-4706-8ce3-1936700eec6f, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741830_1006, duration: 54251357
2023-12-16 08:12:36,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-16 08:12:36,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741831_1007 src: /172.19.0.3:36130 dest: /172.19.0.4:50010
2023-12-16 08:12:36,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:36130, dest: /172.19.0.4:50010, bytes: 481, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000001_0_497024143_26, offset: 0, srvID: 2ee9eb69-157f-4706-8ce3-1936700eec6f, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741831_1007, duration: 11214005
2023-12-16 08:12:36,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-16 08:12:36,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-855300685-172.19.0.2-1702714189155:blk_1073741832_1008 src: /172.19.0.4:49428 dest: /172.19.0.4:50010
2023-12-16 08:12:36,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:49428, dest: /172.19.0.4:50010, bytes: 505, op: HDFS_WRITE, cliID: DFSClient_attempt_20231216081206_0000_m_000000_0_1389196456_26, offset: 0, srvID: 2ee9eb69-157f-4706-8ce3-1936700eec6f, blockid: BP-855300685-172.19.0.2-1702714189155:blk_1073741832_1008, duration: 4533302
2023-12-16 08:12:36,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-855300685-172.19.0.2-1702714189155:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-16 08:12:39,621 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-57010e22-184f-408c-b309-4eee3be6bffc): no suitable block pools found to scan.  Waiting 1814239823 ms.
2023-12-16 08:25:09,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x39731039c3c,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 3 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-16 08:25:09,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-855300685-172.19.0.2-1702714189155
2023-12-16 08:49:13,598 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1587ms
No GCs detected
2023-12-19 14:14:33,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.19.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2023-12-19 14:14:33,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-19 14:14:33,801 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-12-19 14:14:33,883 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2023-12-19 14:14:33,883 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-12-19 14:14:33,886 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-12-19 14:14:33,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2023-12-19 14:14:33,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-12-19 14:14:33,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2023-12-19 14:14:33,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2023-12-19 14:14:33,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2023-12-19 14:14:34,020 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2023-12-19 14:14:34,025 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-12-19 14:14:34,028 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-12-19 14:14:34,031 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-12-19 14:14:34,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-12-19 14:14:34,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-12-19 14:14:34,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-12-19 14:14:34,049 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36701
2023-12-19 14:14:34,049 INFO org.mortbay.log: jetty-6.1.26
2023-12-19 14:14:34,215 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36701
2023-12-19 14:14:34,350 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2023-12-19 14:14:34,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-12-19 14:14:34,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-12-19 14:14:34,709 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2023-12-19 14:14:34,733 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2023-12-19 14:14:34,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2023-12-19 14:14:34,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2023-12-19 14:14:34,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2023-12-19 14:14:34,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.19.0.2:54310 starting to offer service
2023-12-19 14:14:34,811 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-12-19 14:14:34,837 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2023-12-19 14:14:35,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2023-12-19 14:14:35,068 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,068 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-19 14:14:35,104 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,104 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,105 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1931797428-172.19.0.2-1702995266959 is not formatted for BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,105 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2023-12-19 14:14:35,105 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1931797428-172.19.0.2-1702995266959 directory /tmp/hadoop/dfs/data/current/BP-1931797428-172.19.0.2-1702995266959/current
2023-12-19 14:14:35,109 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2023-12-19 14:14:35,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=470937626;bpid=BP-1931797428-172.19.0.2-1702995266959;lv=-56;nsInfo=lv=-63;cid=CID-0970c588-93a0-43a8-ba25-6e35d5178fa9;nsid=470937626;c=0;bpid=BP-1931797428-172.19.0.2-1702995266959;dnuuid=null
2023-12-19 14:14:35,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 1bd9466b-cf79-45f2-a070-d12eff280490
2023-12-19 14:14:35,153 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-857828ab-f0dc-41cd-bfaf-530b360b2742
2023-12-19 14:14:35,153 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2023-12-19 14:14:35,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-12-19 14:14:35,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data/current...
2023-12-19 14:14:35,162 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1931797428-172.19.0.2-1702995266959 on /tmp/hadoop/dfs/data/current: 6ms
2023-12-19 14:14:35,162 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1931797428-172.19.0.2-1702995266959: 7ms
2023-12-19 14:14:35,163 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data/current...
2023-12-19 14:14:35,163 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data/current: 0ms
2023-12-19 14:14:35,163 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2023-12-19 14:14:35,279 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1931797428-172.19.0.2-1702995266959 on volume /tmp/hadoop/dfs/data
2023-12-19 14:14:35,280 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): finished scanning block pool BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:14:35,296 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1702995530296 with interval 21600000
2023-12-19 14:14:35,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid null) service to master/172.19.0.2:54310 beginning handshake with NN
2023-12-19 14:14:35,320 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): no suitable block pools found to scan.  Waiting 1814399954 ms.
2023-12-19 14:14:35,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid null) service to master/172.19.0.2:54310 successfully registered with NN
2023-12-19 14:14:35,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.19.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-12-19 14:14:35,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid 1bd9466b-cf79-45f2-a070-d12eff280490) service to master/172.19.0.2:54310 trying to claim ACTIVE state with txid=1
2023-12-19 14:14:35,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1931797428-172.19.0.2-1702995266959 (Datanode Uuid 1bd9466b-cf79-45f2-a070-d12eff280490) service to master/172.19.0.2:54310
2023-12-19 14:14:35,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4144139674a,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-12-19 14:14:35,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1931797428-172.19.0.2-1702995266959
2023-12-19 14:16:39,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741826_1002 src: /172.19.0.2:38064 dest: /172.19.0.4:50010
2023-12-19 14:16:39,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38064, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741826_1002, duration: 145331176
2023-12-19 14:16:39,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:39,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741830_1006 src: /172.19.0.2:38080 dest: /172.19.0.4:50010
2023-12-19 14:16:39,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38080, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741830_1006, duration: 77997910
2023-12-19 14:16:39,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:39,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741831_1007 src: /172.19.0.2:38092 dest: /172.19.0.4:50010
2023-12-19 14:16:39,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38092, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741831_1007, duration: 48628869
2023-12-19 14:16:39,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:39,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741832_1008 src: /172.19.0.2:38100 dest: /172.19.0.4:50010
2023-12-19 14:16:40,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38100, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741832_1008, duration: 49427639
2023-12-19 14:16:40,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741833_1009 src: /172.19.0.2:38108 dest: /172.19.0.4:50010
2023-12-19 14:16:40,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38108, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741833_1009, duration: 47194093
2023-12-19 14:16:40,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741836_1012 src: /172.19.0.2:38122 dest: /172.19.0.4:50010
2023-12-19 14:16:40,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38122, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741836_1012, duration: 54119883
2023-12-19 14:16:40,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741838_1014 src: /172.19.0.2:38134 dest: /172.19.0.4:50010
2023-12-19 14:16:40,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38134, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741838_1014, duration: 40931764
2023-12-19 14:16:40,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741841_1017 src: /172.19.0.2:38148 dest: /172.19.0.4:50010
2023-12-19 14:16:40,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38148, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741841_1017, duration: 41664497
2023-12-19 14:16:40,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:40,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741844_1020 src: /172.19.0.2:38152 dest: /172.19.0.4:50010
2023-12-19 14:16:40,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38152, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741844_1020, duration: 66461429
2023-12-19 14:16:40,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741846_1022 src: /172.19.0.2:38154 dest: /172.19.0.4:50010
2023-12-19 14:16:41,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38154, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741846_1022, duration: 46987104
2023-12-19 14:16:41,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741847_1023 src: /172.19.0.2:38162 dest: /172.19.0.4:50010
2023-12-19 14:16:41,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38162, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741847_1023, duration: 60694685
2023-12-19 14:16:41,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741849_1025 src: /172.19.0.2:38170 dest: /172.19.0.4:50010
2023-12-19 14:16:41,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38170, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741849_1025, duration: 46508943
2023-12-19 14:16:41,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741851_1027 src: /172.19.0.2:38814 dest: /172.19.0.4:50010
2023-12-19 14:16:41,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38814, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741851_1027, duration: 56335804
2023-12-19 14:16:41,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741854_1030 src: /172.19.0.2:38820 dest: /172.19.0.4:50010
2023-12-19 14:16:41,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38820, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741854_1030, duration: 38906979
2023-12-19 14:16:41,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741855_1031 src: /172.19.0.2:38824 dest: /172.19.0.4:50010
2023-12-19 14:16:41,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38824, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741855_1031, duration: 48420276
2023-12-19 14:16:41,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741855_1031, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:16:41,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741856_1032 src: /172.19.0.2:38828 dest: /172.19.0.4:50010
2023-12-19 14:16:41,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:38828, dest: /172.19.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1723221237_1, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741856_1032, duration: 35579081
2023-12-19 14:16:41,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:04,191 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741826_1002 for rescanning.
2023-12-19 14:17:10,227 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741831_1007 for rescanning.
2023-12-19 14:17:10,293 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741830_1006 for rescanning.
2023-12-19 14:17:13,126 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741832_1008 for rescanning.
2023-12-19 14:17:13,659 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741833_1009 for rescanning.
2023-12-19 14:17:18,883 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741836_1012 for rescanning.
2023-12-19 14:17:21,621 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741838_1014 for rescanning.
2023-12-19 14:17:25,568 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741841_1017 for rescanning.
2023-12-19 14:17:30,354 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741844_1020 for rescanning.
2023-12-19 14:17:33,104 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741846_1022 for rescanning.
2023-12-19 14:17:34,405 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741847_1023 for rescanning.
2023-12-19 14:17:37,224 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741849_1025 for rescanning.
2023-12-19 14:17:39,996 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741851_1027 for rescanning.
2023-12-19 14:17:44,118 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741854_1030 for rescanning.
2023-12-19 14:17:45,525 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741855_1031 for rescanning.
2023-12-19 14:17:46,773 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-857828ab-f0dc-41cd-bfaf-530b360b2742): Scheduling suspect block BP-1931797428-172.19.0.2-1702995266959:blk_1073741856_1032 for rescanning.
2023-12-19 14:17:50,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741858_1034 src: /172.19.0.4:35288 dest: /172.19.0.4:50010
2023-12-19 14:17:50,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741857_1033 src: /172.19.0.3:34414 dest: /172.19.0.4:50010
2023-12-19 14:17:50,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35288, dest: /172.19.0.4:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741858_1034, duration: 26443123
2023-12-19 14:17:50,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34414, dest: /172.19.0.4:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741857_1033, duration: 29735910
2023-12-19 14:17:50,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741857_1033, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741859_1035 src: /172.19.0.4:35296 dest: /172.19.0.4:50010
2023-12-19 14:17:50,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741860_1036 src: /172.19.0.3:34428 dest: /172.19.0.4:50010
2023-12-19 14:17:50,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35296, dest: /172.19.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741859_1035, duration: 3027845
2023-12-19 14:17:50,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34428, dest: /172.19.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741860_1036, duration: 4429007
2023-12-19 14:17:50,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741860_1036, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741862_1038 src: /172.19.0.4:35304 dest: /172.19.0.4:50010
2023-12-19 14:17:50,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741861_1037 src: /172.19.0.3:34444 dest: /172.19.0.4:50010
2023-12-19 14:17:50,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34444, dest: /172.19.0.4:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741861_1037, duration: 10160914
2023-12-19 14:17:50,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35304, dest: /172.19.0.4:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741862_1038, duration: 16327960
2023-12-19 14:17:50,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741864_1040 src: /172.19.0.4:35320 dest: /172.19.0.4:50010
2023-12-19 14:17:50,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741863_1039 src: /172.19.0.3:34448 dest: /172.19.0.4:50010
2023-12-19 14:17:50,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34448, dest: /172.19.0.4:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741863_1039, duration: 21102352
2023-12-19 14:17:50,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35320, dest: /172.19.0.4:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741864_1040, duration: 6031259
2023-12-19 14:17:50,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:50,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741865_1041 src: /172.19.0.3:34464 dest: /172.19.0.4:50010
2023-12-19 14:17:50,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34464, dest: /172.19.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741865_1041, duration: 5250328
2023-12-19 14:17:50,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:50,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741866_1042 src: /172.19.0.4:35326 dest: /172.19.0.4:50010
2023-12-19 14:17:50,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35326, dest: /172.19.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741866_1042, duration: 21809752
2023-12-19 14:17:50,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741867_1043 src: /172.19.0.3:34478 dest: /172.19.0.4:50010
2023-12-19 14:17:51,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34478, dest: /172.19.0.4:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741867_1043, duration: 1712732
2023-12-19 14:17:51,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741868_1044 src: /172.19.0.4:35338 dest: /172.19.0.4:50010
2023-12-19 14:17:51,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35338, dest: /172.19.0.4:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741868_1044, duration: 5765512
2023-12-19 14:17:51,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741869_1045 src: /172.19.0.3:34484 dest: /172.19.0.4:50010
2023-12-19 14:17:51,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:34484, dest: /172.19.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741869_1045, duration: 39601053
2023-12-19 14:17:51,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741870_1046 src: /172.19.0.4:35350 dest: /172.19.0.4:50010
2023-12-19 14:17:51,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:35350, dest: /172.19.0.4:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741870_1046, duration: 2633135
2023-12-19 14:17:51,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741871_1047 src: /172.19.0.3:42118 dest: /172.19.0.4:50010
2023-12-19 14:17:51,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42118, dest: /172.19.0.4:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741871_1047, duration: 2338244
2023-12-19 14:17:51,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741872_1048 src: /172.19.0.4:54496 dest: /172.19.0.4:50010
2023-12-19 14:17:51,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54496, dest: /172.19.0.4:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741872_1048, duration: 16885382
2023-12-19 14:17:51,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741873_1049 src: /172.19.0.3:42128 dest: /172.19.0.4:50010
2023-12-19 14:17:51,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42128, dest: /172.19.0.4:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741873_1049, duration: 2520125
2023-12-19 14:17:51,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741874_1050 src: /172.19.0.4:54510 dest: /172.19.0.4:50010
2023-12-19 14:17:51,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54510, dest: /172.19.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741874_1050, duration: 31863761
2023-12-19 14:17:51,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741874_1050, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741875_1051 src: /172.19.0.3:42132 dest: /172.19.0.4:50010
2023-12-19 14:17:51,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42132, dest: /172.19.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741875_1051, duration: 1843578
2023-12-19 14:17:51,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741875_1051, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:51,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741876_1052 src: /172.19.0.4:54526 dest: /172.19.0.4:50010
2023-12-19 14:17:51,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54526, dest: /172.19.0.4:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741876_1052, duration: 15842738
2023-12-19 14:17:51,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:51,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741877_1053 src: /172.19.0.3:42140 dest: /172.19.0.4:50010
2023-12-19 14:17:52,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42140, dest: /172.19.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741877_1053, duration: 1152014
2023-12-19 14:17:52,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741877_1053, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741878_1054 src: /172.19.0.4:54540 dest: /172.19.0.4:50010
2023-12-19 14:17:52,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54540, dest: /172.19.0.4:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741878_1054, duration: 35212735
2023-12-19 14:17:52,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741879_1055 src: /172.19.0.3:42144 dest: /172.19.0.4:50010
2023-12-19 14:17:52,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42144, dest: /172.19.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741879_1055, duration: 1939316
2023-12-19 14:17:52,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741879_1055, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741880_1056 src: /172.19.0.4:54550 dest: /172.19.0.4:50010
2023-12-19 14:17:52,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54550, dest: /172.19.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741880_1056, duration: 33995269
2023-12-19 14:17:52,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741881_1057 src: /172.19.0.3:42148 dest: /172.19.0.4:50010
2023-12-19 14:17:52,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741882_1058 src: /172.19.0.4:54556 dest: /172.19.0.4:50010
2023-12-19 14:17:52,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42148, dest: /172.19.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741881_1057, duration: 612353
2023-12-19 14:17:52,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741881_1057, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54556, dest: /172.19.0.4:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741882_1058, duration: 19890504
2023-12-19 14:17:52,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741882_1058, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741883_1059 src: /172.19.0.3:42158 dest: /172.19.0.4:50010
2023-12-19 14:17:52,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42158, dest: /172.19.0.4:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741883_1059, duration: 549258
2023-12-19 14:17:52,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741883_1059, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741884_1060 src: /172.19.0.4:54560 dest: /172.19.0.4:50010
2023-12-19 14:17:52,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54560, dest: /172.19.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741884_1060, duration: 35316865
2023-12-19 14:17:52,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741884_1060, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:52,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741885_1061 src: /172.19.0.3:42164 dest: /172.19.0.4:50010
2023-12-19 14:17:52,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42164, dest: /172.19.0.4:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741885_1061, duration: 582476
2023-12-19 14:17:52,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741885_1061, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:17:52,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741886_1062 src: /172.19.0.4:54566 dest: /172.19.0.4:50010
2023-12-19 14:17:52,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.4:54566, dest: /172.19.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000000_0_-904886821_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741886_1062, duration: 5883268
2023-12-19 14:17:52,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741886_1062, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2023-12-19 14:17:53,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1931797428-172.19.0.2-1702995266959:blk_1073741887_1063 src: /172.19.0.3:42178 dest: /172.19.0.4:50010
2023-12-19 14:17:53,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.3:42178, dest: /172.19.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20231219141657_0000_m_000001_0_175125571_26, offset: 0, srvID: 1bd9466b-cf79-45f2-a070-d12eff280490, blockid: BP-1931797428-172.19.0.2-1702995266959:blk_1073741887_1063, duration: 595955
2023-12-19 14:17:53,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1931797428-172.19.0.2-1702995266959:blk_1073741887_1063, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2023-12-19 14:18:50,335 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1931797428-172.19.0.2-1702995266959 Total blocks: 47, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2023-12-19 14:19:16,794 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave2/172.19.0.4"; destination host is: "master":54310; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy14.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:153)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:553)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:823)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)
2023-12-19 14:19:19,316 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2023-12-19 14:19:19,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at slave2/172.19.0.4
************************************************************/
2024-01-09 14:42:00,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-09 14:42:00,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-09 14:42:00,970 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-09 14:42:01,060 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-09 14:42:01,060 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-09 14:42:01,064 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-09 14:42:01,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-09 14:42:01,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-09 14:42:01,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-09 14:42:01,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-09 14:42:01,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-09 14:42:01,260 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-09 14:42:01,266 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-09 14:42:01,271 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-09 14:42:01,276 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-09 14:42:01,277 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-09 14:42:01,277 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-09 14:42:01,278 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-09 14:42:01,288 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41941
2024-01-09 14:42:01,288 INFO org.mortbay.log: jetty-6.1.26
2024-01-09 14:42:01,545 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41941
2024-01-09 14:42:01,796 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-09 14:42:02,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-09 14:42:02,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-09 14:42:02,243 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-09 14:42:02,281 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-09 14:42:02,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-09 14:42:02,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-09 14:42:02,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-09 14:42:02,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-09 14:42:02,437 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-09 14:42:02,438 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-09 14:42:03,222 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-09 14:42:03,223 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,223 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-09 14:42:03,386 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,386 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1699754691-172.18.0.2-1704811312624 is not formatted for BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-09 14:42:03,387 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1699754691-172.18.0.2-1704811312624 directory /tmp/hadoop/dfs/data/current/BP-1699754691-172.18.0.2-1704811312624/current
2024-01-09 14:42:03,445 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-09 14:42:03,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1675739272;bpid=BP-1699754691-172.18.0.2-1704811312624;lv=-56;nsInfo=lv=-63;cid=CID-e260f19a-81d4-4697-8a04-de9a411d3aba;nsid=1675739272;c=0;bpid=BP-1699754691-172.18.0.2-1704811312624;dnuuid=null
2024-01-09 14:42:03,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 848496bd-f03c-4d98-a516-4945fcf9da68
2024-01-09 14:42:03,632 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-44466d3e-768f-41cc-8bf4-36800ef8bf34
2024-01-09 14:42:03,633 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-09 14:42:03,637 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-09 14:42:03,638 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data/current...
2024-01-09 14:42:03,663 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1699754691-172.18.0.2-1704811312624 on /tmp/hadoop/dfs/data/current: 17ms
2024-01-09 14:42:03,664 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1699754691-172.18.0.2-1704811312624: 26ms
2024-01-09 14:42:03,664 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data/current...
2024-01-09 14:42:03,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-01-09 14:42:03,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-09 14:42:03,889 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1699754691-172.18.0.2-1704811312624 on volume /tmp/hadoop/dfs/data
2024-01-09 14:42:03,890 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): finished scanning block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:42:03,905 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1704828148905 with interval 21600000
2024-01-09 14:42:03,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-09 14:42:03,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-09 14:42:03,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-09 14:42:04,014 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): no suitable block pools found to scan.  Waiting 1814399862 ms.
2024-01-09 14:42:04,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid 848496bd-f03c-4d98-a516-4945fcf9da68) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-09 14:42:04,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1699754691-172.18.0.2-1704811312624 (Datanode Uuid 848496bd-f03c-4d98-a516-4945fcf9da68) service to master/172.18.0.2:54310
2024-01-09 14:42:04,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd523394283,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-09 14:42:04,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 14:44:58,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741825_1001 src: /172.18.0.2:32838 dest: /172.18.0.4:50010
2024-01-09 14:44:59,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:32838, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741825_1001, duration: 268775197
2024-01-09 14:44:59,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:44:59,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741826_1002 src: /172.18.0.2:32854 dest: /172.18.0.4:50010
2024-01-09 14:44:59,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:32854, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741826_1002, duration: 158853104
2024-01-09 14:44:59,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:44:59,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741827_1003 src: /172.18.0.2:32864 dest: /172.18.0.4:50010
2024-01-09 14:44:59,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:32864, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741827_1003, duration: 159322722
2024-01-09 14:44:59,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:44:59,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741828_1004 src: /172.18.0.2:32874 dest: /172.18.0.4:50010
2024-01-09 14:44:59,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:32874, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741828_1004, duration: 157899532
2024-01-09 14:44:59,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:44:59,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741830_1006 src: /172.18.0.2:41074 dest: /172.18.0.4:50010
2024-01-09 14:45:00,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41074, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741830_1006, duration: 153096767
2024-01-09 14:45:00,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:00,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741832_1008 src: /172.18.0.2:41084 dest: /172.18.0.4:50010
2024-01-09 14:45:00,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41084, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741832_1008, duration: 181345099
2024-01-09 14:45:00,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:00,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741834_1010 src: /172.18.0.2:41096 dest: /172.18.0.4:50010
2024-01-09 14:45:00,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41096, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741834_1010, duration: 173223426
2024-01-09 14:45:00,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:01,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741836_1012 src: /172.18.0.2:41100 dest: /172.18.0.4:50010
2024-01-09 14:45:01,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41100, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741836_1012, duration: 171105098
2024-01-09 14:45:01,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:01,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741837_1013 src: /172.18.0.2:41114 dest: /172.18.0.4:50010
2024-01-09 14:45:01,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41114, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741837_1013, duration: 175790405
2024-01-09 14:45:01,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:01,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741838_1014 src: /172.18.0.2:41128 dest: /172.18.0.4:50010
2024-01-09 14:45:01,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41128, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741838_1014, duration: 184786396
2024-01-09 14:45:01,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:01,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741839_1015 src: /172.18.0.2:41134 dest: /172.18.0.4:50010
2024-01-09 14:45:02,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41134, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741839_1015, duration: 200871918
2024-01-09 14:45:02,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:02,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741840_1016 src: /172.18.0.2:41144 dest: /172.18.0.4:50010
2024-01-09 14:45:02,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41144, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741840_1016, duration: 189086486
2024-01-09 14:45:02,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:02,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741841_1017 src: /172.18.0.2:41150 dest: /172.18.0.4:50010
2024-01-09 14:45:02,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41150, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741841_1017, duration: 160125029
2024-01-09 14:45:02,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:02,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741843_1019 src: /172.18.0.2:41164 dest: /172.18.0.4:50010
2024-01-09 14:45:02,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41164, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741843_1019, duration: 189451750
2024-01-09 14:45:02,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:03,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741845_1021 src: /172.18.0.2:41170 dest: /172.18.0.4:50010
2024-01-09 14:45:03,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41170, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741845_1021, duration: 196018655
2024-01-09 14:45:03,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:03,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741848_1024 src: /172.18.0.2:41180 dest: /172.18.0.4:50010
2024-01-09 14:45:04,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41180, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741848_1024, duration: 163216453
2024-01-09 14:45:04,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:04,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741849_1025 src: /172.18.0.2:41190 dest: /172.18.0.4:50010
2024-01-09 14:45:04,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41190, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741849_1025, duration: 174717241
2024-01-09 14:45:04,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:04,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741851_1027 src: /172.18.0.2:41198 dest: /172.18.0.4:50010
2024-01-09 14:45:04,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41198, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741851_1027, duration: 185341481
2024-01-09 14:45:04,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:05,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741853_1029 src: /172.18.0.2:41210 dest: /172.18.0.4:50010
2024-01-09 14:45:05,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41210, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741853_1029, duration: 661665083
2024-01-09 14:45:05,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:05,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741854_1030 src: /172.18.0.2:41220 dest: /172.18.0.4:50010
2024-01-09 14:45:06,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41220, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741854_1030, duration: 170938017
2024-01-09 14:45:06,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741854_1030, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:45:06,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741856_1032 src: /172.18.0.2:41224 dest: /172.18.0.4:50010
2024-01-09 14:45:07,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.2:41224, dest: /172.18.0.4:50010, bytes: 16777216, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1657129345_1, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741856_1032, duration: 619145805
2024-01-09 14:45:07,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741856_1032, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:46:38,961 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741826_1002 for rescanning.
2024-01-09 14:46:39,177 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741827_1003 for rescanning.
2024-01-09 14:46:44,408 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741828_1004 for rescanning.
2024-01-09 14:46:48,556 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741830_1006 for rescanning.
2024-01-09 14:46:52,454 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741832_1008 for rescanning.
2024-01-09 14:46:56,258 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741834_1010 for rescanning.
2024-01-09 14:46:59,997 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741836_1012 for rescanning.
2024-01-09 14:47:01,653 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741837_1013 for rescanning.
2024-01-09 14:47:04,253 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741838_1014 for rescanning.
2024-01-09 14:47:06,338 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741839_1015 for rescanning.
2024-01-09 14:47:08,494 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741840_1016 for rescanning.
2024-01-09 14:47:10,423 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741841_1017 for rescanning.
2024-01-09 14:47:15,323 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741843_1019 for rescanning.
2024-01-09 14:47:19,843 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741845_1021 for rescanning.
2024-01-09 14:47:26,195 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741848_1024 for rescanning.
2024-01-09 14:47:28,393 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741849_1025 for rescanning.
2024-01-09 14:47:32,768 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741851_1027 for rescanning.
2024-01-09 14:47:36,965 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741853_1029 for rescanning.
2024-01-09 14:47:39,461 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741854_1030 for rescanning.
2024-01-09 14:47:43,600 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): Scheduling suspect block BP-1699754691-172.18.0.2-1704811312624:blk_1073741856_1032 for rescanning.
2024-01-09 14:47:47,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741857_1033 src: /172.18.0.4:46090 dest: /172.18.0.4:50010
2024-01-09 14:47:47,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741858_1034 src: /172.18.0.3:56244 dest: /172.18.0.4:50010
2024-01-09 14:47:47,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56244, dest: /172.18.0.4:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741858_1034, duration: 38762506
2024-01-09 14:47:47,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741858_1034, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:47,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46090, dest: /172.18.0.4:50010, bytes: 82, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741857_1033, duration: 61622097
2024-01-09 14:47:47,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741859_1035 src: /172.18.0.3:56256 dest: /172.18.0.4:50010
2024-01-09 14:47:48,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56256, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741859_1035, duration: 9081914
2024-01-09 14:47:48,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741859_1035, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741860_1036 src: /172.18.0.4:46104 dest: /172.18.0.4:50010
2024-01-09 14:47:48,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46104, dest: /172.18.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741860_1036, duration: 4452857
2024-01-09 14:47:48,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741860_1036, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741861_1037 src: /172.18.0.3:56270 dest: /172.18.0.4:50010
2024-01-09 14:47:48,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56270, dest: /172.18.0.4:50010, bytes: 69, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741861_1037, duration: 1415562
2024-01-09 14:47:48,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741861_1037, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741862_1038 src: /172.18.0.4:46110 dest: /172.18.0.4:50010
2024-01-09 14:47:48,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46110, dest: /172.18.0.4:50010, bytes: 35, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741862_1038, duration: 3387132
2024-01-09 14:47:48,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741863_1039 src: /172.18.0.3:56278 dest: /172.18.0.4:50010
2024-01-09 14:47:48,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56278, dest: /172.18.0.4:50010, bytes: 111, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741863_1039, duration: 14197406
2024-01-09 14:47:48,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741863_1039, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741864_1040 src: /172.18.0.4:46118 dest: /172.18.0.4:50010
2024-01-09 14:47:48,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46118, dest: /172.18.0.4:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741864_1040, duration: 36682141
2024-01-09 14:47:48,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:48,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741865_1041 src: /172.18.0.3:56294 dest: /172.18.0.4:50010
2024-01-09 14:47:48,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56294, dest: /172.18.0.4:50010, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741865_1041, duration: 14865282
2024-01-09 14:47:48,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741865_1041, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:48,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741866_1042 src: /172.18.0.4:46122 dest: /172.18.0.4:50010
2024-01-09 14:47:48,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46122, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741866_1042, duration: 22121355
2024-01-09 14:47:48,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741867_1043 src: /172.18.0.3:56300 dest: /172.18.0.4:50010
2024-01-09 14:47:49,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56300, dest: /172.18.0.4:50010, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741867_1043, duration: 1830807
2024-01-09 14:47:49,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741867_1043, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741868_1044 src: /172.18.0.4:46124 dest: /172.18.0.4:50010
2024-01-09 14:47:49,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46124, dest: /172.18.0.4:50010, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741868_1044, duration: 22572497
2024-01-09 14:47:49,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741869_1045 src: /172.18.0.3:56308 dest: /172.18.0.4:50010
2024-01-09 14:47:49,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56308, dest: /172.18.0.4:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741869_1045, duration: 16334179
2024-01-09 14:47:49,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741869_1045, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741870_1046 src: /172.18.0.4:46140 dest: /172.18.0.4:50010
2024-01-09 14:47:49,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:46140, dest: /172.18.0.4:50010, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741870_1046, duration: 3532964
2024-01-09 14:47:49,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741871_1047 src: /172.18.0.3:56314 dest: /172.18.0.4:50010
2024-01-09 14:47:49,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:56314, dest: /172.18.0.4:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741871_1047, duration: 9255959
2024-01-09 14:47:49,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741871_1047, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741872_1048 src: /172.18.0.4:52750 dest: /172.18.0.4:50010
2024-01-09 14:47:49,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741873_1049 src: /172.18.0.3:47214 dest: /172.18.0.4:50010
2024-01-09 14:47:49,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52750, dest: /172.18.0.4:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741872_1048, duration: 16717104
2024-01-09 14:47:49,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741872_1048, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:49,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47214, dest: /172.18.0.4:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741873_1049, duration: 12655607
2024-01-09 14:47:49,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741873_1049, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741874_1050 src: /172.18.0.3:47226 dest: /172.18.0.4:50010
2024-01-09 14:47:49,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47226, dest: /172.18.0.4:50010, bytes: 71, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741874_1050, duration: 1225473
2024-01-09 14:47:49,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741874_1050, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:49,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741875_1051 src: /172.18.0.4:52756 dest: /172.18.0.4:50010
2024-01-09 14:47:50,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52756, dest: /172.18.0.4:50010, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741875_1051, duration: 23900039
2024-01-09 14:47:50,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741875_1051, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741876_1052 src: /172.18.0.3:47242 dest: /172.18.0.4:50010
2024-01-09 14:47:50,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47242, dest: /172.18.0.4:50010, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741876_1052, duration: 1801279
2024-01-09 14:47:50,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741876_1052, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741877_1053 src: /172.18.0.4:52762 dest: /172.18.0.4:50010
2024-01-09 14:47:50,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52762, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741877_1053, duration: 14126532
2024-01-09 14:47:50,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741878_1054 src: /172.18.0.3:47258 dest: /172.18.0.4:50010
2024-01-09 14:47:50,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47258, dest: /172.18.0.4:50010, bytes: 61, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741878_1054, duration: 5526563
2024-01-09 14:47:50,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741878_1054, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741879_1055 src: /172.18.0.4:52776 dest: /172.18.0.4:50010
2024-01-09 14:47:50,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52776, dest: /172.18.0.4:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741879_1055, duration: 49882819
2024-01-09 14:47:50,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741880_1056 src: /172.18.0.3:47268 dest: /172.18.0.4:50010
2024-01-09 14:47:50,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47268, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741880_1056, duration: 2261720
2024-01-09 14:47:50,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741880_1056, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741881_1057 src: /172.18.0.4:52786 dest: /172.18.0.4:50010
2024-01-09 14:47:50,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52786, dest: /172.18.0.4:50010, bytes: 53, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741881_1057, duration: 9651888
2024-01-09 14:47:50,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741881_1057, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:50,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741882_1058 src: /172.18.0.3:47282 dest: /172.18.0.4:50010
2024-01-09 14:47:50,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47282, dest: /172.18.0.4:50010, bytes: 56, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741882_1058, duration: 5758598
2024-01-09 14:47:50,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741882_1058, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:50,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741883_1059 src: /172.18.0.4:52788 dest: /172.18.0.4:50010
2024-01-09 14:47:51,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52788, dest: /172.18.0.4:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741883_1059, duration: 31558827
2024-01-09 14:47:51,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741883_1059, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:51,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741884_1060 src: /172.18.0.3:47286 dest: /172.18.0.4:50010
2024-01-09 14:47:51,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47286, dest: /172.18.0.4:50010, bytes: 38, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741884_1060, duration: 2533656
2024-01-09 14:47:51,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741884_1060, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:51,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741885_1061 src: /172.18.0.4:52792 dest: /172.18.0.4:50010
2024-01-09 14:47:51,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52792, dest: /172.18.0.4:50010, bytes: 91, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741885_1061, duration: 2563648
2024-01-09 14:47:51,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741885_1061, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:47:51,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741886_1062 src: /172.18.0.3:47302 dest: /172.18.0.4:50010
2024-01-09 14:47:51,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.3:47302, dest: /172.18.0.4:50010, bytes: 33, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000001_0_801507785_27, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741886_1062, duration: 937127
2024-01-09 14:47:51,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741886_1062, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-01-09 14:47:51,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699754691-172.18.0.2-1704811312624:blk_1073741887_1063 src: /172.18.0.4:52800 dest: /172.18.0.4:50010
2024-01-09 14:47:51,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.18.0.4:52800, dest: /172.18.0.4:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_attempt_20240109144629_0000_m_000000_0_307968708_26, offset: 0, srvID: 848496bd-f03c-4d98-a516-4945fcf9da68, blockid: BP-1699754691-172.18.0.2-1704811312624:blk_1073741887_1063, duration: 16808580
2024-01-09 14:47:51,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699754691-172.18.0.2-1704811312624:blk_1073741887_1063, type=HAS_DOWNSTREAM_IN_PIPELINE terminating
2024-01-09 14:52:01,467 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-44466d3e-768f-41cc-8bf4-36800ef8bf34): no suitable block pools found to scan.  Waiting 1813802409 ms.
2024-01-09 16:39:44,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x740fb97d5a2,  containing 1 storage report(s), of which we sent 1. The reports had 52 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-09 16:39:44,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1699754691-172.18.0.2-1704811312624
2024-01-09 19:22:28,924 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1699754691-172.18.0.2-1704811312624 Total blocks: 52, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-20 13:35:18,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 13:35:18,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 13:35:19,808 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 13:35:19,907 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 13:35:19,907 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 13:35:19,911 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 13:35:19,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 13:35:19,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 13:35:19,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 13:35:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 13:35:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 13:35:20,166 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 13:35:20,176 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 13:35:20,194 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 13:35:20,200 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 13:35:20,201 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 13:35:20,201 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 13:35:20,214 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 13:35:20,226 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46861
2024-01-20 13:35:20,226 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 13:35:20,494 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46861
2024-01-20 13:35:20,725 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 13:35:21,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 13:35:21,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 13:35:21,163 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 13:35:21,192 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 13:35:21,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 13:35:21,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 13:35:21,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 13:35:21,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 13:35:21,333 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 13:35:21,334 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 13:35:22,028 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 13:35:22,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,030 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 13:35:22,171 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,171 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,172 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-469528286-172.18.0.2-1705757711645 is not formatted for BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,172 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 13:35:22,172 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-469528286-172.18.0.2-1705757711645 directory /tmp/hadoop/dfs/data/current/BP-469528286-172.18.0.2-1705757711645/current
2024-01-20 13:35:22,261 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 13:35:22,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1692160234;bpid=BP-469528286-172.18.0.2-1705757711645;lv=-56;nsInfo=lv=-63;cid=CID-389d0ca0-b953-4d93-ae1e-d64cf269b391;nsid=1692160234;c=0;bpid=BP-469528286-172.18.0.2-1705757711645;dnuuid=null
2024-01-20 13:35:22,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 78df9b64-7d31-446c-80ed-63368df88aac
2024-01-20 13:35:22,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c6944e1e-f9d7-49b2-bcce-d0510d5e168c
2024-01-20 13:35:22,478 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 13:35:22,483 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 13:35:22,484 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,492 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 13:35:22,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-469528286-172.18.0.2-1705757711645 on /tmp/hadoop/dfs/data/current: 28ms
2024-01-20 13:35:22,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-469528286-172.18.0.2-1705757711645: 36ms
2024-01-20 13:35:22,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 13:35:22,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 13:35:22,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 13:35:22,802 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-469528286-172.18.0.2-1705757711645 on volume /tmp/hadoop/dfs/data
2024-01-20 13:35:22,803 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c6944e1e-f9d7-49b2-bcce-d0510d5e168c): finished scanning block pool BP-469528286-172.18.0.2-1705757711645
2024-01-20 13:35:22,818 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705778622818 with interval 21600000
2024-01-20 13:35:22,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 13:35:22,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 13:35:22,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 13:35:22,950 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c6944e1e-f9d7-49b2-bcce-d0510d5e168c): no suitable block pools found to scan.  Waiting 1814399839 ms.
2024-01-20 13:35:23,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid 78df9b64-7d31-446c-80ed-63368df88aac) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 13:35:23,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-469528286-172.18.0.2-1705757711645 (Datanode Uuid 78df9b64-7d31-446c-80ed-63368df88aac) service to master/172.18.0.2:54310
2024-01-20 13:35:23,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6d56ff4f6f9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 13:35:23,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-469528286-172.18.0.2-1705757711645
2024-01-20 16:19:37,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 16:19:37,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 16:19:38,610 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 16:19:38,713 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 16:19:38,713 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 16:19:38,716 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 16:19:38,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 16:19:38,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 16:19:38,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 16:19:38,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 16:19:38,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 16:19:38,932 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 16:19:38,940 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 16:19:38,955 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 16:19:38,967 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 16:19:38,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 16:19:38,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 16:19:38,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 16:19:38,988 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39701
2024-01-20 16:19:38,988 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 16:19:39,197 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39701
2024-01-20 16:19:39,389 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 16:19:39,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 16:19:39,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 16:19:39,796 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 16:19:39,807 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 16:19:39,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 16:19:39,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 16:19:39,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 16:19:39,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 16:19:39,956 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 16:19:39,967 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 16:19:40,595 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 16:19:40,597 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,597 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 16:19:40,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1309909280-172.18.0.2-1705767570687 is not formatted for BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:40,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 16:19:40,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1309909280-172.18.0.2-1705767570687 directory /tmp/hadoop/dfs/data/current/BP-1309909280-172.18.0.2-1705767570687/current
2024-01-20 16:19:40,862 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 16:19:40,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2024432647;bpid=BP-1309909280-172.18.0.2-1705767570687;lv=-56;nsInfo=lv=-63;cid=CID-9a37a394-0884-486e-9b78-814b7ed43dbe;nsid=2024432647;c=0;bpid=BP-1309909280-172.18.0.2-1705767570687;dnuuid=null
2024-01-20 16:19:40,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 8397fcea-5b6e-4f12-92e4-7d3800643d49
2024-01-20 16:19:41,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9e00c6f7-30df-417d-9011-8a879e7fca53
2024-01-20 16:19:41,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 16:19:41,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 16:19:41,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:41,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 16:19:41,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1309909280-172.18.0.2-1705767570687 on /tmp/hadoop/dfs/data/current: 26ms
2024-01-20 16:19:41,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1309909280-172.18.0.2-1705767570687: 27ms
2024-01-20 16:19:41,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 16:19:41,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 16:19:41,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-01-20 16:19:41,356 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1309909280-172.18.0.2-1705767570687 on volume /tmp/hadoop/dfs/data
2024-01-20 16:19:41,357 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9e00c6f7-30df-417d-9011-8a879e7fca53): finished scanning block pool BP-1309909280-172.18.0.2-1705767570687
2024-01-20 16:19:41,371 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705776222371 with interval 21600000
2024-01-20 16:19:41,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 16:19:41,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 16:19:41,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 16:19:41,496 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9e00c6f7-30df-417d-9011-8a879e7fca53): no suitable block pools found to scan.  Waiting 1814399847 ms.
2024-01-20 16:19:41,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid 8397fcea-5b6e-4f12-92e4-7d3800643d49) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 16:19:41,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1309909280-172.18.0.2-1705767570687 (Datanode Uuid 8397fcea-5b6e-4f12-92e4-7d3800643d49) service to master/172.18.0.2:54310
2024-01-20 16:19:41,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x30e2a0ad020,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 16:19:41,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1309909280-172.18.0.2-1705767570687
2024-01-20 17:00:27,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 17:00:27,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 17:00:28,463 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 17:00:28,546 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 17:00:28,546 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 17:00:28,550 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 17:00:28,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 17:00:28,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 17:00:28,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 17:00:28,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 17:00:28,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 17:00:28,710 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 17:00:28,716 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 17:00:28,721 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 17:00:28,726 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 17:00:28,727 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 17:00:28,727 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 17:00:28,728 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 17:00:28,738 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44267
2024-01-20 17:00:28,738 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 17:00:28,924 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44267
2024-01-20 17:00:29,059 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 17:00:29,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 17:00:29,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 17:00:29,463 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 17:00:29,497 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 17:00:29,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 17:00:29,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 17:00:29,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 17:00:29,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 17:00:29,607 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 17:00:29,616 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 17:00:30,224 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 17:00:30,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:00:30,345 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,345 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,346 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1983476275-172.18.0.2-1705770021146 is not formatted for BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,346 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:00:30,346 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1983476275-172.18.0.2-1705770021146 directory /tmp/hadoop/dfs/data/current/BP-1983476275-172.18.0.2-1705770021146/current
2024-01-20 17:00:30,415 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 17:00:30,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=757749215;bpid=BP-1983476275-172.18.0.2-1705770021146;lv=-56;nsInfo=lv=-63;cid=CID-770b6b9f-afc4-4233-a71d-9fdb943b02b5;nsid=757749215;c=0;bpid=BP-1983476275-172.18.0.2-1705770021146;dnuuid=null
2024-01-20 17:00:30,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID d9121e60-53bd-44ab-ba32-52b548a8f483
2024-01-20 17:00:30,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9fb60ade-859c-482a-9612-d3ed13177484
2024-01-20 17:00:30,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 17:00:30,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 17:00:30,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:00:30,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1983476275-172.18.0.2-1705770021146 on /tmp/hadoop/dfs/data/current: 6ms
2024-01-20 17:00:30,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1983476275-172.18.0.2-1705770021146: 7ms
2024-01-20 17:00:30,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:00:30,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 17:00:30,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 17:00:30,674 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1983476275-172.18.0.2-1705770021146 on volume /tmp/hadoop/dfs/data
2024-01-20 17:00:30,675 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9fb60ade-859c-482a-9612-d3ed13177484): finished scanning block pool BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:00:30,686 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705783946686 with interval 21600000
2024-01-20 17:00:30,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 17:00:30,746 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-9fb60ade-859c-482a-9612-d3ed13177484): no suitable block pools found to scan.  Waiting 1814399928 ms.
2024-01-20 17:00:30,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 17:00:30,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 17:00:30,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid d9121e60-53bd-44ab-ba32-52b548a8f483) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 17:00:30,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1983476275-172.18.0.2-1705770021146 (Datanode Uuid d9121e60-53bd-44ab-ba32-52b548a8f483) service to master/172.18.0.2:54310
2024-01-20 17:00:30,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x548706b1d69,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 17:00:30,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1983476275-172.18.0.2-1705770021146
2024-01-20 17:16:17,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 17:16:17,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 17:16:18,050 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 17:16:18,151 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 17:16:18,151 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 17:16:18,154 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 17:16:18,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 17:16:18,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 17:16:18,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 17:16:18,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 17:16:18,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 17:16:18,318 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 17:16:18,324 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 17:16:18,339 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 17:16:18,344 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 17:16:18,358 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 17:16:18,358 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 17:16:18,358 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 17:16:18,369 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39275
2024-01-20 17:16:18,369 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 17:16:18,586 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39275
2024-01-20 17:16:18,692 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 17:16:19,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 17:16:19,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 17:16:19,071 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 17:16:19,101 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 17:16:19,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 17:16:19,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 17:16:19,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 17:16:19,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 17:16:19,240 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 17:16:19,241 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 17:16:19,811 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 17:16:19,812 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,812 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:16:19,960 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,960 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,961 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1198635670-172.18.0.2-1705770970464 is not formatted for BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:19,961 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 17:16:19,961 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1198635670-172.18.0.2-1705770970464 directory /tmp/hadoop/dfs/data/current/BP-1198635670-172.18.0.2-1705770970464/current
2024-01-20 17:16:20,035 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 17:16:20,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2096026784;bpid=BP-1198635670-172.18.0.2-1705770970464;lv=-56;nsInfo=lv=-63;cid=CID-b8843bbc-681b-4a29-bd0f-a3d3dd4bfc1f;nsid=2096026784;c=0;bpid=BP-1198635670-172.18.0.2-1705770970464;dnuuid=null
2024-01-20 17:16:20,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 2d34e84d-287e-4b73-8579-e54384fb3e2c
2024-01-20 17:16:20,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0360fe39-d77d-4387-912d-01898a41c241
2024-01-20 17:16:20,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 17:16:20,197 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 17:16:20,197 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:20,198 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:16:20,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1198635670-172.18.0.2-1705770970464 on /tmp/hadoop/dfs/data/current: 7ms
2024-01-20 17:16:20,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1198635670-172.18.0.2-1705770970464: 8ms
2024-01-20 17:16:20,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 17:16:20,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 17:16:20,207 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 17:16:20,352 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1198635670-172.18.0.2-1705770970464 on volume /tmp/hadoop/dfs/data
2024-01-20 17:16:20,353 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0360fe39-d77d-4387-912d-01898a41c241): finished scanning block pool BP-1198635670-172.18.0.2-1705770970464
2024-01-20 17:16:20,370 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705790945369 with interval 21600000
2024-01-20 17:16:20,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 17:16:20,429 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-0360fe39-d77d-4387-912d-01898a41c241): no suitable block pools found to scan.  Waiting 1814399914 ms.
2024-01-20 17:16:20,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 17:16:20,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 17:16:20,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid 2d34e84d-287e-4b73-8579-e54384fb3e2c) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 17:16:20,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1198635670-172.18.0.2-1705770970464 (Datanode Uuid 2d34e84d-287e-4b73-8579-e54384fb3e2c) service to master/172.18.0.2:54310
2024-01-20 17:16:20,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6258dd04513,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 17:16:20,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1198635670-172.18.0.2-1705770970464
2024-01-20 21:11:47,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 21:11:47,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 21:11:48,931 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 21:11:49,031 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 21:11:49,031 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 21:11:49,034 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 21:11:49,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 21:11:49,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 21:11:49,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 21:11:49,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 21:11:49,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 21:11:49,245 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 21:11:49,263 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 21:11:49,281 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 21:11:49,286 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 21:11:49,287 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 21:11:49,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 21:11:49,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 21:11:49,313 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39557
2024-01-20 21:11:49,313 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 21:11:49,568 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39557
2024-01-20 21:11:49,789 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 21:11:50,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 21:11:50,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 21:11:50,216 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 21:11:50,244 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 21:11:50,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 21:11:50,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 21:11:50,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 21:11:50,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 21:11:50,374 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 21:11:50,375 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 21:11:51,037 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 21:11:51,038 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,038 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 21:11:51,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,176 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-449117960-172.18.0.2-1705785100612 is not formatted for BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,176 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 21:11:51,176 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-449117960-172.18.0.2-1705785100612 directory /tmp/hadoop/dfs/data/current/BP-449117960-172.18.0.2-1705785100612/current
2024-01-20 21:11:51,244 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 21:11:51,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2087465963;bpid=BP-449117960-172.18.0.2-1705785100612;lv=-56;nsInfo=lv=-63;cid=CID-9e37cee3-5766-489c-898a-40c8b8b382be;nsid=2087465963;c=0;bpid=BP-449117960-172.18.0.2-1705785100612;dnuuid=null
2024-01-20 21:11:51,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 5bd23252-91ad-4471-9444-89926efc8afa
2024-01-20 21:11:51,398 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-36d9a03e-f567-4bff-930c-7aff2574be1a
2024-01-20 21:11:51,399 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 21:11:51,404 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 21:11:51,404 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 21:11:51,423 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-449117960-172.18.0.2-1705785100612 on /tmp/hadoop/dfs/data/current: 17ms
2024-01-20 21:11:51,423 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-449117960-172.18.0.2-1705785100612: 19ms
2024-01-20 21:11:51,424 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 21:11:51,424 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-01-20 21:11:51,424 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 21:11:51,721 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-449117960-172.18.0.2-1705785100612 on volume /tmp/hadoop/dfs/data
2024-01-20 21:11:51,722 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-36d9a03e-f567-4bff-930c-7aff2574be1a): finished scanning block pool BP-449117960-172.18.0.2-1705785100612
2024-01-20 21:11:51,735 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705793395735 with interval 21600000
2024-01-20 21:11:51,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 21:11:51,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 21:11:51,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 21:11:51,868 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-36d9a03e-f567-4bff-930c-7aff2574be1a): no suitable block pools found to scan.  Waiting 1814399843 ms.
2024-01-20 21:11:51,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid 5bd23252-91ad-4471-9444-89926efc8afa) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 21:11:51,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-449117960-172.18.0.2-1705785100612 (Datanode Uuid 5bd23252-91ad-4471-9444-89926efc8afa) service to master/172.18.0.2:54310
2024-01-20 21:11:52,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1dc25058d83,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 70 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 21:11:52,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-449117960-172.18.0.2-1705785100612
2024-01-20 22:16:42,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 22:16:42,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 22:16:43,498 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 22:16:43,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 22:16:43,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 22:16:43,591 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 22:16:43,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 22:16:43,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 22:16:43,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 22:16:43,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 22:16:43,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 22:16:43,793 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 22:16:43,800 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 22:16:43,816 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 22:16:43,821 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 22:16:43,822 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 22:16:43,822 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 22:16:43,823 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 22:16:43,845 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44003
2024-01-20 22:16:43,845 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 22:16:44,108 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44003
2024-01-20 22:16:44,299 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 22:16:44,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 22:16:44,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 22:16:44,759 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 22:16:44,782 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 22:16:44,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 22:16:44,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 22:16:44,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 22:16:44,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 22:16:44,912 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 22:16:44,927 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 22:16:45,513 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 22:16:45,514 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,514 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:16:45,635 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,635 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,636 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-171478855-172.18.0.2-1705788995744 is not formatted for BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,636 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:16:45,636 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-171478855-172.18.0.2-1705788995744 directory /tmp/hadoop/dfs/data/current/BP-171478855-172.18.0.2-1705788995744/current
2024-01-20 22:16:45,704 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 22:16:45,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=842859768;bpid=BP-171478855-172.18.0.2-1705788995744;lv=-56;nsInfo=lv=-63;cid=CID-089f6790-0632-4a14-b372-671e4247dc3d;nsid=842859768;c=0;bpid=BP-171478855-172.18.0.2-1705788995744;dnuuid=null
2024-01-20 22:16:45,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 0a97d558-3504-4ae1-95d1-132c6ff3d8eb
2024-01-20 22:16:45,843 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c9462270-80a0-4308-a184-c4ddf9d3a1da
2024-01-20 22:16:45,843 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 22:16:45,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 22:16:45,849 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:45,850 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:16:45,860 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-171478855-172.18.0.2-1705788995744 on /tmp/hadoop/dfs/data/current: 10ms
2024-01-20 22:16:45,861 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-171478855-172.18.0.2-1705788995744: 12ms
2024-01-20 22:16:45,861 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:16:45,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 22:16:45,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-20 22:16:46,097 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-171478855-172.18.0.2-1705788995744 on volume /tmp/hadoop/dfs/data
2024-01-20 22:16:46,098 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c9462270-80a0-4308-a184-c4ddf9d3a1da): finished scanning block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:16:46,113 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705810597113 with interval 21600000
2024-01-20 22:16:46,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 22:16:46,181 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c9462270-80a0-4308-a184-c4ddf9d3a1da): no suitable block pools found to scan.  Waiting 1814399907 ms.
2024-01-20 22:16:46,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 22:16:46,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 22:16:46,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid 0a97d558-3504-4ae1-95d1-132c6ff3d8eb) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 22:16:46,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-171478855-172.18.0.2-1705788995744 (Datanode Uuid 0a97d558-3504-4ae1-95d1-132c6ff3d8eb) service to master/172.18.0.2:54310
2024-01-20 22:16:46,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x566df0cea4f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 22:16:46,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-171478855-172.18.0.2-1705788995744
2024-01-20 22:38:55,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-20 22:38:55,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-20 22:38:56,197 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-20 22:38:56,282 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-20 22:38:56,282 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-20 22:38:56,286 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-20 22:38:56,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-20 22:38:56,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-20 22:38:56,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-20 22:38:56,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-20 22:38:56,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-20 22:38:56,506 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-20 22:38:56,523 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-20 22:38:56,540 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-20 22:38:56,545 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-20 22:38:56,546 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-20 22:38:56,546 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-20 22:38:56,547 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-20 22:38:56,559 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34975
2024-01-20 22:38:56,559 INFO org.mortbay.log: jetty-6.1.26
2024-01-20 22:38:56,784 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34975
2024-01-20 22:38:56,990 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-20 22:38:57,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-20 22:38:57,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-20 22:38:57,394 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-20 22:38:57,425 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-20 22:38:57,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-20 22:38:57,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-20 22:38:57,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-20 22:38:57,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-20 22:38:57,566 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-20 22:38:57,567 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-20 22:38:58,129 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-20 22:38:58,130 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,130 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:38:58,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-290709276-172.18.0.2-1705790328183 is not formatted for BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-20 22:38:58,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-290709276-172.18.0.2-1705790328183 directory /tmp/hadoop/dfs/data/current/BP-290709276-172.18.0.2-1705790328183/current
2024-01-20 22:38:58,345 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-20 22:38:58,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=178358391;bpid=BP-290709276-172.18.0.2-1705790328183;lv=-56;nsInfo=lv=-63;cid=CID-2d22698e-c393-4ab9-adbe-72631a4165c4;nsid=178358391;c=0;bpid=BP-290709276-172.18.0.2-1705790328183;dnuuid=null
2024-01-20 22:38:58,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 93c69fca-1048-42dd-b044-d3ac19f33cd3
2024-01-20 22:38:58,522 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-d18a9ba5-2f9f-4bf4-a832-691f38f55921
2024-01-20 22:38:58,522 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-20 22:38:58,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-20 22:38:58,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:38:58,554 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-290709276-172.18.0.2-1705790328183 on /tmp/hadoop/dfs/data/current: 26ms
2024-01-20 22:38:58,554 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-290709276-172.18.0.2-1705790328183: 28ms
2024-01-20 22:38:58,554 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data/current...
2024-01-20 22:38:58,555 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-20 22:38:58,555 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2024-01-20 22:38:58,772 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-290709276-172.18.0.2-1705790328183 on volume /tmp/hadoop/dfs/data
2024-01-20 22:38:58,773 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-d18a9ba5-2f9f-4bf4-a832-691f38f55921): finished scanning block pool BP-290709276-172.18.0.2-1705790328183
2024-01-20 22:38:58,790 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705795393790 with interval 21600000
2024-01-20 22:38:58,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-20 22:38:58,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-20 22:38:58,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-20 22:38:58,918 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-d18a9ba5-2f9f-4bf4-a832-691f38f55921): no suitable block pools found to scan.  Waiting 1814399854 ms.
2024-01-20 22:38:59,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid 93c69fca-1048-42dd-b044-d3ac19f33cd3) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-20 22:38:59,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-290709276-172.18.0.2-1705790328183 (Datanode Uuid 93c69fca-1048-42dd-b044-d3ac19f33cd3) service to master/172.18.0.2:54310
2024-01-20 22:38:59,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x69d2bbc6ed1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 53 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-20 22:38:59,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-290709276-172.18.0.2-1705790328183
2024-01-21 16:57:02,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-21 16:57:02,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-21 16:57:03,283 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-21 16:57:03,370 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-21 16:57:03,370 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-21 16:57:03,373 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-21 16:57:03,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-21 16:57:03,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-21 16:57:03,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-21 16:57:03,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-21 16:57:03,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-21 16:57:03,541 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-21 16:57:03,547 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-21 16:57:03,564 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-21 16:57:03,569 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-21 16:57:03,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-21 16:57:03,570 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-21 16:57:03,571 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-21 16:57:03,595 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36967
2024-01-21 16:57:03,595 INFO org.mortbay.log: jetty-6.1.26
2024-01-21 16:57:03,828 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36967
2024-01-21 16:57:04,037 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-21 16:57:04,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-21 16:57:04,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-21 16:57:04,445 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-21 16:57:04,468 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-21 16:57:04,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-21 16:57:04,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-21 16:57:04,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-21 16:57:04,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-21 16:57:04,640 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-21 16:57:04,641 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-21 16:57:05,263 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-21 16:57:05,264 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,264 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-21 16:57:05,391 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,391 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1175791455-172.18.0.2-1705856215266 is not formatted for BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-21 16:57:05,392 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1175791455-172.18.0.2-1705856215266 directory /tmp/hadoop/dfs/data/current/BP-1175791455-172.18.0.2-1705856215266/current
2024-01-21 16:57:05,462 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-21 16:57:05,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=619814465;bpid=BP-1175791455-172.18.0.2-1705856215266;lv=-56;nsInfo=lv=-63;cid=CID-598f264a-2ba9-4c96-a8a5-cc4228cf780d;nsid=619814465;c=0;bpid=BP-1175791455-172.18.0.2-1705856215266;dnuuid=null
2024-01-21 16:57:05,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 2b792796-59e5-4be6-80e9-9b14231a277d
2024-01-21 16:57:05,612 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b1c16bb3-8ba6-41ed-b7c8-31ba0b7e46e7
2024-01-21 16:57:05,612 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-21 16:57:05,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-21 16:57:05,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,617 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data/current...
2024-01-21 16:57:05,638 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1175791455-172.18.0.2-1705856215266 on /tmp/hadoop/dfs/data/current: 20ms
2024-01-21 16:57:05,638 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1175791455-172.18.0.2-1705856215266: 22ms
2024-01-21 16:57:05,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data/current...
2024-01-21 16:57:05,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-21 16:57:05,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-21 16:57:05,823 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1175791455-172.18.0.2-1705856215266 on volume /tmp/hadoop/dfs/data
2024-01-21 16:57:05,824 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b1c16bb3-8ba6-41ed-b7c8-31ba0b7e46e7): finished scanning block pool BP-1175791455-172.18.0.2-1705856215266
2024-01-21 16:57:05,838 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705863916838 with interval 21600000
2024-01-21 16:57:05,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-21 16:57:05,930 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-b1c16bb3-8ba6-41ed-b7c8-31ba0b7e46e7): no suitable block pools found to scan.  Waiting 1814399887 ms.
2024-01-21 16:57:05,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-21 16:57:05,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-21 16:57:06,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid 2b792796-59e5-4be6-80e9-9b14231a277d) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-21 16:57:06,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1175791455-172.18.0.2-1705856215266 (Datanode Uuid 2b792796-59e5-4be6-80e9-9b14231a277d) service to master/172.18.0.2:54310
2024-01-21 16:57:06,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x960693c169e,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-21 16:57:06,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1175791455-172.18.0.2-1705856215266
2024-01-21 17:35:04,055 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2191ms
No GCs detected
2024-01-22 12:21:22,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-22 12:21:22,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-22 12:21:23,386 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-22 12:21:23,473 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-22 12:21:23,473 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-22 12:21:23,477 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-22 12:21:23,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-22 12:21:23,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-22 12:21:23,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-22 12:21:23,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-22 12:21:23,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-22 12:21:23,710 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-22 12:21:23,716 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-22 12:21:23,734 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-22 12:21:23,740 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-22 12:21:23,741 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-22 12:21:23,741 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-22 12:21:23,742 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-22 12:21:23,766 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40905
2024-01-22 12:21:23,766 INFO org.mortbay.log: jetty-6.1.26
2024-01-22 12:21:24,039 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40905
2024-01-22 12:21:24,237 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-22 12:21:24,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-22 12:21:24,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-22 12:21:24,638 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-22 12:21:24,676 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-22 12:21:24,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-22 12:21:24,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-22 12:21:24,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-22 12:21:24,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-22 12:21:24,790 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-22 12:21:24,791 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-22 12:21:25,395 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-22 12:21:25,396 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,397 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-22 12:21:25,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-637491475-172.18.0.2-1705926075383 is not formatted for BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,523 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-22 12:21:25,523 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-637491475-172.18.0.2-1705926075383 directory /tmp/hadoop/dfs/data/current/BP-637491475-172.18.0.2-1705926075383/current
2024-01-22 12:21:25,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-22 12:21:25,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=134794854;bpid=BP-637491475-172.18.0.2-1705926075383;lv=-56;nsInfo=lv=-63;cid=CID-7b4d5891-c564-4515-8f64-e172cc0493f4;nsid=134794854;c=0;bpid=BP-637491475-172.18.0.2-1705926075383;dnuuid=null
2024-01-22 12:21:25,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID d3e7b4f2-e274-468a-8f20-ed33fdf90e56
2024-01-22 12:21:25,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-6541aca0-e7c6-4d28-966a-279b3dd99aa3
2024-01-22 12:21:25,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-22 12:21:25,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-22 12:21:25,960 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:25,967 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data/current...
2024-01-22 12:21:25,985 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-637491475-172.18.0.2-1705926075383 on /tmp/hadoop/dfs/data/current: 17ms
2024-01-22 12:21:25,985 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-637491475-172.18.0.2-1705926075383: 25ms
2024-01-22 12:21:25,986 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data/current...
2024-01-22 12:21:25,986 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-22 12:21:25,986 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-22 12:21:26,280 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-637491475-172.18.0.2-1705926075383 on volume /tmp/hadoop/dfs/data
2024-01-22 12:21:26,281 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-6541aca0-e7c6-4d28-966a-279b3dd99aa3): finished scanning block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 12:21:26,296 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1705937949296 with interval 21600000
2024-01-22 12:21:26,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-22 12:21:26,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-22 12:21:26,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-22 12:21:26,416 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-6541aca0-e7c6-4d28-966a-279b3dd99aa3): no suitable block pools found to scan.  Waiting 1814399864 ms.
2024-01-22 12:21:26,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid d3e7b4f2-e274-468a-8f20-ed33fdf90e56) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-22 12:21:26,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-637491475-172.18.0.2-1705926075383 (Datanode Uuid d3e7b4f2-e274-468a-8f20-ed33fdf90e56) service to master/172.18.0.2:54310
2024-01-22 12:21:26,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6c4b4d7e8b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 70 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-22 12:21:26,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-637491475-172.18.0.2-1705926075383
2024-01-22 14:49:35,823 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3009ms
No GCs detected
2024-01-22 15:04:19,003 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2901ms
GC pool 'Copy' had collection(s): count=1 time=3105ms
2024-01-31 11:32:42,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 11:32:42,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 11:32:43,735 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 11:32:43,821 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 11:32:43,821 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 11:32:43,828 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 11:32:43,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-31 11:32:43,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 11:32:43,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 11:32:43,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 11:32:43,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 11:32:44,049 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 11:32:44,066 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 11:32:44,071 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 11:32:44,075 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 11:32:44,088 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 11:32:44,088 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 11:32:44,089 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 11:32:44,099 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39525
2024-01-31 11:32:44,099 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 11:32:44,320 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39525
2024-01-31 11:32:44,520 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 11:32:44,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 11:32:44,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 11:32:44,921 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 11:32:44,946 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 11:32:44,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 11:32:45,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 11:32:45,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 11:32:45,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.4:54310 starting to offer service
2024-01-31 11:32:45,101 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 11:32:45,102 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 11:32:45,645 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave2
2024-01-31 11:32:45,646 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,646 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 11:32:45,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1071215085-172.18.0.4-1706700755668 is not formatted for BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:45,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 11:32:45,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1071215085-172.18.0.4-1706700755668 directory /tmp/hadoop/dfs/data/current/BP-1071215085-172.18.0.4-1706700755668/current
2024-01-31 11:32:45,820 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 11:32:45,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=634398172;bpid=BP-1071215085-172.18.0.4-1706700755668;lv=-56;nsInfo=lv=-63;cid=CID-3e869996-b220-45f2-a5b6-cf4fc36d8ce8;nsid=634398172;c=0;bpid=BP-1071215085-172.18.0.4-1706700755668;dnuuid=null
2024-01-31 11:32:45,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 861ae45f-6e8a-45f9-afc4-266bfdd979e4
2024-01-31 11:32:46,095 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a71c6ff2-ccdb-4298-baa6-8bbd0cafd6d5
2024-01-31 11:32:46,095 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 11:32:46,100 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 11:32:46,100 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:46,102 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 11:32:46,123 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1071215085-172.18.0.4-1706700755668 on /tmp/hadoop/dfs/data/current: 21ms
2024-01-31 11:32:46,123 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1071215085-172.18.0.4-1706700755668: 23ms
2024-01-31 11:32:46,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 11:32:46,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 11:32:46,124 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 11:32:46,395 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1071215085-172.18.0.4-1706700755668 on volume /tmp/hadoop/dfs/data
2024-01-31 11:32:46,397 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-a71c6ff2-ccdb-4298-baa6-8bbd0cafd6d5): finished scanning block pool BP-1071215085-172.18.0.4-1706700755668
2024-01-31 11:32:46,420 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706709547420 with interval 21600000
2024-01-31 11:32:46,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid null) service to master/172.18.0.4:54310 beginning handshake with NN
2024-01-31 11:32:46,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid null) service to master/172.18.0.4:54310 successfully registered with NN
2024-01-31 11:32:46,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.4:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 11:32:46,521 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-a71c6ff2-ccdb-4298-baa6-8bbd0cafd6d5): no suitable block pools found to scan.  Waiting 1814399864 ms.
2024-01-31 11:32:46,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid 861ae45f-6e8a-45f9-afc4-266bfdd979e4) service to master/172.18.0.4:54310 trying to claim ACTIVE state with txid=1
2024-01-31 11:32:46,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1071215085-172.18.0.4-1706700755668 (Datanode Uuid 861ae45f-6e8a-45f9-afc4-266bfdd979e4) service to master/172.18.0.4:54310
2024-01-31 11:32:46,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6f1f9f5a5e5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 86 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 11:32:46,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1071215085-172.18.0.4-1706700755668
2024-01-31 13:02:03,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 13:02:03,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 13:02:03,930 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 13:02:04,027 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 13:02:04,027 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 13:02:04,031 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 13:02:04,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-31 13:02:04,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 13:02:04,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 13:02:04,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 13:02:04,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 13:02:04,210 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 13:02:04,229 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 13:02:04,234 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 13:02:04,240 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 13:02:04,241 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 13:02:04,241 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 13:02:04,254 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 13:02:04,265 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46869
2024-01-31 13:02:04,265 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 13:02:04,555 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46869
2024-01-31 13:02:04,779 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 13:02:05,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 13:02:05,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 13:02:05,195 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 13:02:05,207 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 13:02:05,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 13:02:05,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 13:02:05,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 13:02:05,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-31 13:02:05,419 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 13:02:05,420 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 13:02:06,087 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 44@slave2
2024-01-31 13:02:06,088 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,088 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:02:06,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-304942432-172.18.0.2-1706706115706 is not formatted for BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:02:06,193 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-304942432-172.18.0.2-1706706115706 directory /tmp/hadoop/dfs/data/current/BP-304942432-172.18.0.2-1706706115706/current
2024-01-31 13:02:06,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 13:02:06,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=513807859;bpid=BP-304942432-172.18.0.2-1706706115706;lv=-56;nsInfo=lv=-63;cid=CID-8167d057-3746-45e6-bc43-1f73010e984f;nsid=513807859;c=0;bpid=BP-304942432-172.18.0.2-1706706115706;dnuuid=null
2024-01-31 13:02:06,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 7f2a8339-ddda-495c-b79b-5a495486aa09
2024-01-31 13:02:06,471 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-25d5a17b-6404-4818-ab62-643dbb38bc88
2024-01-31 13:02:06,471 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 13:02:06,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 13:02:06,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,486 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:02:06,506 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-304942432-172.18.0.2-1706706115706 on /tmp/hadoop/dfs/data/current: 19ms
2024-01-31 13:02:06,506 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-304942432-172.18.0.2-1706706115706: 29ms
2024-01-31 13:02:06,507 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:02:06,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-01-31 13:02:06,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2024-01-31 13:02:06,750 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-304942432-172.18.0.2-1706706115706 on volume /tmp/hadoop/dfs/data
2024-01-31 13:02:06,752 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-25d5a17b-6404-4818-ab62-643dbb38bc88): finished scanning block pool BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:02:06,765 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706708587765 with interval 21600000
2024-01-31 13:02:06,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-31 13:02:06,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-31 13:02:06,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 13:02:06,863 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-25d5a17b-6404-4818-ab62-643dbb38bc88): no suitable block pools found to scan.  Waiting 1814399874 ms.
2024-01-31 13:02:07,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid 7f2a8339-ddda-495c-b79b-5a495486aa09) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-31 13:02:07,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-304942432-172.18.0.2-1706706115706 (Datanode Uuid 7f2a8339-ddda-495c-b79b-5a495486aa09) service to master/172.18.0.2:54310
2024-01-31 13:02:07,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xbd1ed8639ea,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 72 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 13:02:07,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-304942432-172.18.0.2-1706706115706
2024-01-31 13:29:16,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 13:29:16,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 13:29:17,312 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 13:29:17,424 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 13:29:17,424 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 13:29:17,427 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 13:29:17,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-31 13:29:17,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 13:29:17,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 13:29:17,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 13:29:17,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 13:29:17,626 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 13:29:17,634 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 13:29:17,643 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 13:29:17,651 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 13:29:17,671 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 13:29:17,671 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 13:29:17,671 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 13:29:17,682 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41833
2024-01-31 13:29:17,685 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 13:29:17,968 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41833
2024-01-31 13:29:18,176 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 13:29:18,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 13:29:18,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 13:29:18,656 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 13:29:18,695 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 13:29:18,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 13:29:18,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 13:29:18,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 13:29:18,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.2:54310 starting to offer service
2024-01-31 13:29:18,837 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 13:29:18,838 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 13:29:19,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave2
2024-01-31 13:29:19,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,570 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:29:19,722 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,722 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,723 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-583157701-172.18.0.2-1706707749215 is not formatted for BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,723 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 13:29:19,723 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-583157701-172.18.0.2-1706707749215 directory /tmp/hadoop/dfs/data/current/BP-583157701-172.18.0.2-1706707749215/current
2024-01-31 13:29:19,777 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 13:29:19,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=306995317;bpid=BP-583157701-172.18.0.2-1706707749215;lv=-56;nsInfo=lv=-63;cid=CID-058974d8-4383-4236-99ec-4ce43c431678;nsid=306995317;c=0;bpid=BP-583157701-172.18.0.2-1706707749215;dnuuid=null
2024-01-31 13:29:19,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 8729d6b0-6fc5-4495-9e00-747eeb06f7ce
2024-01-31 13:29:19,912 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-500a513a-3cdf-4b7b-b782-fb4b325a98a6
2024-01-31 13:29:19,912 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 13:29:19,917 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 13:29:19,924 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:19,926 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:29:19,956 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-583157701-172.18.0.2-1706707749215 on /tmp/hadoop/dfs/data/current: 30ms
2024-01-31 13:29:19,957 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-583157701-172.18.0.2-1706707749215: 32ms
2024-01-31 13:29:19,957 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 13:29:19,958 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 13:29:19,958 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 13:29:20,213 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-583157701-172.18.0.2-1706707749215 on volume /tmp/hadoop/dfs/data
2024-01-31 13:29:20,214 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-500a513a-3cdf-4b7b-b782-fb4b325a98a6): finished scanning block pool BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:29:20,230 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706709435230 with interval 21600000
2024-01-31 13:29:20,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid null) service to master/172.18.0.2:54310 beginning handshake with NN
2024-01-31 13:29:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid null) service to master/172.18.0.2:54310 successfully registered with NN
2024-01-31 13:29:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.2:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 13:29:20,333 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-500a513a-3cdf-4b7b-b782-fb4b325a98a6): no suitable block pools found to scan.  Waiting 1814399880 ms.
2024-01-31 13:29:20,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid 8729d6b0-6fc5-4495-9e00-747eeb06f7ce) service to master/172.18.0.2:54310 trying to claim ACTIVE state with txid=1
2024-01-31 13:29:20,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-583157701-172.18.0.2-1706707749215 (Datanode Uuid 8729d6b0-6fc5-4495-9e00-747eeb06f7ce) service to master/172.18.0.2:54310
2024-01-31 13:29:20,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd4e3cabec0f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 217 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 13:29:20,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-583157701-172.18.0.2-1706707749215
2024-01-31 13:57:15,496 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-583157701-172.18.0.2-1706707749215 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-31 14:57:00,585 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3604ms
No GCs detected
2024-01-31 15:17:20,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 15:17:20,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 15:17:21,824 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 15:17:21,937 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 15:17:21,937 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 15:17:21,941 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 15:17:21,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-31 15:17:21,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 15:17:21,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 15:17:21,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 15:17:21,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 15:17:22,123 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 15:17:22,143 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 15:17:22,148 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 15:17:22,153 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 15:17:22,155 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 15:17:22,155 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 15:17:22,162 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 15:17:22,183 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41581
2024-01-31 15:17:22,183 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 15:17:22,440 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41581
2024-01-31 15:17:22,650 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 15:17:22,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 15:17:22,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 15:17:23,067 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 15:17:23,089 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 15:17:23,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 15:17:23,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 15:17:23,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 15:17:23,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.4:54310 starting to offer service
2024-01-31 15:17:23,229 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 15:17:23,230 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 15:17:23,867 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave2
2024-01-31 15:17:23,868 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:23,868 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 15:17:24,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1431395744-172.18.0.4-1706714233822 is not formatted for BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 15:17:24,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1431395744-172.18.0.4-1706714233822 directory /tmp/hadoop/dfs/data/current/BP-1431395744-172.18.0.4-1706714233822/current
2024-01-31 15:17:24,414 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 15:17:24,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1371280364;bpid=BP-1431395744-172.18.0.4-1706714233822;lv=-56;nsInfo=lv=-63;cid=CID-cbc3682d-53ae-4915-b762-092f6d4a0db0;nsid=1371280364;c=0;bpid=BP-1431395744-172.18.0.4-1706714233822;dnuuid=null
2024-01-31 15:17:24,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 1afbda39-8b75-41ca-9d19-3c86a70fd246
2024-01-31 15:17:24,628 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c76d2e96-bfbb-4c96-b2da-b8276a773648
2024-01-31 15:17:24,629 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 15:17:24,639 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 15:17:24,640 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,641 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 15:17:24,662 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1431395744-172.18.0.4-1706714233822 on /tmp/hadoop/dfs/data/current: 21ms
2024-01-31 15:17:24,663 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1431395744-172.18.0.4-1706714233822: 23ms
2024-01-31 15:17:24,664 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 15:17:24,664 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 15:17:24,664 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 15:17:24,974 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1431395744-172.18.0.4-1706714233822 on volume /tmp/hadoop/dfs/data
2024-01-31 15:17:24,975 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c76d2e96-bfbb-4c96-b2da-b8276a773648): finished scanning block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 15:17:24,994 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706722509994 with interval 21600000
2024-01-31 15:17:25,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid null) service to master/172.18.0.4:54310 beginning handshake with NN
2024-01-31 15:17:25,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid null) service to master/172.18.0.4:54310 successfully registered with NN
2024-01-31 15:17:25,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.4:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 15:17:25,150 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-c76d2e96-bfbb-4c96-b2da-b8276a773648): no suitable block pools found to scan.  Waiting 1814399824 ms.
2024-01-31 15:17:25,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid 1afbda39-8b75-41ca-9d19-3c86a70fd246) service to master/172.18.0.4:54310 trying to claim ACTIVE state with txid=1
2024-01-31 15:17:25,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1431395744-172.18.0.4-1706714233822 (Datanode Uuid 1afbda39-8b75-41ca-9d19-3c86a70fd246) service to master/172.18.0.4:54310
2024-01-31 15:17:25,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xecd2b5c4be,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 15:17:25,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1431395744-172.18.0.4-1706714233822
2024-01-31 16:14:27,836 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4174ms
GC pool 'Copy' had collection(s): count=1 time=4332ms
2024-01-31 17:35:10,373 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1431395744-172.18.0.4-1706714233822 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2024-01-31 18:40:02,618 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6778ms
No GCs detected
2024-01-31 22:59:08,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-01-31 22:59:08,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-31 22:59:08,909 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-01-31 22:59:08,990 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-01-31 22:59:08,990 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-01-31 22:59:08,994 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-01-31 22:59:08,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-01-31 22:59:09,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-01-31 22:59:09,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-01-31 22:59:09,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-01-31 22:59:09,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-01-31 22:59:09,215 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-01-31 22:59:09,221 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-01-31 22:59:09,226 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-01-31 22:59:09,230 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-01-31 22:59:09,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-01-31 22:59:09,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-01-31 22:59:09,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-01-31 22:59:09,243 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44541
2024-01-31 22:59:09,243 INFO org.mortbay.log: jetty-6.1.26
2024-01-31 22:59:09,502 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44541
2024-01-31 22:59:09,745 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-01-31 22:59:10,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-01-31 22:59:10,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-01-31 22:59:10,154 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-01-31 22:59:10,191 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-01-31 22:59:10,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-01-31 22:59:10,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-01-31 22:59:10,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-01-31 22:59:10,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.6:54310 starting to offer service
2024-01-31 22:59:10,300 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-01-31 22:59:10,301 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-01-31 22:59:10,894 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave2
2024-01-31 22:59:10,895 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:10,895 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 22:59:11,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,040 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-355379469-172.18.0.6-1706741940834 is not formatted for BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,040 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-01-31 22:59:11,040 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-355379469-172.18.0.6-1706741940834 directory /tmp/hadoop/dfs/data/current/BP-355379469-172.18.0.6-1706741940834/current
2024-01-31 22:59:11,093 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-01-31 22:59:11,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=321320448;bpid=BP-355379469-172.18.0.6-1706741940834;lv=-56;nsInfo=lv=-63;cid=CID-9f407693-9c9d-42b2-929b-9cb929a35059;nsid=321320448;c=0;bpid=BP-355379469-172.18.0.6-1706741940834;dnuuid=null
2024-01-31 22:59:11,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 595d2f97-2f4e-4b97-a75e-9ef7bbba3c86
2024-01-31 22:59:11,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-bb564ef1-d8e2-46cf-9c73-f30991278154
2024-01-31 22:59:11,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-01-31 22:59:11,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-01-31 22:59:11,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,305 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 22:59:11,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-355379469-172.18.0.6-1706741940834 on /tmp/hadoop/dfs/data/current: 17ms
2024-01-31 22:59:11,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-355379469-172.18.0.6-1706741940834: 18ms
2024-01-31 22:59:11,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data/current...
2024-01-31 22:59:11,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data/current: 0ms
2024-01-31 22:59:11,323 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-01-31 22:59:11,606 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-355379469-172.18.0.6-1706741940834 on volume /tmp/hadoop/dfs/data
2024-01-31 22:59:11,607 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-bb564ef1-d8e2-46cf-9c73-f30991278154): finished scanning block pool BP-355379469-172.18.0.6-1706741940834
2024-01-31 22:59:11,626 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1706747245626 with interval 21600000
2024-01-31 22:59:11,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid null) service to master/172.18.0.6:54310 beginning handshake with NN
2024-01-31 22:59:11,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid null) service to master/172.18.0.6:54310 successfully registered with NN
2024-01-31 22:59:11,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.6:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-01-31 22:59:11,739 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-bb564ef1-d8e2-46cf-9c73-f30991278154): no suitable block pools found to scan.  Waiting 1814399860 ms.
2024-01-31 22:59:11,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid 595d2f97-2f4e-4b97-a75e-9ef7bbba3c86) service to master/172.18.0.6:54310 trying to claim ACTIVE state with txid=1
2024-01-31 22:59:11,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-355379469-172.18.0.6-1706741940834 (Datanode Uuid 595d2f97-2f4e-4b97-a75e-9ef7bbba3c86) service to master/172.18.0.6:54310
2024-01-31 22:59:11,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa9efe00653c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 57 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-01-31 22:59:11,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-355379469-172.18.0.6-1706741940834
2024-02-03 17:10:22,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave2/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /root/hadoop/etc/hadoop:/root/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/root/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/common/lib/junit-4.11.jar:/root/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/root/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/root/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/root/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/root/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/root/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/root/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/root/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/root/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/root/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/root/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/root/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/root/hadoop/share/hadoop/common/lib/activation-1.1.jar:/root/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/root/hadoop/share/hadoop/common/lib/asm-3.2.jar:/root/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/root/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/root/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/root/hadoop/share/hadoop/hdfs:/root/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/root/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/root/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/root/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/root/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/root/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/root/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/root/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/root/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/root/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/root/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/root/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/root/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/root/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/root/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/root/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/root/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/root/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/root/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/root/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/root/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/root/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/root/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/root/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/root/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/root/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/root/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/root/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/root/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/root/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/root/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/root/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/root/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar:/root/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2024-02-03 17:10:22,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-02-03 17:10:23,653 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-02-03 17:10:23,764 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-02-03 17:10:23,764 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-02-03 17:10:23,768 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2024-02-03 17:10:23,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2024-02-03 17:10:23,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-02-03 17:10:23,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-02-03 17:10:23,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-02-03 17:10:23,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-02-03 17:10:24,022 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-02-03 17:10:24,030 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-02-03 17:10:24,045 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-02-03 17:10:24,050 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-02-03 17:10:24,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-02-03 17:10:24,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-02-03 17:10:24,052 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-02-03 17:10:24,075 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38513
2024-02-03 17:10:24,076 INFO org.mortbay.log: jetty-6.1.26
2024-02-03 17:10:24,293 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38513
2024-02-03 17:10:24,504 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2024-02-03 17:10:24,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2024-02-03 17:10:24,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-02-03 17:10:24,956 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-02-03 17:10:24,992 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-02-03 17:10:25,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-02-03 17:10:25,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-02-03 17:10:25,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-02-03 17:10:25,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.6:54310 starting to offer service
2024-02-03 17:10:25,128 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-02-03 17:10:25,129 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-02-03 17:10:25,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop/dfs/data/in_use.lock acquired by nodename 42@slave2
2024-02-03 17:10:25,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop/dfs/data is not formatted for BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-02-03 17:10:25,939 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,940 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop/dfs/data/current/BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,940 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop/dfs/data/current/BP-1439553629-172.18.0.6-1706980215407 is not formatted for BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:25,940 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-02-03 17:10:25,940 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1439553629-172.18.0.6-1706980215407 directory /tmp/hadoop/dfs/data/current/BP-1439553629-172.18.0.6-1706980215407/current
2024-02-03 17:10:26,024 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-02-03 17:10:26,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1537516082;bpid=BP-1439553629-172.18.0.6-1706980215407;lv=-56;nsInfo=lv=-63;cid=CID-0dc58037-822b-4bcf-b296-f3e933fa8198;nsid=1537516082;c=0;bpid=BP-1439553629-172.18.0.6-1706980215407;dnuuid=null
2024-02-03 17:10:26,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 6ce68669-64d5-4a6a-ab98-0bd73d5cd642
2024-02-03 17:10:26,203 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-f3d62395-fcfa-4fb6-a35c-a9b4ce8e873b
2024-02-03 17:10:26,203 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop/dfs/data/current, StorageType: DISK
2024-02-03 17:10:26,209 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-02-03 17:10:26,209 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:26,217 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data/current...
2024-02-03 17:10:26,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1439553629-172.18.0.6-1706980215407 on /tmp/hadoop/dfs/data/current: 22ms
2024-02-03 17:10:26,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1439553629-172.18.0.6-1706980215407: 31ms
2024-02-03 17:10:26,241 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data/current...
2024-02-03 17:10:26,242 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data/current: 1ms
2024-02-03 17:10:26,242 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-02-03 17:10:26,516 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1439553629-172.18.0.6-1706980215407 on volume /tmp/hadoop/dfs/data
2024-02-03 17:10:26,518 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f3d62395-fcfa-4fb6-a35c-a9b4ce8e873b): finished scanning block pool BP-1439553629-172.18.0.6-1706980215407
2024-02-03 17:10:26,533 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1707000372533 with interval 21600000
2024-02-03 17:10:26,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid null) service to master/172.18.0.6:54310 beginning handshake with NN
2024-02-03 17:10:26,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid null) service to master/172.18.0.6:54310 successfully registered with NN
2024-02-03 17:10:26,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.18.0.6:54310 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-02-03 17:10:26,671 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop/dfs/data, DS-f3d62395-fcfa-4fb6-a35c-a9b4ce8e873b): no suitable block pools found to scan.  Waiting 1814399829 ms.
2024-02-03 17:10:26,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid 6ce68669-64d5-4a6a-ab98-0bd73d5cd642) service to master/172.18.0.6:54310 trying to claim ACTIVE state with txid=1
2024-02-03 17:10:26,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1439553629-172.18.0.6-1706980215407 (Datanode Uuid 6ce68669-64d5-4a6a-ab98-0bd73d5cd642) service to master/172.18.0.6:54310
2024-02-03 17:10:26,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe2b02cd2efa,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 55 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2024-02-03 17:10:26,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1439553629-172.18.0.6-1706980215407
